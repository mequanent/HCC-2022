{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mequanent/HCC-2022/blob/main/Recommendation%20Sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcHNFEcWJOuf"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4tMRNY6LB8zZ",
        "outputId": "3ebde1aa-d9ed-4c76-b414-bc657e5d8461"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gc\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "# synthesize data\n",
        "NUM_USERS = 10_000\n",
        "NUM_ITEMS = 1_000\n",
        "user_id = np.arange(start = 0, stop = NUM_USERS)\n",
        "item_id = np.arange(start = 0, stop = NUM_ITEMS)\n",
        "np.random.seed(42)\n",
        "\n",
        "user_item_dict = defaultdict(list)\n",
        "genres = ['Action','Comedy','Drama','Fantasy','Horror','Mystery','Romance','Thriller','Western']\n",
        "for id in user_id:\n",
        "    \n",
        "    # random the number of item generation\n",
        "    # for each user, random 3 to 5 items to be rated.\n",
        "    num_rand_item = np.random.randint(low = 3, high = 5)\n",
        "\n",
        "    # random from the item_id\n",
        "    rand_items = np.random.choice(item_id, size = num_rand_item, replace = False)\n",
        "\n",
        "    # random rating for each itme_id\n",
        "    rand_rating = np.random.randint(low = 1, high = 10, size = num_rand_item)\n",
        "\n",
        "    # collect the user-item paris.\n",
        "    for uid, iid,rating in zip([id] * num_rand_item, rand_items, rand_rating):\n",
        "        user_item_dict['user_id'].append(uid)\n",
        "        user_item_dict['item_id'].append(iid)\n",
        "        user_item_dict['rating'].append(rating)\n",
        "\n",
        "# prepare dataframe\n",
        "ratings = pd.DataFrame(user_item_dict)\n",
        "print(\"Rating Dataframe\")\n",
        "ratings[['user_id','item_id']] = ratings[['user_id','item_id']].astype(str)\n",
        "display(ratings.head())\n",
        "\n",
        "item_genre_dict = defaultdict(list)\n",
        "for iid in item_id:\n",
        "\n",
        "    # random number of genres\n",
        "    num_rand_genre = np.random.randint(low = 1, high = 3)\n",
        "    # random set of genres\n",
        "    rand_genres = np.random.choice(genres, size = num_rand_genre, replace = False)\n",
        "    item_genre_dict['item_id'].append(iid)\n",
        "    item_genre_dict['genres'].append(', '.join(list(rand_genres)))\n",
        "\n",
        "# prepare dataframe\n",
        "items = pd.DataFrame(item_genre_dict)\n",
        "print(\"\\nItem Dataframe\")\n",
        "items = items.astype(str)\n",
        "display(items.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rating Dataframe\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>521</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>941</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>741</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>986</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>275</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  user_id item_id  rating\n",
              "0       0     521       2\n",
              "1       0     941       8\n",
              "2       0     741       2\n",
              "3       1     986       5\n",
              "4       1     275       5"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Item Dataframe\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Mystery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Drama, Western</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Fantasy, Horror</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Comedy, Drama</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  item_id           genres\n",
              "0       0  Romance, Action\n",
              "1       1          Mystery\n",
              "2       2   Drama, Western\n",
              "3       3  Fantasy, Horror\n",
              "4       4    Comedy, Drama"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPSHx5UANsIb"
      },
      "source": [
        "# Popularity based\n",
        "\n",
        "**Introduction**\n",
        "\n",
        "For any machine learning problems, we need a baseline model or method to use as a reference whether our approach is good or not.\n",
        "\n",
        "Our machine learning prediction or sophsticated analysis should, at least, beat those baseline performance.\n",
        "\n",
        "For recommendation system, we can make a simple baseline score with popular item recommendation\n",
        "\n",
        "To define the popularity of the item, there have a metrics called weighted rating system that is used to score the rating of each movie.\n",
        "\n",
        "Here is the formula\n",
        "\n",
        "```\n",
        "(WR) = (v ÷ (v+m)) × R + (m ÷ (v+m)) × C\n",
        "```\n",
        "Where\n",
        "- R = average rating for the movie. (rating)\n",
        "- v = number of votes for the movie. (members)\n",
        "- m = minimum votes required to be listed in the Top 250 (defined by > percentile 80 of total votes)\n",
        "- C = the average rating across the whole dataset.\n",
        "\n",
        "**Drawback**\n",
        "\n",
        "- It's not personalized. All the users will get the same exact list of popularity based recommendation.\n",
        "\n",
        "**Action**\n",
        "\n",
        "- For new users, if we don't have any information about them we can provide the list based on ranking the vote_count or weighted_rating as a best guess.\n",
        "In real world, this is the result when you see the section \"Popular on Netflix\"\n",
        "\n",
        "**Reference**\n",
        "\n",
        "- [IMDB rating system](https://help.imdb.com/article/imdb/track-movies-tv/ratings-faq/G67Y87TFYYP6TWAV?ref_=helpms_helpart_inline#)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tw7HGVGWJTer",
        "outputId": "b23d0dfa-8bd0-4715-f99b-5fb390f9114d"
      },
      "source": [
        "def weighted_rating(v,m,R,C):\n",
        "    '''\n",
        "    Calculate the weighted rating\n",
        "    \n",
        "    Args:\n",
        "    v -> average rating for each item (float)\n",
        "    m -> minimum votes required to be classified as popular (float)\n",
        "    R -> average rating for the item (pd.Series)\n",
        "    C -> average rating for the whole dataset (pd.Series)\n",
        "    \n",
        "    Returns:\n",
        "    pd.Series\n",
        "    '''\n",
        "    return ( (v / (v + m)) * R) + ( (m / (v + m)) * C )\n",
        "\n",
        "def assign_popular_based_score(rating_df, item_df, user_col, item_col, rating_col):\n",
        "    '''\n",
        "    Assigned popular based score based on the IMDB weighted average.\n",
        "    \n",
        "    Args:\n",
        "    rating -> pd.DataFrame contains ['item_id', 'rating'] for each user.\n",
        "    \n",
        "    Returns\n",
        "    popular_items -> pd.DataFrame contains item and IMDB weighted score.\n",
        "    '''\n",
        "    \n",
        "    # pre processing\n",
        "    vote_count = (\n",
        "        rating_df\n",
        "        .groupby(item_col,as_index=False)\n",
        "        .agg( {user_col:'count', rating_col:'mean'} )\n",
        "        )\n",
        "    vote_count.columns = [item_col, 'vote_count', 'avg_rating']\n",
        "    \n",
        "    # calcuate input parameters\n",
        "    C = np.mean(vote_count['avg_rating'])\n",
        "    m = np.percentile(vote_count['vote_count'], 70)\n",
        "    vote_count = vote_count[vote_count['vote_count'] >= m]\n",
        "    R = vote_count['avg_rating']\n",
        "    v = vote_count['vote_count']\n",
        "    vote_count['weighted_rating'] = weighted_rating(v,m,R,C)\n",
        "    \n",
        "    # post processing\n",
        "    vote_count = vote_count.merge(item_df, on = [item_col], how = 'left')\n",
        "    popular_items = vote_count.loc[:,[item_col, 'genres', 'vote_count', 'avg_rating', 'weighted_rating']]\n",
        "    \n",
        "    return popular_items\n",
        "\n",
        "# init constant\n",
        "USER_COL = 'user_id'\n",
        "ITEM_COL = 'item_id'\n",
        "RATING_COL = 'rating'\n",
        "\n",
        "# calcualte popularity based\n",
        "pop_items = assign_popular_based_score(ratings, items, USER_COL, ITEM_COL, RATING_COL)\n",
        "pop_items = pop_items.sort_values('weighted_rating', ascending = False)\n",
        "\n",
        "# plot the popularity based on the weighted score\n",
        "fix, ax = plt.subplots(figsize=(9,6))\n",
        "sns.barplot(data = pop_items.head(10),\n",
        "            y = 'item_id',\n",
        "            x = 'weighted_rating',\n",
        "            palette = 'mako');\n",
        "sns.despine();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EHqK1l0KE-j"
      },
      "source": [
        "# Content based \n",
        "\n",
        "**Introduction**\n",
        "\n",
        "For example, if a person has liked the movie “Inception”, then this algorithm will recommend movies that fall under the same genre.\n",
        "\n",
        "Here we create a better way of recommendation by introducing other features of the content into our engine.\n",
        "\n",
        "It's an improvement compared to the popularity based recommendation we mentioned earlier.\n",
        "\n",
        "Now, the customer who read, watch, or like any kinds of specific products will get a recommendation based on the product they interacted in the past.\n",
        "\n",
        "Consider the example of Netflix. They save all the information related to each user in a vector form. This vector contains the past behavior of the user, i.e. the movies liked/disliked by the user and the ratings given by them. This vector is known as the profile vector. All the information related to movies is stored in another vector called the item vector. Item vector contains the details of each movie, like genre, cast, director, etc. The content-based filtering algorithm finds the cosine of the angle between the profile vector and item vector, i.e. cosine similarity.\n",
        "\n",
        "**Drawback**\n",
        "\n",
        "A major drawback of this algorithm is that it is limited to recommending items that are of the same type.\n",
        "It will never recommend products which the user has not bought or liked in the past. So if a user has watched or liked only action movies in the past, the system will recommend only action movies.\n",
        "\n",
        "**Reference**\n",
        "\n",
        "[Building a movie content based recommender using tf-idf](https://towardsdatascience.com/content-based-recommender-systems-28a1dbd858f5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "J4YXYjEuK1C2",
        "outputId": "3b2c7d40-dad7-498c-ab82-0583749d9315"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def top_k_items(item_id, top_k, corr_mat, map_name):\n",
        "    \n",
        "    # sort correlation value ascendingly and select top_k item_id\n",
        "    top_items = corr_mat[item_id,:].argsort()[-top_k:][::-1] \n",
        "    top_items = [map_name[e] for e in top_items] \n",
        "\n",
        "    return top_items\n",
        "\n",
        "# preprocessing\n",
        "rated_items = items.loc[items[ITEM_COL].isin(ratings[ITEM_COL])].copy()\n",
        "\n",
        "# extract the genre\n",
        "genre = rated_items['genres'].str.split(\",\", expand=True)\n",
        "\n",
        "# get all possible genre\n",
        "all_genre = set()\n",
        "for c in genre.columns:\n",
        "    distinct_genre = genre[c].str.lower().str.strip().unique()\n",
        "    all_genre.update(distinct_genre)\n",
        "all_genre.remove(None)\n",
        "\n",
        "# create item-genre matrix\n",
        "item_genre_mat = rated_items[[ITEM_COL, 'genres']].copy()\n",
        "item_genre_mat['genres'] = item_genre_mat['genres'].str.lower().str.strip()\n",
        "\n",
        "# OHE the genres column\n",
        "for genre in all_genre:\n",
        "    item_genre_mat[genre] = np.where(item_genre_mat['genres'].str.contains(genre), 1, 0)\n",
        "item_genre_mat = item_genre_mat.drop(['genres'], axis=1)\n",
        "item_genre_mat = item_genre_mat.set_index(ITEM_COL)\n",
        "\n",
        "# compute similarity matix\n",
        "corr_mat = cosine_similarity(item_genre_mat)\n",
        "\n",
        "# get top-k similar items\n",
        "ind2name = {ind:name for ind,name in enumerate(item_genre_mat.index)}\n",
        "name2ind = {v:k for k,v in ind2name.items()}\n",
        "similar_items = top_k_items(name2ind['99'],\n",
        "                            top_k = 10,\n",
        "                            corr_mat = corr_mat,\n",
        "                            map_name = ind2name)\n",
        "\n",
        "# display result\n",
        "print(\"The top-k similar movie to item_id 99\")\n",
        "display(items.loc[items[ITEM_COL].isin(similar_items)])\n",
        "\n",
        "del corr_mat\n",
        "gc.collect();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The top-k similar movie to item_id 99\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>211</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>352</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>512</td>\n",
              "      <td>Action, Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>618</th>\n",
              "      <td>618</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>737</th>\n",
              "      <td>737</td>\n",
              "      <td>Action, Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>744</th>\n",
              "      <td>744</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>813</th>\n",
              "      <td>813</td>\n",
              "      <td>Action, Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>858</th>\n",
              "      <td>858</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    item_id           genres\n",
              "0         0  Romance, Action\n",
              "99       99  Romance, Action\n",
              "211     211  Romance, Action\n",
              "352     352  Romance, Action\n",
              "512     512  Action, Romance\n",
              "618     618  Romance, Action\n",
              "737     737  Action, Romance\n",
              "744     744  Romance, Action\n",
              "813     813  Action, Romance\n",
              "858     858  Romance, Action"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jme6wp0MK1ng"
      },
      "source": [
        "Summary\n",
        "\n",
        "As we expect, all the similar items interm of genre is in the top-k recommendation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0LqiAD4JIut"
      },
      "source": [
        "# Collaborative filtering\n",
        "\n",
        "**Introduction**\n",
        "\n",
        "The collaborative filtering algorithm uses “User Behavior” for recommending items. This is one of the most commonly used algorithms in the industry as it is not dependent on any additional information.\n",
        "\n",
        "There are 2 ways we can make a prediction using the collaborative filtering technique.\n",
        "\n",
        "1. User based - The user-similarity matrix will consist of some distance metric that measures the similarity between any two pairs of users.\n",
        "This algorithm is useful when the number of users is less. Its not effective when there are a large number of users as it will take a lot of time to compute the similarity between all user pairs. This leads us to item-item collaborative filtering, which is effective when the number of users is more than the items being recommended.\n",
        "\n",
        "2. Item based - Likewise, the item-similarity matrix will measure the similarity between any two pairs of items.\n",
        "\n",
        "**Drawback**\n",
        "\n",
        "What will happen if a new user or a new item is added in the dataset? The answer is we can't make a prediction for that user or item because we don't have enough \"User behavior\" information. This problem is called a Cold Start. \n",
        "\n",
        "There are two types of cold start.\n",
        "1. User - Since there is no history of that user, the system does not know the preferences of that user\n",
        "These can be determined by what has been popular recently overall or regionally.\n",
        "\n",
        "2. Item - More the interaction a product receives, the easier it is for our model to recommend that product to the right user.\n",
        "We can make use of Content based filtering to solve this problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w9c4fVUR2Zp"
      },
      "source": [
        "## 3.1 Memory based approache\n",
        "\n",
        "**Introduction**\n",
        "\n",
        "The key difference of memory-based approach from the model-based techniques is that we are not learning any parameter using gradient descent (or any other optimization algorithm). The closest user or items are calculated only by using Cosine similarity or Pearson correlation coefficients, which are only based on arithmetic operations. various-implementations-of-collaborative-filtering\n",
        "\n",
        "Memory-based methods use user rating historical data to compute the similarity between users or items. The idea behind these methods is to define a similarity measure between users or items, and find the most similar to recommend unseen items. Building a memory based collaborative filtering recommender\n",
        "\n",
        "**Drawback**\n",
        "\n",
        "It's not scalable due to the sprasity of the data.\n",
        "We needs to construct the similarity matrix everytime the new user comes. (Hard to maintain, and operationalize)\n",
        "\n",
        "**Action**\n",
        "\n",
        "- The list result can be showed in the front-end application like \"Made for you\" -> Provide the list of recommended items.\n",
        "- The list result can be showed in the front-end application like \"Because you like item\" -> Provided the list of recommended items.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZQU_akPFSsft",
        "outputId": "8befbfb0-7a87-46b9-d81a-279165caff47"
      },
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# preprocess data\n",
        "row = ratings[USER_COL]\n",
        "col = ratings[ITEM_COL]\n",
        "data = ratings[RATING_COL]\n",
        "\n",
        "# init user-item matrix\n",
        "mat = csr_matrix((data, (row, col)), shape=(NUM_USERS, NUM_ITEMS))\n",
        "mat.eliminate_zeros()\n",
        "\n",
        "# calculate sparsity\n",
        "sparsity = float(len(mat.nonzero()[0]))\n",
        "sparsity /= (mat.shape[0] * mat.shape[1])\n",
        "sparsity *= 100\n",
        "print(f'Sparsity: {sparsity:4.2f}%. This means that {sparsity:4.2f}% of the user-item ratings have a value.')\n",
        "\n",
        "# compute similarity\n",
        "item_corr_mat = cosine_similarity(mat.T)\n",
        "\n",
        "# get top k item\n",
        "print(\"\\nThe top-k similar movie to item_id 99\")\n",
        "similar_items = top_k_items(name2ind['99'],\n",
        "                            top_k = 10,\n",
        "                            corr_mat = item_corr_mat,\n",
        "                            map_name = ind2name)\n",
        "\n",
        "display(items.loc[items[ITEM_COL].isin(similar_items)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sparsity: 0.35%. This means that 0.35% of the user-item ratings have a value.\n",
            "\n",
            "The top-k similar movie to item_id 99\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>248</td>\n",
              "      <td>Horror</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>352</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392</th>\n",
              "      <td>392</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507</th>\n",
              "      <td>507</td>\n",
              "      <td>Horror, Western</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570</th>\n",
              "      <td>570</td>\n",
              "      <td>Horror</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>730</th>\n",
              "      <td>730</td>\n",
              "      <td>Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>757</th>\n",
              "      <td>757</td>\n",
              "      <td>Romance, Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>824</th>\n",
              "      <td>824</td>\n",
              "      <td>Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>899</th>\n",
              "      <td>899</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    item_id             genres\n",
              "99       99    Romance, Action\n",
              "248     248             Horror\n",
              "352     352    Romance, Action\n",
              "392     392    Romance, Action\n",
              "507     507    Horror, Western\n",
              "570     570             Horror\n",
              "730     730            Fantasy\n",
              "757     757  Romance, Thriller\n",
              "824     824            Fantasy\n",
              "899     899             Comedy"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vbEOgthUOk1"
      },
      "source": [
        "Summary\n",
        "\n",
        "Now, we will get the different set of result from the content-based. The similaity between items has been calculated based on the \"User-behavior\" rather than the attributes of the items."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgfvmPF9UcKa"
      },
      "source": [
        "## 3.2 Model-based approach¶\n",
        "\n",
        "**Introduction**\n",
        "\n",
        "Model-based CF uses machine learning algorithms to predict users’ rating of unrated items. \n",
        "There are many model-based CF algorithms, the most commonly used are matrix factorization models such as to applying a SVD to reconstruct the rating matrix, latent Dirichlet allocation or Markov decision process based models. Building a memory based collaborative filtering recommender\n",
        "\n",
        "**Type**\n",
        "\n",
        "- Matrix Factorization (MF) based\n",
        "    1. TruncatedSVD (Sklearn)\n",
        "    2. Funk MF (Surprise)\n",
        "    3. Non negative MF (Surprise)\n",
        "- Deep learning MF based\n",
        "    1. Generalizaed MF (Keras)\n",
        "    2. Neural Collaborative filtering (Recommenders)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r6-BQeiVeD9"
      },
      "source": [
        "### 3.2.1 TrucatedSVD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iwNSoyueWX9U",
        "outputId": "d0ab8c8d-f10a-4504-87eb-0667b9955472"
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "epsilon = 1e-9\n",
        "n_latent_factors = 10\n",
        "\n",
        "# calculate item latent matrix\n",
        "item_svd = TruncatedSVD(n_components = n_latent_factors)\n",
        "item_features = item_svd.fit_transform(mat.transpose()) + epsilon\n",
        "\n",
        "# calculate user latent matrix\n",
        "user_svd = TruncatedSVD(n_components = n_latent_factors)\n",
        "user_features = user_svd.fit_transform(mat) + epsilon\n",
        "\n",
        "# compute similarity\n",
        "item_corr_mat = cosine_similarity(item_features)\n",
        "\n",
        "# get top k item\n",
        "print(\"\\nThe top-k similar movie to item_id 99\")\n",
        "similar_items = top_k_items(name2ind['99'],\n",
        "                            top_k = 10,\n",
        "                            corr_mat = item_corr_mat,\n",
        "                            map_name = ind2name)\n",
        "\n",
        "display(items.loc[items[ITEM_COL].isin(similar_items)])\n",
        "\n",
        "del user_features\n",
        "gc.collect();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "The top-k similar movie to item_id 99\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>75</td>\n",
              "      <td>Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>90</td>\n",
              "      <td>Action, Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>359</td>\n",
              "      <td>Horror, Mystery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>521</th>\n",
              "      <td>521</td>\n",
              "      <td>Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>568</td>\n",
              "      <td>Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>629</th>\n",
              "      <td>629</td>\n",
              "      <td>Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802</th>\n",
              "      <td>802</td>\n",
              "      <td>Mystery, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>832</th>\n",
              "      <td>832</td>\n",
              "      <td>Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>885</th>\n",
              "      <td>885</td>\n",
              "      <td>Romance</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    item_id           genres\n",
              "75       75          Romance\n",
              "90       90  Action, Fantasy\n",
              "99       99  Romance, Action\n",
              "359     359  Horror, Mystery\n",
              "521     521         Thriller\n",
              "568     568          Romance\n",
              "629     629         Thriller\n",
              "802     802  Mystery, Action\n",
              "832     832           Action\n",
              "885     885          Romance"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac5z421WWm1Q"
      },
      "source": [
        "Summary\n",
        "\n",
        "With this method, you can see that we can compute the similarity based on the specific number of latent factor.\n",
        "\n",
        "Now, the recommendation would be based on some latent factors that we cannot explain directly.\n",
        "But in mathematically speaking, it will be the top latent factor that minimize the loss between the Actual rating and Reconstructed rating.\n",
        "You can see that now we reduce the size of matrix compared to the one in memory-based approach. however, it's still not good enough approach because eventually when the user, or item size growing with the time.\n",
        "Soon it will reach the limitation of computation resouce as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loRUBhr8W3fk"
      },
      "source": [
        "### 3.2.2 Funk MF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "O4-ouJ27XXCm"
      },
      "source": [
        "!pip install scikit-surprise -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "L7Imga3WW6I_",
        "outputId": "dce2a867-82bd-4bee-ed05-2feee404755e"
      },
      "source": [
        "from surprise import SVD, accuracy\n",
        "from surprise import Dataset, Reader\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise.model_selection.split import train_test_split\n",
        "\n",
        "def pred2dict(predictions, top_k=None):\n",
        "    \n",
        "    rec_dict = defaultdict(list)\n",
        "    for user_id, item_id, actual_rating, pred_rating, _ in predictions:\n",
        "        rec_dict[user_id].append((item_id, pred_rating))        \n",
        "        \n",
        "    return rec_dict\n",
        "\n",
        "def get_top_k_recommendation(rec_dict, user_id, top_k, ind2name):\n",
        "    \n",
        "    pred_ratings = rec_dict[user_id]\n",
        "    # sort descendingly by pred_rating\n",
        "    pred_ratings = sorted(pred_ratings, key=lambda x: x[1], reverse=True)\n",
        "    pred_ratings = pred_ratings[:top_k]\n",
        "    recs = [ind2name[e[0]] for e in pred_ratings]\n",
        "    \n",
        "    return recs\n",
        "\n",
        "# prepare train and test sets\n",
        "reader = Reader(rating_scale=(1,10))\n",
        "data = Dataset.load_from_df(ratings, reader)\n",
        "train, test = train_test_split(data, test_size=.2, random_state=42)\n",
        "\n",
        "# init and fit the funk mf model\n",
        "algo = SVD(random_state = 42)\n",
        "algo.fit(train)\n",
        "pred = algo.test(test);\n",
        "\n",
        "# evaluation the test set\n",
        "accuracy.rmse(pred)\n",
        "\n",
        "# extract the item features from algo\n",
        "item_corr_mat = cosine_similarity(algo.qi)\n",
        "\n",
        "print(\"\\nThe top-k similar movie to item_id 99\")\n",
        "similar_items = top_k_items(name2ind['99'],\n",
        "                            top_k = 10,\n",
        "                            corr_mat = item_corr_mat,\n",
        "                            map_name = ind2name)\n",
        "\n",
        "display(items.loc[items[ITEM_COL].isin(similar_items)])\n",
        "\n",
        "del item_corr_mat\n",
        "gc.collect();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 2.6256\n",
            "\n",
            "The top-k similar movie to item_id 99\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>114</td>\n",
              "      <td>Thriller, Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>180</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>194</td>\n",
              "      <td>Mystery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>366</td>\n",
              "      <td>Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546</th>\n",
              "      <td>546</td>\n",
              "      <td>Action, Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>599</td>\n",
              "      <td>Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611</th>\n",
              "      <td>611</td>\n",
              "      <td>Drama, Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>771</th>\n",
              "      <td>771</td>\n",
              "      <td>Romance, Western</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>801</th>\n",
              "      <td>801</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    item_id             genres\n",
              "99       99    Romance, Action\n",
              "114     114  Thriller, Romance\n",
              "180     180             Comedy\n",
              "194     194            Mystery\n",
              "366     366             Action\n",
              "546     546   Action, Thriller\n",
              "599     599            Romance\n",
              "611     611      Drama, Comedy\n",
              "771     771   Romance, Western\n",
              "801     801              Drama"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlVYFT5LYB1m"
      },
      "source": [
        "Summary\n",
        "\n",
        "Here we use the Funk MF algorithms to create the latent factors matrix, and now we can build both the user-based, item-based recommendation.\n",
        "We also randomly split out some users from the train set into the test set for the validation purpose."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upcYlKRkXV2V"
      },
      "source": [
        "### 3.2.3 Deep learning MF - Generalized Matrix Factorization (MF)\n",
        "Usually, in the MF method, we tried to learn the user-item interaction or tried to reconstruct the predicted rating with the inner product of the shared lated features.\n",
        "\n",
        "Now, for the deep learning approach, we use the different internal engine which is the DNNs to estimate the user and item laten features. We estimate the shared latent feature minimizing the target loss function.\n",
        "\n",
        "After that, we used the fitted model to predict the pair of item that each customer have never watched to see what to recommend next.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KIxzJwaLaOHY"
      },
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets\n",
        "!pip install -q scann"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "givA5CGbaUD9",
        "outputId": "fbb5642d-7447-4f55-e622-8a61f9b5a2d5"
      },
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x  # this line is not required unless you are in a notebook`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "Y2zBc5j7Xrt1",
        "outputId": "eea1dd96-695a-4c69-d27f-3551420ee0d2"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_recommenders as tfrs\n",
        "import tensorflow.keras as keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from typing import Dict, Text, Tuple\n",
        "\n",
        "def df_to_ds(df):\n",
        "\n",
        "    # convert pd.DataFrame to tf.data.Dataset\n",
        "    ds = tf.data.Dataset.from_tensor_slices(\n",
        "        (dict(df[['user_id','item_id']]), df['rating']))\n",
        "    \n",
        "    # convert Tuple[Dict[Text, tf.Tensor], tf.Tensor] to Dict[Text, tf.Tensor]\n",
        "    ds = ds.map(lambda x, y: {\n",
        "    'user_id' : x['user_id'],\n",
        "    'item_id' : x['item_id'],\n",
        "    'rating' : y\n",
        "    })\n",
        "\n",
        "    return ds.batch(256)\n",
        "\n",
        "class RankingModel(keras.Model):\n",
        "\n",
        "    def __init__(self, user_id, item_id, embedding_size):\n",
        "        super().__init__()\n",
        "        \n",
        "        # user model\n",
        "        input = keras.Input(shape=(), dtype=tf.string)\n",
        "        x = keras.layers.StringLookup(\n",
        "            vocabulary = user_id, mask_token = None\n",
        "            )(input)\n",
        "        output = keras.layers.Embedding(\n",
        "            input_dim = len(user_id) + 1,\n",
        "            output_dim = embedding_size,\n",
        "            name = 'embedding'\n",
        "        )(x)\n",
        "        self.user_model = keras.Model(inputs = input,\n",
        "                                      outputs = output,\n",
        "                                      name = 'user_model')\n",
        "\n",
        "        # item model\n",
        "        input = keras.Input(shape=(), dtype=tf.string)\n",
        "        x = keras.layers.StringLookup(\n",
        "            vocabulary = item_id, mask_token = None\n",
        "            )(input)\n",
        "        output = keras.layers.Embedding(\n",
        "            input_dim = len(item_id) + 1,\n",
        "            output_dim = embedding_size,\n",
        "            name = 'embedding'\n",
        "        )(x)\n",
        "        self.item_model = keras.Model(inputs = input,\n",
        "                                  outputs = output,\n",
        "                                  name = 'item_model')\n",
        "\n",
        "        # rating model\n",
        "        user_input = keras.Input(shape=(embedding_size,), name='user_emb')\n",
        "        item_input = keras.Input(shape=(embedding_size,), name='item_emb')\n",
        "        x = keras.layers.Concatenate(axis=1)([user_input, item_input])\n",
        "        x = keras.layers.Dense(256, activation = 'relu')(x)\n",
        "        x = keras.layers.Dense(64, activation = 'relu')(x)\n",
        "        output = keras.layers.Dense(1)(x)\n",
        "        \n",
        "        self.rating_model = keras.Model(\n",
        "            inputs = {\n",
        "                'user_id' : user_input,\n",
        "                'item_id' : item_input\n",
        "            },\n",
        "            outputs = output,\n",
        "            name = 'rating_model'\n",
        "        )\n",
        "\n",
        "    def call(self, inputs: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
        "\n",
        "        user_emb = self.user_model(inputs['user_id'])\n",
        "        item_emb = self.item_model(inputs['item_id'])\n",
        "\n",
        "        prediction = self.rating_model({\n",
        "            'user_id' : user_emb,\n",
        "            'item_id' : item_emb\n",
        "        })\n",
        "        \n",
        "        return prediction\n",
        "\n",
        "class GMFModel(tfrs.models.Model):\n",
        "\n",
        "    def __init__(self, user_id, item_id, embedding_size):\n",
        "        super().__init__()\n",
        "        self.ranking_model = RankingModel(user_id, item_id, embedding_size)\n",
        "        self.task = tfrs.tasks.Ranking(\n",
        "            loss = keras.losses.MeanSquaredError(),\n",
        "            metrics = [keras.metrics.RootMeanSquaredError()]\n",
        "        )\n",
        "    \n",
        "    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
        "        \n",
        "        return self.ranking_model(\n",
        "            {\n",
        "             'user_id' : features['user_id'], \n",
        "             'item_id' : features['item_id']\n",
        "            })\n",
        "\n",
        "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "\n",
        "        return self.task(labels = features.pop('rating'),\n",
        "                         predictions = self.ranking_model(features))\n",
        "\n",
        "# preprocess\n",
        "train, test = train_test_split(ratings, train_size = .8, random_state=42)\n",
        "train, test = df_to_ds(train), df_to_ds(test)\n",
        "\n",
        "# # init model\n",
        "embedding_size = 64\n",
        "model = GMFModel(user_id.astype(str),\n",
        "                 item_id.astype(str),\n",
        "                 embedding_size)\n",
        "model.compile(\n",
        "    optimizer = keras.optimizers.Adagrad(learning_rate = .01)\n",
        ")\n",
        "\n",
        "# # fitting the model\n",
        "model.fit(train, epochs=3, verbose=0)\n",
        "\n",
        "# evaluate with the test data\n",
        "result = model.evaluate(test, return_dict=True, verbose=0)\n",
        "print(\"\\nEvaluation on the test set:\")\n",
        "display(result)\n",
        "\n",
        "# extract item embedding\n",
        "item_emb = model.ranking_model.item_model.layers[-1].get_weights()[0]\n",
        "\n",
        "\n",
        "item_corr_mat = cosine_similarity(item_emb)\n",
        "\n",
        "print(\"\\nThe top-k similar movie to item_id 99\")\n",
        "similar_items = top_k_items(name2ind['99'],\n",
        "                            top_k = 10,\n",
        "                            corr_mat = item_corr_mat,\n",
        "                            map_name = ind2name)\n",
        "\n",
        "display(items.loc[items[ITEM_COL].isin(similar_items)])\n",
        "\n",
        "del item_corr_mat\n",
        "gc.collect();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation on the test set:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'loss': 6.006824970245361,\n",
              " 'regularization_loss': 0,\n",
              " 'root_mean_squared_error': 2.5790839195251465,\n",
              " 'total_loss': 6.006824970245361}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The top-k similar movie to item_id 99\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>94</td>\n",
              "      <td>Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>Romance, Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>194</td>\n",
              "      <td>Mystery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>206</td>\n",
              "      <td>Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>228</td>\n",
              "      <td>Mystery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351</th>\n",
              "      <td>351</td>\n",
              "      <td>Action, Western</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404</th>\n",
              "      <td>404</td>\n",
              "      <td>Mystery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534</th>\n",
              "      <td>534</td>\n",
              "      <td>Action, Western</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541</th>\n",
              "      <td>541</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>994</th>\n",
              "      <td>994</td>\n",
              "      <td>Action</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    item_id           genres\n",
              "94       94         Thriller\n",
              "99       99  Romance, Action\n",
              "194     194          Mystery\n",
              "206     206          Romance\n",
              "228     228          Mystery\n",
              "351     351  Action, Western\n",
              "404     404          Mystery\n",
              "534     534  Action, Western\n",
              "541     541            Drama\n",
              "994     994           Action"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwZ9L81RmSW0"
      },
      "source": [
        "### 3.2.4 Deep learning MF - Neural Collaborative Filtering (NCF)\n",
        "\n",
        "Due to the library conflie, remove the implementation."
      ]
    }
  ]
}