{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lightgcn_pyg.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mequanent/Music-Recommendation-Exercises/blob/main/LightGCN%20using%20Pytorch%20Geometric.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: LightGCN with PyTorch Geometric from [Medium](https://medium.com/stanford-cs224w/lightgcn-with-pytorch-geometric-91bab836471e).\n",
        "\n",
        "@hhotta@stanford.edu"
      ],
      "metadata": {
        "id": "-HEi2gj_sPQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To install the correct version of Pytorch Geometric.\n",
        "# This cell is modified from: https://gist.github.com/ameya98/b193856171d11d37ada46458f60e73e7\n",
        "\n",
        "import torch\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "CUDA_version = torch.version.cuda\n",
        "\n",
        "TORCH = TORCH_version.split('+')[0]\n",
        "CUDA = 'cu' + CUDA_version.replace('.', '')\n",
        "\n",
        "!pip install -q torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-geometric "
      ],
      "metadata": {
        "id": "EGuLx-U-krHR",
        "outputId": "8858d55b-9aa0-4219-d5cc-4ce9074d47f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.9 MB 4.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 6.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 4.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 750 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 407 kB 5.3 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWkNAZvtNQ6R"
      },
      "source": [
        "# Implementing a Recommender System using LightGCN\n",
        "\n",
        "In this colab, we explain how to set up a graph recommender system using the [LighGCN](https://arxiv.org/abs/2002.02126) model. Specifically, we apply LightGCN to a movie recommendation task using [PyTorch](https://pytorch.org/) and [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/).\n",
        "\n",
        "We use the [MovieLens](https://grouplens.org/datasets/movielens/) (*small*) dataset which has 100,000 ratings applied to 9,000 movies by 600 users. \n",
        "\n",
        "Our implementation was inspired by the following documentation and repositories:\n",
        "- https://github.com/gusye1234/LightGCN-PyTorch\n",
        "- https://www.kaggle.com/dipanjandas96/lightgcn-pytorch-from-scratch\n",
        "- https://pytorch-geometric.readthedocs.io/en/latest/notes/load_csv.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OBSacx6Q03m"
      },
      "source": [
        "# import required modules\n",
        "from pathlib import Path\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing as prep\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim, Tensor\n",
        "\n",
        "from torch_sparse import SparseTensor, matmul\n",
        "\n",
        "from torch_geometric.utils import structured_negative_sampling\n",
        "from torch_geometric.data import download_url, extract_zip\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.typing import Adj"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mZ6-zPxPklE"
      },
      "source": [
        "# Loading the Dataset\n",
        "\n",
        "We load the dataset and set ratings >=4 on a 0.5 ~ 5 scale as an edge between users and movies.\n",
        "\n",
        "We split the edges of the graph using a 80/10/10 train/validation/test split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cRC_IazQ4Oj",
        "outputId": "fc471cf9-7c13-4582-a65a-d06ae931db49"
      },
      "source": [
        "# Movie\n",
        "# download the dataset\n",
        "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
        "extract_zip(download_url(url, '.'), '.')\n",
        "\n",
        "movie_path = './ml-latest-small/movies.csv'\n",
        "rating_path = './ml-latest-small/ratings.csv'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Extracting ./ml-latest-small.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Music\n",
        "metaurl = \"http://deepyeti.ucsd.edu/jianmo/amazon/metaFiles2/meta_Digital_Music.json.gz\"\n",
        "reviewurl = \"http://deepyeti.ucsd.edu/jianmo/amazon/categoryFiles/Digital_Music.json.gz\"\n",
        "ratingurl = \"http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Digital_Music.csv\"\n",
        "\n",
        "columns = ['movieId','userId','rating','timestamp']\n",
        "meta = pd.read_json(metaurl, lines = True)\n",
        "review = pd.read_json(reviewurl, lines = True)\n",
        "rating = pd.read_csv(ratingurl, names=columns, header = None)\n",
        "\n",
        "# Re-order the user and item columns\n",
        "columns = ['userId','movieId','rating','timestamp']\n",
        "rating = rating.reindex(columns=columns)\n",
        "rating.head(2)\n",
        "\n",
        "moviecols = ['movieId',\t'title',\t'genres'] # For music review"
      ],
      "metadata": {
        "id": "Gw2NNxgbv2tP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = rating[rating['rating']>4]\n",
        "df.shape"
      ],
      "metadata": {
        "id": "WUrz-DUGE_qM",
        "outputId": "615865ed-dcec-4c96-af77-bf7a6f2887d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1280147, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['userId'].value_counts().index.tolist())"
      ],
      "metadata": {
        "id": "AhdAnGvGKiEP",
        "outputId": "ea469a04-5ad5-449f-8b1a-fb5da4de31a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "713286"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#a = df['userId'].value_counts().index.tolist()[:-60000]\n",
        "a = df['userId'].value_counts().index.tolist()[48000:]\n",
        "df = df.loc[df['userId'].isin(a)]\n",
        "df.shape"
      ],
      "metadata": {
        "id": "T5PjX0AHIoWr",
        "outputId": "eb98bc4a-bbe0-4cb8-c6ce-c7ba7192c78b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(857275, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u = review.asin.unique().tolist()\n",
        "v = meta.asin.unique().tolist()\n",
        "n = df.movieId.unique().tolist()\n",
        "m = set(n).intersection(v, u)\n",
        "\n",
        "print(len(u), len(n), len(v), len(m))\n",
        "\n",
        "met = meta.loc[meta['asin'].isin(m)]\n",
        "rev = review.loc[review['asin'].isin(m)]\n",
        "rat = df.loc[rating['movieId'].isin(m)]"
      ],
      "metadata": {
        "id": "gf5E4Bj4Frt4",
        "outputId": "c5a03557-db51-4adc-dab5-520cab9ed86a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "456992 294140 66013 42791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Original\n",
        "u = review.asin.unique().tolist()\n",
        "v = meta.asin.unique().tolist()\n",
        "n = rating.movieId.unique().tolist()\n",
        "m = set(n).intersection(v, u)\n",
        "\n",
        "print(len(u), len(n), len(v), len(m))\n",
        "\n",
        "met = meta.loc[meta['asin'].isin(m)]\n",
        "rev = review.loc[review['asin'].isin(m)]\n",
        "rat = rating.loc[rating['movieId'].isin(m)]"
      ],
      "metadata": {
        "id": "I23sZpIbHSlV",
        "outputId": "27f4aa20-ab7f-4eab-9eda-9a0e73e1de42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "456992 456992 66013 66010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = rev[['asin']]\n",
        "b = met[['asin', 'title', 'brand']]\n",
        "a_b = pd.merge(a, b, on = 'asin', how = 'inner').drop_duplicates()\n",
        "a_b.rename(columns = {'asin': 'movieId', 'brand': 'genres'}, inplace = True) \n",
        "ratng = pd.merge(rat, a_b, on = 'movieId', how = 'inner')\n",
        "ratng = ratng[:100000]"
      ],
      "metadata": {
        "id": "UXNR9hohGDay"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratng.shape"
      ],
      "metadata": {
        "id": "0Y4BfBKEjmBm",
        "outputId": "e462b091-9333-4e54-b47e-a02a0c689208",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Original\n",
        "a = rev[['asin']]\n",
        "b = met[['asin', 'title', 'brand']]\n",
        "existing = ['asin'\t'title'\t'brand']\n",
        "a_b = pd.merge(a, b, on = 'asin', how = 'inner').drop_duplicates()\n",
        "#a_b[a_b['asin']=='B00NPZI1ZS']['title'].values[0]\n",
        "a_b.rename(columns = {'asin': 'movieId', 'brand': 'genres'}, inplace = True) \n",
        "# ['movieId',\t'title',\t'genres']\n",
        "ratng = pd.merge(rat, a_b, on = 'movieId', how = 'inner')\n",
        "ratng"
      ],
      "metadata": {
        "id": "4xJYOXYq3t4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "leu = prep.LabelEncoder() # ['userId','movieId','rating','timestamp']\n",
        "lem = prep.LabelEncoder()\n",
        "\n",
        "ratng['movieId'] = leu.fit_transform(ratng['movieId'].values)\n",
        "ratng['userId'] = lem.fit_transform(ratng['userId'].values)\n",
        "ratng.head(2)"
      ],
      "metadata": {
        "id": "dJhfhHmbbkTK",
        "outputId": "de72316f-4502-4a47-c3ef-556b572a7510",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId  movieId  rating   timestamp                          title  \\\n",
              "0   23808        1     5.0  1387670400  So You Wanna Go Back to Egypt   \n",
              "1   76028        1     5.0  1378857600  So You Wanna Go Back to Egypt   \n",
              "\n",
              "        genres  \n",
              "0  Keith Green  \n",
              "1  Keith Green  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67bc061e-1f62-484c-8fc9-8002681b9e8c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23808</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1387670400</td>\n",
              "      <td>So You Wanna Go Back to Egypt</td>\n",
              "      <td>Keith Green</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>76028</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1378857600</td>\n",
              "      <td>So You Wanna Go Back to Egypt</td>\n",
              "      <td>Keith Green</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67bc061e-1f62-484c-8fc9-8002681b9e8c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-67bc061e-1f62-484c-8fc9-8002681b9e8c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-67bc061e-1f62-484c-8fc9-8002681b9e8c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = ratng[['userId', 'movieId',\t'rating',\t'timestamp'\t]]\n",
        "movie = ratng[['movieId',\t'title',\t'genres'\t]].drop_duplicates()"
      ],
      "metadata": {
        "id": "Vg6i_1sdh5AO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie"
      ],
      "metadata": {
        "id": "4OCKoldlqUeF",
        "outputId": "4f088815-3b5e-4767-f06e-e76591ac5ce6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       movieId                                              title  \\\n",
              "0            1                      So You Wanna Go Back to Egypt   \n",
              "20           2                          Early Works - Dallas Holm   \n",
              "62           3                        Early Works - Don Francisco   \n",
              "90           0                       Master Collection Volume One   \n",
              "126          8                     The Lord's Supper / Be Exalted   \n",
              "...        ...                                                ...   \n",
              "99995    42740             Ya Svecha A-Shema by Katya Kapelnikova   \n",
              "99996    42743  The Best Of Sentimental Seventies by New Seeke...   \n",
              "99997    42741  Bach: Toccatas &amp; Fugues BWV 538, 540, 564 ...   \n",
              "99998    42742                              Synapse by Spacelords   \n",
              "99999    42744  Time Out - Stereo &amp; Mono Versions (2CD) De...   \n",
              "\n",
              "                    genres  \n",
              "0              Keith Green  \n",
              "20             Dallas Holm  \n",
              "62           Don Francisco  \n",
              "90     John Michael Talbot  \n",
              "126    John Michael Talbot  \n",
              "...                    ...  \n",
              "99995    Katya Kapelnikova  \n",
              "99996                       \n",
              "99997          Andre Isoir  \n",
              "99998                       \n",
              "99999                       \n",
              "\n",
              "[42745 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a7e0f35-02d5-4191-8864-bf534d100c5a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>So You Wanna Go Back to Egypt</td>\n",
              "      <td>Keith Green</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2</td>\n",
              "      <td>Early Works - Dallas Holm</td>\n",
              "      <td>Dallas Holm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>3</td>\n",
              "      <td>Early Works - Don Francisco</td>\n",
              "      <td>Don Francisco</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>0</td>\n",
              "      <td>Master Collection Volume One</td>\n",
              "      <td>John Michael Talbot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>8</td>\n",
              "      <td>The Lord's Supper / Be Exalted</td>\n",
              "      <td>John Michael Talbot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>42740</td>\n",
              "      <td>Ya Svecha A-Shema by Katya Kapelnikova</td>\n",
              "      <td>Katya Kapelnikova</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>42743</td>\n",
              "      <td>The Best Of Sentimental Seventies by New Seeke...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>42741</td>\n",
              "      <td>Bach: Toccatas &amp;amp; Fugues BWV 538, 540, 564 ...</td>\n",
              "      <td>Andre Isoir</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>42742</td>\n",
              "      <td>Synapse by Spacelords</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>42744</td>\n",
              "      <td>Time Out - Stereo &amp;amp; Mono Versions (2CD) De...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>42745 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a7e0f35-02d5-4191-8864-bf534d100c5a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a7e0f35-02d5-4191-8864-bf534d100c5a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a7e0f35-02d5-4191-8864-bf534d100c5a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#path = Path('/content/drive/MyDrive/Colab Notebooks/') \n",
        "path = Path('./ml-latest-small/')\n",
        "movie_file = path/'movie.csv'\n",
        "rating_file = path/'rating.csv'\n",
        "\n",
        "#movie.to_csv(movie_file,columns = ['movieId',\t'title',\t'genres'], index=False)#  sep=' ')\n",
        "movie.to_csv(movie_file, index=False)\n",
        "ratings.to_csv(rating_file, index=False)\n",
        "#ratings.to_csv(rating_file, columns = ['userId',\t'movieId',\t'rating',\t'timestamp'])#, sep=' ')\n",
        "#np.savetxt(movie_file, movie, fmt='%s')\n",
        "#np.savetxt(rating_file, ratings, fmt='%s')"
      ],
      "metadata": {
        "id": "vVD-GitQOonp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_path = './ml-latest-small/movie.csv'\n",
        "rating_path = './ml-latest-small/rating.csv'"
      ],
      "metadata": {
        "id": "cMGO9I8EaCPf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = pd.read_csv(movie_path)\n",
        "r.head(2)"
      ],
      "metadata": {
        "id": "BAR03PlVrs3p",
        "outputId": "26299936-9276-4c1a-9cfd-d30d0296d5f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   movieId                          title       genres\n",
              "0        1  So You Wanna Go Back to Egypt  Keith Green\n",
              "1        2      Early Works - Dallas Holm  Dallas Holm"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80393131-c5dd-4d76-8c2c-b1f5a96fc086\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>So You Wanna Go Back to Egypt</td>\n",
              "      <td>Keith Green</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Early Works - Dallas Holm</td>\n",
              "      <td>Dallas Holm</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80393131-c5dd-4d76-8c2c-b1f5a96fc086')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-80393131-c5dd-4d76-8c2c-b1f5a96fc086 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-80393131-c5dd-4d76-8c2c-b1f5a96fc086');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4lKu660qE4e3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2P3zYR8Q8EX"
      },
      "source": [
        "# load user and movie nodes\n",
        "def load_node_csv(path, index_col):\n",
        "    \"\"\"Loads csv containing node information\n",
        "\n",
        "    Args:\n",
        "        path (str): path to csv file\n",
        "        index_col (str): column name of index column\n",
        "\n",
        "    Returns:\n",
        "        dict: mapping of csv row to node id\n",
        "    \"\"\" \n",
        "    df = pd.read_csv(path, index_col=index_col)\n",
        "    mapping = {index: i for i, index in enumerate(df.index.unique())}\n",
        "    return mapping\n",
        "\n",
        "\n",
        "user_mapping = load_node_csv(rating_path, index_col='userId')\n",
        "movie_mapping = load_node_csv(movie_path, index_col='movieId')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkJzQlxSRDEq"
      },
      "source": [
        "# load edges between users and movies\n",
        "def load_edge_csv(path, src_index_col, src_mapping, dst_index_col, dst_mapping, link_index_col, rating_threshold=4):\n",
        "    \"\"\"Loads csv containing edges between users and items\n",
        "\n",
        "    Args:\n",
        "        path (str): path to csv file\n",
        "        src_index_col (str): column name of users\n",
        "        src_mapping (dict): mapping between row number and user id\n",
        "        dst_index_col (str): column name of items\n",
        "        dst_mapping (dict): mapping between row number and item id\n",
        "        link_index_col (str): column name of user item interaction\n",
        "        rating_threshold (int, optional): Threshold to determine positivity of edge. Defaults to 4.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: 2 by N matrix containing the node ids of N user-item edges\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path)\n",
        "    edge_index = None\n",
        "    src = [src_mapping[index] for index in df[src_index_col]]\n",
        "    dst = [dst_mapping[index] for index in df[dst_index_col]]\n",
        "    edge_attr = torch.from_numpy(df[link_index_col].values).view(-1, 1).to(torch.long) >= rating_threshold\n",
        "\n",
        "\n",
        "    edge_index = [[], []]\n",
        "    for i in range(edge_attr.shape[0]):\n",
        "        if edge_attr[i]:\n",
        "            edge_index[0].append(src[i])\n",
        "            edge_index[1].append(dst[i])\n",
        "\n",
        "    return torch.tensor(edge_index)\n",
        "\n",
        "\n",
        "edge_index = load_edge_csv(\n",
        "    rating_path,\n",
        "    src_index_col='userId',\n",
        "    src_mapping=user_mapping,\n",
        "    dst_index_col='movieId',\n",
        "    dst_mapping=movie_mapping,\n",
        "    link_index_col='rating',\n",
        "    rating_threshold=4,\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIueYZfaT6_H"
      },
      "source": [
        "# split the edges of the graph using a 80/10/10 train/validation/test split\n",
        "num_users, num_movies = len(user_mapping), len(movie_mapping)\n",
        "num_interactions = edge_index.shape[1]\n",
        "all_indices = [i for i in range(num_interactions)]\n",
        "\n",
        "train_indices, test_indices = train_test_split(\n",
        "    all_indices, test_size=0.2, random_state=1)\n",
        "val_indices, test_indices = train_test_split(\n",
        "    test_indices, test_size=0.5, random_state=1)\n",
        "\n",
        "train_edge_index = edge_index[:, train_indices]\n",
        "val_edge_index = edge_index[:, val_indices]\n",
        "test_edge_index = edge_index[:, test_indices]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5yKILBJUAN6"
      },
      "source": [
        "# convert edge indices into Sparse Tensors: https://pytorch-geometric.readthedocs.io/en/latest/notes/sparse_tensor.html\n",
        "train_sparse_edge_index = SparseTensor(row=train_edge_index[0], col=train_edge_index[1], sparse_sizes=(\n",
        "    num_users + num_movies, num_users + num_movies))\n",
        "val_sparse_edge_index = SparseTensor(row=val_edge_index[0], col=val_edge_index[1], sparse_sizes=(\n",
        "    num_users + num_movies, num_users + num_movies))\n",
        "test_sparse_edge_index = SparseTensor(row=test_edge_index[0], col=test_edge_index[1], sparse_sizes=(\n",
        "    num_users + num_movies, num_users + num_movies))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqKI1VduKcwf"
      },
      "source": [
        "# function which random samples a mini-batch of positive and negative samples\n",
        "def sample_mini_batch(batch_size, edge_index):\n",
        "    \"\"\"Randomly samples indices of a minibatch given an adjacency matrix\n",
        "\n",
        "    Args:\n",
        "        batch_size (int): minibatch size\n",
        "        edge_index (torch.Tensor): 2 by N list of edges\n",
        "\n",
        "    Returns:\n",
        "        tuple: user indices, positive item indices, negative item indices\n",
        "    \"\"\"\n",
        "    edges = structured_negative_sampling(edge_index)\n",
        "    edges = torch.stack(edges, dim=0)\n",
        "    indices = random.choices(\n",
        "        [i for i in range(edges[0].shape[0])], k=batch_size)\n",
        "    batch = edges[:, indices]\n",
        "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
        "    return user_indices, pos_item_indices, neg_item_indices"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOB5kDmtUrUY"
      },
      "source": [
        "# Implementing LightGCN\n",
        "\n",
        "## Light Graph Convolution\n",
        "Between each layer, LightGCN uses the following propagation rule for user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "e_u^{(k+1)} = \\sum_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|}\\sqrt{|N_i|}} e_i^{(k)} \\quad e_i^{(k+1)} = \\sum_{u \\in N_i} \\frac{1}{\\sqrt{|N_i|}\\sqrt{|N_u|}} e_u^{(k)}\n",
        "\\end{equation}\n",
        "\n",
        "$N_u$: the set of all neighbors of user $u$ (items liked by $u$)\n",
        "\n",
        "$N_i$: the set of all neighbors of item $i$ (users who liked $i$)\n",
        "\n",
        "$e_u^{(k)}$ : k-th layer user embedding\n",
        "\n",
        "$e_i^{(k)}$ : k-th layer item embedding\n",
        "\n",
        "\n",
        "\n",
        "## Layer Combination and Model Prediction\n",
        "The only trainable parameters of LightGCN are the 0-th layer embeddings $e_u^{(0)}$ and $e_i^{(0)}$ for each user and item. We combine the embeddings obtained at each layer of propagation to form the final embeddings for all user and item, $e_u$ and $e_i$ via the follwing equation.\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "e_u = \\sum_{k = 0}^K \\alpha_k e_u^{(k)} \\quad e_i = \\sum_{k = 0}^K \\alpha_k e_i^{(k)}\n",
        "\\end{equation}\n",
        "\n",
        "$\\alpha_k$ : hyperparameter which weights the contribution of the k-th layer embedding to the final embedding\n",
        "\n",
        "The model prediction is obtained by taking the inner product of the final user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{y}_{ui} = e_u^Te_i\n",
        "\\end{equation}\n",
        "\n",
        "## Matrix Form\n",
        "In our implementation, we utilize the matrix form of LightGCN. We perform multi-scale diffusion to obtain the final embedding, which sums embeddings diffused across multi-hop scales. \n",
        "\n",
        "\\begin{equation}\n",
        "E^{(K)} = \\alpha_0 E^{(0)} + \\alpha_1 \\tilde{A}^1 E^{(0)} + \\alpha_2 \\tilde{A}^2 E^{(0)} + \\cdot \\cdot \\cdot + \\alpha_K \\tilde{A}^K \\tilde{A} E^{(0)}\n",
        "\\end{equation}\n",
        "\n",
        "$E^{(0)} \\in \\mathcal{R}^{(M + N)} \\times T$ : stacked initial item and user embeddings where $M$, $N$, and $T$ denote the number of users, number of items, and the dimension of each embedding respectively\n",
        "\n",
        "$\\tilde{A} = D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$ : symmetrically normalized adjacency matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9GvYg9ehDOX"
      },
      "source": [
        "# defines LightGCN model\n",
        "class LightGCN(MessagePassing):\n",
        "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_users, num_items, embedding_dim=64, K=3, add_self_loops=False):\n",
        "        \"\"\"Initializes LightGCN Model\n",
        "\n",
        "        Args:\n",
        "            num_users (int): Number of users\n",
        "            num_items (int): Number of items\n",
        "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
        "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
        "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_users, self.num_items = num_users, num_items\n",
        "        self.embedding_dim, self.K = embedding_dim, K\n",
        "        self.add_self_loops = add_self_loops\n",
        "\n",
        "        self.users_emb = nn.Embedding(\n",
        "            num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n",
        "        self.items_emb = nn.Embedding(\n",
        "            num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n",
        "\n",
        "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
        "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
        "\n",
        "    def forward(self, edge_index: SparseTensor):\n",
        "        \"\"\"Forward propagation of LightGCN Model.\n",
        "\n",
        "        Args:\n",
        "            edge_index (SparseTensor): adjacency matrix\n",
        "\n",
        "        Returns:\n",
        "            tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
        "        \"\"\"\n",
        "        # compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
        "        edge_index_norm = gcn_norm(\n",
        "            edge_index, add_self_loops=self.add_self_loops)\n",
        "\n",
        "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
        "        embs = [emb_0]\n",
        "        emb_k = emb_0\n",
        "\n",
        "        # multi-scale diffusion\n",
        "        for i in range(self.K):\n",
        "            emb_k = self.propagate(edge_index_norm, x=emb_k)\n",
        "            embs.append(emb_k)\n",
        "\n",
        "        embs = torch.stack(embs, dim=1)\n",
        "        emb_final = torch.mean(embs, dim=1) # E^K\n",
        "\n",
        "        users_emb_final, items_emb_final = torch.split(\n",
        "            emb_final, [self.num_users, self.num_items]) # splits into e_u^K and e_i^K\n",
        "\n",
        "        # returns e_u^K, e_u^0, e_i^K, e_i^0\n",
        "        return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
        "\n",
        "    def message(self, x_j: Tensor) -> Tensor:\n",
        "        return x_j\n",
        "\n",
        "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
        "        # computes \\tilde{A} @ x\n",
        "        return matmul(adj_t, x)\n",
        "\n",
        "model = LightGCN(num_users, num_movies)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My8eqloiBccE"
      },
      "source": [
        "# Loss Function\n",
        "\n",
        "\n",
        "\n",
        "We utilize a Bayesian Personalized Ranking (BPR) loss, a pairwise objective which encourages the predictions of positive samples to be higher than negative samples for each user.\n",
        "\n",
        "\\begin{equation}\n",
        "L_{BPR} = -\\sum_{u = 1}^M \\sum_{i \\in N_u} \\sum_{j \\notin N_u} \\ln{\\sigma(\\hat{y}_{ui} - \\hat{y}_{uj})} + \\lambda ||E^{(0)}||^2 \n",
        "\\end{equation}\n",
        "\n",
        "$\\hat{y}_{u}$: predicted score of a positive sample\n",
        "\n",
        "$\\hat{y}_{uj}$: predicted score of a negative sample\n",
        "\n",
        "$\\lambda$: hyperparameter which controls the L2 regularization strength"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmPs1xS-BYfe"
      },
      "source": [
        "def bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, lambda_val):\n",
        "    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n",
        "\n",
        "    Args:\n",
        "        users_emb_final (torch.Tensor): e_u_k\n",
        "        users_emb_0 (torch.Tensor): e_u_0\n",
        "        pos_items_emb_final (torch.Tensor): positive e_i_k\n",
        "        pos_items_emb_0 (torch.Tensor): positive e_i_0\n",
        "        neg_items_emb_final (torch.Tensor): negative e_i_k\n",
        "        neg_items_emb_0 (torch.Tensor): negative e_i_0\n",
        "        lambda_val (float): lambda value for regularization loss term\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: scalar bpr loss value\n",
        "    \"\"\"\n",
        "    reg_loss = lambda_val * (users_emb_0.norm(2).pow(2) +\n",
        "                             pos_items_emb_0.norm(2).pow(2) +\n",
        "                             neg_items_emb_0.norm(2).pow(2)) # L2 loss\n",
        "\n",
        "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
        "    pos_scores = torch.sum(pos_scores, dim=-1) # predicted scores of positive samples\n",
        "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
        "    neg_scores = torch.sum(neg_scores, dim=-1) # predicted scores of negative samples\n",
        "\n",
        "    loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores)) + reg_loss\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS7HVr3qLQGx"
      },
      "source": [
        "# Evaluation Metrics\n",
        "\n",
        "We evalaluate our model using the following metrics\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{Recall} = \\frac{TP}{TP + FP}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{Precision} = \\frac{TP}{TP + FN}\n",
        "\\end{equation}\n",
        "\n",
        "**Dicounted Cumulative Gain (DCG)** at rank position p is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{DCG}_\\text{p} = \\sum_{i = 1}^p \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
        "\\end{equation}\n",
        "\n",
        "p: a particular rank position\n",
        "\n",
        "$rel_i \\in \\{0, 1\\}$ : graded relevance of the result at position $i$\n",
        "\n",
        "**Idealised Dicounted Cumulative Gain (IDCG)**, namely the maximum possible DCG, at rank position $p$ is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{IDCG}_\\text{p} = \\sum_{i = 1}^{|REL_p|} \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
        "\\end{equation}\n",
        "\n",
        "$|REL_p|$ : list of items ordered by their relevance up to position p\n",
        "\n",
        "**Normalized Dicounted Cumulative Gain (NDCG)** at rank position $p$ is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{nDCG}_\\text{p} = \\frac{\\text{DCG}_p}{\\text{nDCG}_p}\n",
        "\\end{equation}\n",
        "\n",
        "Specifically, we use the metrics recall@K, precision@K, and NDCG@K. @K indicates that these metrics are computed on the top K recommendations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHO2gdhRSwzJ"
      },
      "source": [
        "# helper function to get N_u\n",
        "def get_user_positive_items(edge_index):\n",
        "    \"\"\"Generates dictionary of positive items for each user\n",
        "\n",
        "    Args:\n",
        "        edge_index (torch.Tensor): 2 by N list of edges\n",
        "\n",
        "    Returns:\n",
        "        dict: dictionary of positive items for each user\n",
        "    \"\"\"\n",
        "    user_pos_items = {}\n",
        "    for i in range(edge_index.shape[1]):\n",
        "        user = edge_index[0][i].item()\n",
        "        item = edge_index[1][i].item()\n",
        "        if user not in user_pos_items:\n",
        "            user_pos_items[user] = []\n",
        "        user_pos_items[user].append(item)\n",
        "    return user_pos_items"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8We4BTtfS4NV"
      },
      "source": [
        "# computes recall@K and precision@K\n",
        "def RecallPrecision_ATk(groundTruth, r, k):\n",
        "    \"\"\"Computers recall @ k and precision @ k\n",
        "\n",
        "    Args:\n",
        "        groundTruth (list): list of lists containing highly rated items of each user\n",
        "        r (list): list of lists indicating whether each top k item recommended to each user\n",
        "            is a top k ground truth item or not\n",
        "        k (intg): determines the top k items to compute precision and recall on\n",
        "\n",
        "    Returns:\n",
        "        tuple: recall @ k, precision @ k\n",
        "    \"\"\"\n",
        "    num_correct_pred = torch.sum(r, dim=-1)  # number of correctly predicted items per user\n",
        "    # number of items liked by each user in the test set\n",
        "    user_num_liked = torch.Tensor([len(groundTruth[i])\n",
        "                                  for i in range(len(groundTruth))])\n",
        "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
        "    precision = torch.mean(num_correct_pred) / k\n",
        "    return recall.item(), precision.item()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v4A3Ek4TE02"
      },
      "source": [
        "# computes NDCG@K\n",
        "def NDCGatK_r(groundTruth, r, k):\n",
        "    \"\"\"Computes Normalized Discounted Cumulative Gain (NDCG) @ k\n",
        "\n",
        "    Args:\n",
        "        groundTruth (list): list of lists containing highly rated items of each user\n",
        "        r (list): list of lists indicating whether each top k item recommended to each user\n",
        "            is a top k ground truth item or not\n",
        "        k (int): determines the top k items to compute ndcg on\n",
        "\n",
        "    Returns:\n",
        "        float: ndcg @ k\n",
        "    \"\"\"\n",
        "    assert len(r) == len(groundTruth)\n",
        "\n",
        "    test_matrix = torch.zeros((len(r), k))\n",
        "\n",
        "    for i, items in enumerate(groundTruth):\n",
        "        length = min(len(items), k)\n",
        "        test_matrix[i, :length] = 1\n",
        "    max_r = test_matrix\n",
        "    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)), axis=1)\n",
        "    dcg = r * (1. / torch.log2(torch.arange(2, k + 2)))\n",
        "    dcg = torch.sum(dcg, axis=1)\n",
        "    idcg[idcg == 0.] = 1.\n",
        "    ndcg = dcg / idcg\n",
        "    ndcg[torch.isnan(ndcg)] = 0.\n",
        "    return torch.mean(ndcg).item()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6_741LlTMwI"
      },
      "source": [
        "# wrapper function to get evaluation metrics\n",
        "def get_metrics(model, edge_index, exclude_edge_indices, k):\n",
        "    \"\"\"Computes the evaluation metrics: recall, precision, and ndcg @ k\n",
        "\n",
        "    Args:\n",
        "        model (LighGCN): lightgcn model\n",
        "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
        "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
        "        k (int): determines the top k items to compute metrics on\n",
        "\n",
        "    Returns:\n",
        "        tuple: recall @ k, precision @ k, ndcg @ k\n",
        "    \"\"\"\n",
        "    user_embedding = model.users_emb.weight\n",
        "    item_embedding = model.items_emb.weight\n",
        "\n",
        "    # get ratings between every user and item - shape is num users x num movies\n",
        "    rating = torch.matmul(user_embedding, item_embedding.T)\n",
        "\n",
        "    for exclude_edge_index in exclude_edge_indices:\n",
        "        # gets all the positive items for each user from the edge index\n",
        "        user_pos_items = get_user_positive_items(exclude_edge_index)\n",
        "        # get coordinates of all edges to exclude\n",
        "        exclude_users = []\n",
        "        exclude_items = []\n",
        "        for user, items in user_pos_items.items():\n",
        "            exclude_users.extend([user] * len(items))\n",
        "            exclude_items.extend(items)\n",
        "\n",
        "        # set ratings of excluded edges to large negative value\n",
        "        rating[exclude_users, exclude_items] = -(1 << 10)\n",
        "\n",
        "    # get the top k recommended items for each user\n",
        "    _, top_K_items = torch.topk(rating, k=k)\n",
        "\n",
        "    # get all unique users in evaluated split\n",
        "    users = edge_index[0].unique()\n",
        "\n",
        "    test_user_pos_items = get_user_positive_items(edge_index)\n",
        "\n",
        "    # convert test user pos items dictionary into a list\n",
        "    test_user_pos_items_list = [\n",
        "        test_user_pos_items[user.item()] for user in users]\n",
        "\n",
        "    # determine the correctness of topk predictions\n",
        "    r = []\n",
        "    for user in users:\n",
        "        ground_truth_items = test_user_pos_items[user.item()]\n",
        "        label = list(map(lambda x: x in ground_truth_items, top_K_items[user]))\n",
        "        r.append(label)\n",
        "    r = torch.Tensor(np.array(r).astype('float'))\n",
        "\n",
        "    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n",
        "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
        "\n",
        "    return recall, precision, ndcg"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr_qESXASsVw"
      },
      "source": [
        "# wrapper function to evaluate model\n",
        "def evaluation(model, edge_index, sparse_edge_index, exclude_edge_indices, k, lambda_val):\n",
        "    \"\"\"Evaluates model loss and metrics including recall, precision, ndcg @ k\n",
        "\n",
        "    Args:\n",
        "        model (LighGCN): lightgcn model\n",
        "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
        "        sparse_edge_index (sparseTensor): sparse adjacency matrix for split to evaluate\n",
        "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
        "        k (int): determines the top k items to compute metrics on\n",
        "        lambda_val (float): determines lambda for bpr loss\n",
        "\n",
        "    Returns:\n",
        "        tuple: bpr loss, recall @ k, precision @ k, ndcg @ k\n",
        "    \"\"\"\n",
        "    # get embeddings\n",
        "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
        "        sparse_edge_index)\n",
        "    edges = structured_negative_sampling(\n",
        "        edge_index, contains_neg_self_loops=False)\n",
        "    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
        "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
        "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
        "        pos_item_indices], items_emb_0[pos_item_indices]\n",
        "    print(\"items_emb_final\", items_emb_final)\n",
        "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
        "        neg_item_indices], items_emb_0[neg_item_indices]\n",
        "\n",
        "    loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0,\n",
        "                    neg_items_emb_final, neg_items_emb_0, lambda_val).item()\n",
        "\n",
        "    recall, precision, ndcg = get_metrics(\n",
        "        model, edge_index, exclude_edge_indices, k)\n",
        "\n",
        "    return loss, recall, precision, ndcg"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYw1cUgPTjws"
      },
      "source": [
        "# Training\n",
        "\n",
        "Your test set performance should be in line with the following (*K=20*):\n",
        "\n",
        "*Recall@K: 0.13, Precision@K: 0.045, NDCG@K: 0.10*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQL2W-NQTeFd"
      },
      "source": [
        "# define constants\n",
        "ITERATIONS = 10000\n",
        "#ITERATIONS = 100\n",
        "BATCH_SIZE = 1024\n",
        "LR = 1e-3\n",
        "ITERS_PER_EVAL = 200\n",
        "ITERS_PER_LR_DECAY = 200\n",
        "#ITERS_PER_EVAL = 5\n",
        "#ITERS_PER_LR_DECAY = 5\n",
        "K = 20\n",
        "LAMBDA = 1e-6"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49JDkBtKTfE-",
        "outputId": "a8b4117a-3d4d-46af-9ddd-fdb1975aaa5f"
      },
      "source": [
        "# setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device {device}.\")\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "edge_index = edge_index.to(device)\n",
        "train_edge_index = train_edge_index.to(device)\n",
        "train_sparse_edge_index = train_sparse_edge_index.to(device)\n",
        "\n",
        "val_edge_index = val_edge_index.to(device)\n",
        "val_sparse_edge_index = val_sparse_edge_index.to(device)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device cpu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYjrDp1w-hiP",
        "outputId": "980f3ecc-9aef-454d-b7e5-bb202bcb6a66"
      },
      "source": [
        "# training loop\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "neg_items_emb_final2 = neg_items_emb_02 = items_emb_final2 = neg_item_indices2 = items_emb_02 = []\n",
        "\n",
        "for iter in range(ITERATIONS):\n",
        "    # forward propagation\n",
        "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
        "        train_sparse_edge_index)\n",
        "\n",
        "    # mini batching\n",
        "    user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(\n",
        "        BATCH_SIZE, train_edge_index)\n",
        "    user_indices, pos_item_indices, neg_item_indices = user_indices.to(\n",
        "        device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
        "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
        "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
        "        pos_item_indices], items_emb_0[pos_item_indices]\n",
        "\n",
        "    items_emb_final2, items_emb_02, neg_item_indices2 = items_emb_final, items_emb_0, neg_item_indices \n",
        "    #neg_item_indices2 = neg_item_indices\n",
        "\n",
        "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
        "        neg_item_indices], items_emb_0[neg_item_indices]\n",
        "    \n",
        "    neg_items_emb_final2, neg_items_emb_02 = neg_items_emb_final, neg_items_emb_0\n",
        "    # loss computation\n",
        "    train_loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final,\n",
        "                          pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, LAMBDA)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if iter % ITERS_PER_EVAL == 0:\n",
        "        model.eval()\n",
        "        val_loss, recall, precision, ndcg = evaluation(\n",
        "            model, val_edge_index, val_sparse_edge_index, [train_edge_index], K, LAMBDA)\n",
        "        print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\")\n",
        "        train_losses.append(train_loss.item())\n",
        "        val_losses.append(val_loss)\n",
        "        model.train()\n",
        "\n",
        "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
        "        scheduler.step()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "items_emb_final tensor([[ 0.0236,  0.0077, -0.0432,  ...,  0.0097,  0.0372, -0.0033],\n",
            "        [ 0.0167,  0.0109, -0.0047,  ..., -0.0651, -0.0016, -0.0293],\n",
            "        [ 0.0074,  0.0211,  0.0187,  ..., -0.0265, -0.0075, -0.0317],\n",
            "        ...,\n",
            "        [ 0.0104,  0.0200, -0.0284,  ..., -0.0008,  0.0092, -0.0143],\n",
            "        [ 0.0341, -0.0064, -0.0177,  ..., -0.0460,  0.0537,  0.0059],\n",
            "        [-0.0361, -0.0180, -0.0231,  ..., -0.0094, -0.0001,  0.0348]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 0/10000] train_loss: -0.69094, val_loss: -0.6838, val_recall@20: 0.00219, val_precision@20: 0.0009, val_ndcg@20: 0.00122\n",
            "items_emb_final tensor([[ 0.0100, -0.0223, -0.0117,  ..., -0.0025,  0.0541, -0.0299],\n",
            "        [ 0.0093, -0.0036,  0.0121,  ..., -0.0640,  0.0095, -0.0215],\n",
            "        [ 0.0117,  0.0064,  0.0236,  ..., -0.0286, -0.0017, -0.0388],\n",
            "        ...,\n",
            "        [ 0.0167,  0.0234, -0.0338,  ...,  0.0013,  0.0084, -0.0119],\n",
            "        [ 0.0325, -0.0006, -0.0175,  ..., -0.0476,  0.0483,  0.0065],\n",
            "        [-0.0434, -0.0253, -0.0257,  ..., -0.0118, -0.0053,  0.0240]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 200/10000] train_loss: -0.70029, val_loss: -0.69, val_recall@20: 0.05167, val_precision@20: 0.01745, val_ndcg@20: 0.0356\n",
            "items_emb_final tensor([[-0.0671, -0.1006,  0.0666,  ..., -0.0818,  0.1348, -0.1052],\n",
            "        [-0.0471, -0.0607,  0.0672,  ..., -0.1200,  0.0663, -0.0723],\n",
            "        [-0.0171, -0.0334,  0.0579,  ..., -0.0634,  0.0336, -0.0751],\n",
            "        ...,\n",
            "        [ 0.0364,  0.0479, -0.0547,  ...,  0.0246, -0.0144,  0.0083],\n",
            "        [ 0.0450,  0.0139, -0.0315,  ..., -0.0352,  0.0362,  0.0164],\n",
            "        [-0.0359, -0.0220, -0.0353,  ..., -0.0050, -0.0161,  0.0288]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 400/10000] train_loss: -0.88609, val_loss: -0.83544, val_recall@20: 0.13996, val_precision@20: 0.04222, val_ndcg@20: 0.10063\n",
            "items_emb_final tensor([[-0.1558, -0.1836,  0.1503,  ..., -0.1678,  0.2206, -0.1930],\n",
            "        [-0.1133, -0.1224,  0.1300,  ..., -0.1836,  0.1306, -0.1365],\n",
            "        [-0.0450, -0.0612,  0.0843,  ..., -0.0911,  0.0599, -0.1034],\n",
            "        ...,\n",
            "        [ 0.0662,  0.0742, -0.0826,  ...,  0.0535, -0.0436,  0.0381],\n",
            "        [ 0.0668,  0.0340, -0.0521,  ..., -0.0145,  0.0153,  0.0386],\n",
            "        [-0.0186, -0.0060, -0.0560,  ...,  0.0148, -0.0373,  0.0469]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 600/10000] train_loss: -1.86289, val_loss: -1.5515, val_recall@20: 0.14777, val_precision@20: 0.04512, val_ndcg@20: 0.10547\n",
            "items_emb_final tensor([[-0.2282, -0.2535,  0.2203,  ..., -0.2387,  0.2916, -0.2649],\n",
            "        [-0.1654, -0.1726,  0.1805,  ..., -0.2345,  0.1811, -0.1871],\n",
            "        [-0.0762, -0.0929,  0.1145,  ..., -0.1224,  0.0907, -0.1349],\n",
            "        ...,\n",
            "        [ 0.0830,  0.0900, -0.0985,  ...,  0.0700, -0.0602,  0.0544],\n",
            "        [ 0.0871,  0.0533, -0.0709,  ...,  0.0046, -0.0046,  0.0583],\n",
            "        [-0.0022,  0.0089, -0.0734,  ...,  0.0326, -0.0557,  0.0637]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 800/10000] train_loss: -3.42595, val_loss: -2.90425, val_recall@20: 0.1487, val_precision@20: 0.04503, val_ndcg@20: 0.10634\n",
            "items_emb_final tensor([[-0.2885, -0.3124,  0.2794,  ..., -0.2982,  0.3511, -0.3251],\n",
            "        [-0.2075, -0.2139,  0.2217,  ..., -0.2760,  0.2229, -0.2294],\n",
            "        [-0.1166, -0.1329,  0.1541,  ..., -0.1623,  0.1306, -0.1751],\n",
            "        ...,\n",
            "        [ 0.1063,  0.1127, -0.1210,  ...,  0.0926, -0.0833,  0.0781],\n",
            "        [ 0.1112,  0.0764, -0.0944,  ...,  0.0281, -0.0282,  0.0822],\n",
            "        [ 0.0144,  0.0253, -0.0917,  ...,  0.0496, -0.0732,  0.0805]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 1000/10000] train_loss: -5.52287, val_loss: -4.60147, val_recall@20: 0.15096, val_precision@20: 0.04584, val_ndcg@20: 0.10772\n",
            "items_emb_final tensor([[-0.3397, -0.3629,  0.3300,  ..., -0.3491,  0.4019, -0.3764],\n",
            "        [-0.2462, -0.2519,  0.2596,  ..., -0.3146,  0.2610, -0.2678],\n",
            "        [-0.1389, -0.1550,  0.1761,  ..., -0.1843,  0.1527, -0.1973],\n",
            "        ...,\n",
            "        [ 0.1207,  0.1267, -0.1351,  ...,  0.1066, -0.0971,  0.0923],\n",
            "        [ 0.1327,  0.0979, -0.1155,  ...,  0.0493, -0.0496,  0.1036],\n",
            "        [ 0.0351,  0.0457, -0.1123,  ...,  0.0703, -0.0943,  0.1015]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 1200/10000] train_loss: -7.65181, val_loss: -6.4137, val_recall@20: 0.15183, val_precision@20: 0.04521, val_ndcg@20: 0.10657\n",
            "items_emb_final tensor([[-0.3877, -0.4102,  0.3773,  ..., -0.3967,  0.4494, -0.4243],\n",
            "        [-0.2832, -0.2884,  0.2963,  ..., -0.3514,  0.2979, -0.3049],\n",
            "        [-0.1560, -0.1722,  0.1934,  ..., -0.2015,  0.1699, -0.2146],\n",
            "        ...,\n",
            "        [ 0.1353,  0.1408, -0.1496,  ...,  0.1212, -0.1112,  0.1068],\n",
            "        [ 0.1517,  0.1169, -0.1346,  ...,  0.0686, -0.0687,  0.1226],\n",
            "        [ 0.0529,  0.0629, -0.1297,  ...,  0.0878, -0.1118,  0.1190]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 1400/10000] train_loss: -10.29765, val_loss: -8.2883, val_recall@20: 0.15325, val_precision@20: 0.04548, val_ndcg@20: 0.10758\n",
            "items_emb_final tensor([[-0.4309, -0.4530,  0.4200,  ..., -0.4396,  0.4924, -0.4673],\n",
            "        [-0.3137, -0.3186,  0.3265,  ..., -0.3818,  0.3283, -0.3354],\n",
            "        [-0.1796, -0.1953,  0.2165,  ..., -0.2245,  0.1932, -0.2379],\n",
            "        ...,\n",
            "        [ 0.1478,  0.1533, -0.1622,  ...,  0.1333, -0.1237,  0.1194],\n",
            "        [ 0.1669,  0.1322, -0.1499,  ...,  0.0838, -0.0840,  0.1378],\n",
            "        [ 0.0586,  0.0686, -0.1355,  ...,  0.0936, -0.1176,  0.1249]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 1600/10000] train_loss: -12.76477, val_loss: -10.25429, val_recall@20: 0.15311, val_precision@20: 0.04575, val_ndcg@20: 0.10775\n",
            "items_emb_final tensor([[-0.4727, -0.4943,  0.4616,  ..., -0.4811,  0.5340, -0.5089],\n",
            "        [-0.3426, -0.3471,  0.3551,  ..., -0.4105,  0.3569, -0.3641],\n",
            "        [-0.2004, -0.2161,  0.2371,  ..., -0.2450,  0.2138, -0.2586],\n",
            "        ...,\n",
            "        [ 0.1601,  0.1655, -0.1748,  ...,  0.1456, -0.1362,  0.1318],\n",
            "        [ 0.1799,  0.1452, -0.1628,  ...,  0.0968, -0.0969,  0.1508],\n",
            "        [ 0.0654,  0.0751, -0.1429,  ...,  0.1006, -0.1250,  0.1318]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 1800/10000] train_loss: -14.62305, val_loss: -12.18685, val_recall@20: 0.15206, val_precision@20: 0.04575, val_ndcg@20: 0.10753\n",
            "items_emb_final tensor([[-0.5113, -0.5326,  0.4998,  ..., -0.5195,  0.5723, -0.5473],\n",
            "        [-0.3739, -0.3783,  0.3863,  ..., -0.4418,  0.3882, -0.3955],\n",
            "        [-0.2102, -0.2259,  0.2467,  ..., -0.2547,  0.2235, -0.2684],\n",
            "        ...,\n",
            "        [ 0.1772,  0.1825, -0.1916,  ...,  0.1626, -0.1532,  0.1487],\n",
            "        [ 0.1871,  0.1521, -0.1698,  ...,  0.1039, -0.1039,  0.1578],\n",
            "        [ 0.0757,  0.0853, -0.1532,  ...,  0.1109, -0.1353,  0.1420]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 2000/10000] train_loss: -17.62463, val_loss: -14.2077, val_recall@20: 0.15368, val_precision@20: 0.04629, val_ndcg@20: 0.10834\n",
            "items_emb_final tensor([[-0.5436, -0.5647,  0.5321,  ..., -0.5517,  0.6045, -0.5796],\n",
            "        [-0.3981, -0.4023,  0.4103,  ..., -0.4659,  0.4122, -0.4195],\n",
            "        [-0.2215, -0.2372,  0.2579,  ..., -0.2659,  0.2347, -0.2797],\n",
            "        ...,\n",
            "        [ 0.1902,  0.1955, -0.2047,  ...,  0.1757, -0.1664,  0.1617],\n",
            "        [ 0.1944,  0.1595, -0.1772,  ...,  0.1112, -0.1112,  0.1654],\n",
            "        [ 0.0843,  0.0938, -0.1620,  ...,  0.1197, -0.1442,  0.1506]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 2200/10000] train_loss: -19.52638, val_loss: -16.13138, val_recall@20: 0.15408, val_precision@20: 0.04638, val_ndcg@20: 0.10865\n",
            "items_emb_final tensor([[-0.5759, -0.5969,  0.5643,  ..., -0.5839,  0.6368, -0.6118],\n",
            "        [-0.4206, -0.4247,  0.4327,  ..., -0.4884,  0.4347, -0.4420],\n",
            "        [-0.2371, -0.2528,  0.2734,  ..., -0.2815,  0.2503, -0.2954],\n",
            "        ...,\n",
            "        [ 0.1994,  0.2047, -0.2138,  ...,  0.1849, -0.1756,  0.1709],\n",
            "        [ 0.2030,  0.1681, -0.1858,  ...,  0.1197, -0.1198,  0.1740],\n",
            "        [ 0.0953,  0.1047, -0.1731,  ...,  0.1309, -0.1553,  0.1615]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 2400/10000] train_loss: -22.69383, val_loss: -17.89569, val_recall@20: 0.15299, val_precision@20: 0.04593, val_ndcg@20: 0.10816\n",
            "items_emb_final tensor([[-0.6073, -0.6281,  0.5956,  ..., -0.6152,  0.6681, -0.6432],\n",
            "        [-0.4431, -0.4471,  0.4551,  ..., -0.5108,  0.4571, -0.4644],\n",
            "        [-0.2506, -0.2663,  0.2869,  ..., -0.2949,  0.2637, -0.3088],\n",
            "        ...,\n",
            "        [ 0.2085,  0.2137, -0.2228,  ...,  0.1939, -0.1846,  0.1799],\n",
            "        [ 0.2132,  0.1782, -0.1959,  ...,  0.1300, -0.1300,  0.1842],\n",
            "        [ 0.1040,  0.1133, -0.1821,  ...,  0.1398, -0.1643,  0.1703]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 2600/10000] train_loss: -23.56925, val_loss: -19.94868, val_recall@20: 0.15356, val_precision@20: 0.0462, val_ndcg@20: 0.10823\n",
            "items_emb_final tensor([[-0.6322, -0.6528,  0.6203,  ..., -0.6399,  0.6928, -0.6680],\n",
            "        [-0.4651, -0.4689,  0.4770,  ..., -0.5327,  0.4790, -0.4863],\n",
            "        [-0.2621, -0.2776,  0.2981,  ..., -0.3062,  0.2751, -0.3202],\n",
            "        ...,\n",
            "        [ 0.2200,  0.2250, -0.2342,  ...,  0.2052, -0.1960,  0.1914],\n",
            "        [ 0.2257,  0.1905, -0.2083,  ...,  0.1425, -0.1424,  0.1966],\n",
            "        [ 0.1106,  0.1199, -0.1890,  ...,  0.1466, -0.1711,  0.1770]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 2800/10000] train_loss: -27.40034, val_loss: -22.06235, val_recall@20: 0.15293, val_precision@20: 0.04611, val_ndcg@20: 0.10796\n",
            "items_emb_final tensor([[-0.6591, -0.6797,  0.6472,  ..., -0.6669,  0.7197, -0.6950],\n",
            "        [-0.4835, -0.4872,  0.4953,  ..., -0.5511,  0.4973, -0.5047],\n",
            "        [-0.2719, -0.2875,  0.3080,  ..., -0.3161,  0.2851, -0.3301],\n",
            "        ...,\n",
            "        [ 0.2284,  0.2335, -0.2427,  ...,  0.2137, -0.2045,  0.1999],\n",
            "        [ 0.2354,  0.2001, -0.2179,  ...,  0.1521, -0.1521,  0.2063],\n",
            "        [ 0.1242,  0.1335, -0.2026,  ...,  0.1603, -0.1849,  0.1906]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 3000/10000] train_loss: -27.46251, val_loss: -23.71014, val_recall@20: 0.15294, val_precision@20: 0.0462, val_ndcg@20: 0.10821\n",
            "items_emb_final tensor([[-0.6846, -0.7051,  0.6726,  ..., -0.6923,  0.7452, -0.7205],\n",
            "        [-0.5027, -0.5065,  0.5145,  ..., -0.5703,  0.5166, -0.5240],\n",
            "        [-0.2808, -0.2965,  0.3170,  ..., -0.3251,  0.2940, -0.3391],\n",
            "        ...,\n",
            "        [ 0.2370,  0.2420, -0.2513,  ...,  0.2223, -0.2131,  0.2086],\n",
            "        [ 0.2418,  0.2065, -0.2243,  ...,  0.1585, -0.1585,  0.2127],\n",
            "        [ 0.1308,  0.1401, -0.2094,  ...,  0.1670, -0.1916,  0.1973]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 3200/10000] train_loss: -31.83695, val_loss: -25.64082, val_recall@20: 0.1536, val_precision@20: 0.0462, val_ndcg@20: 0.10838\n",
            "items_emb_final tensor([[-0.7076, -0.7280,  0.6955,  ..., -0.7152,  0.7680, -0.7434],\n",
            "        [-0.5193, -0.5231,  0.5311,  ..., -0.5869,  0.5332, -0.5406],\n",
            "        [-0.2904, -0.3061,  0.3266,  ..., -0.3347,  0.3036, -0.3487],\n",
            "        ...,\n",
            "        [ 0.2455,  0.2505, -0.2599,  ...,  0.2308, -0.2216,  0.2170],\n",
            "        [ 0.2514,  0.2159, -0.2338,  ...,  0.1680, -0.1679,  0.2222],\n",
            "        [ 0.1384,  0.1476, -0.2170,  ...,  0.1746, -0.1993,  0.2049]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 3400/10000] train_loss: -31.59576, val_loss: -26.99333, val_recall@20: 0.15321, val_precision@20: 0.04629, val_ndcg@20: 0.10834\n",
            "items_emb_final tensor([[-0.7277, -0.7481,  0.7156,  ..., -0.7353,  0.7882, -0.7635],\n",
            "        [-0.5349, -0.5386,  0.5466,  ..., -0.6025,  0.5488, -0.5562],\n",
            "        [-0.3001, -0.3158,  0.3362,  ..., -0.3443,  0.3132, -0.3584],\n",
            "        ...,\n",
            "        [ 0.2529,  0.2579, -0.2672,  ...,  0.2382, -0.2291,  0.2245],\n",
            "        [ 0.2582,  0.2228, -0.2405,  ...,  0.1748, -0.1747,  0.2290],\n",
            "        [ 0.1449,  0.1541, -0.2235,  ...,  0.1812, -0.2058,  0.2115]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 3600/10000] train_loss: -35.56142, val_loss: -28.92831, val_recall@20: 0.1534, val_precision@20: 0.04638, val_ndcg@20: 0.10823\n",
            "items_emb_final tensor([[-0.7481, -0.7683,  0.7359,  ..., -0.7556,  0.8085, -0.7838],\n",
            "        [-0.5497, -0.5534,  0.5614,  ..., -0.6172,  0.5635, -0.5710],\n",
            "        [-0.3076, -0.3233,  0.3437,  ..., -0.3519,  0.3208, -0.3660],\n",
            "        ...,\n",
            "        [ 0.2581,  0.2631, -0.2725,  ...,  0.2434, -0.2343,  0.2297],\n",
            "        [ 0.2627,  0.2274, -0.2450,  ...,  0.1793, -0.1792,  0.2335],\n",
            "        [ 0.1516,  0.1606, -0.2301,  ...,  0.1879, -0.2125,  0.2181]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 3800/10000] train_loss: -37.40523, val_loss: -30.59818, val_recall@20: 0.15403, val_precision@20: 0.04656, val_ndcg@20: 0.10863\n",
            "items_emb_final tensor([[-0.7664, -0.7867,  0.7543,  ..., -0.7740,  0.8269, -0.8022],\n",
            "        [-0.5632, -0.5669,  0.5749,  ..., -0.6308,  0.5771, -0.5845],\n",
            "        [-0.3169, -0.3327,  0.3530,  ..., -0.3611,  0.3301, -0.3753],\n",
            "        ...,\n",
            "        [ 0.2644,  0.2695, -0.2789,  ...,  0.2498, -0.2407,  0.2361],\n",
            "        [ 0.2675,  0.2321, -0.2498,  ...,  0.1841, -0.1840,  0.2384],\n",
            "        [ 0.1559,  0.1649, -0.2344,  ...,  0.1922, -0.2169,  0.2225]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 4000/10000] train_loss: -39.26976, val_loss: -32.24901, val_recall@20: 0.15385, val_precision@20: 0.04647, val_ndcg@20: 0.10861\n",
            "items_emb_final tensor([[-0.7833, -0.8035,  0.7711,  ..., -0.7908,  0.8437, -0.8190],\n",
            "        [-0.5769, -0.5805,  0.5885,  ..., -0.6444,  0.5907, -0.5981],\n",
            "        [-0.3230, -0.3388,  0.3591,  ..., -0.3673,  0.3362, -0.3814],\n",
            "        ...,\n",
            "        [ 0.2690,  0.2740, -0.2834,  ...,  0.2544, -0.2453,  0.2407],\n",
            "        [ 0.2737,  0.2383, -0.2559,  ...,  0.1903, -0.1902,  0.2446],\n",
            "        [ 0.1597,  0.1686, -0.2382,  ...,  0.1960, -0.2206,  0.2262]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 4200/10000] train_loss: -41.18998, val_loss: -33.54197, val_recall@20: 0.15393, val_precision@20: 0.04647, val_ndcg@20: 0.10859\n",
            "items_emb_final tensor([[-0.8007, -0.8208,  0.7884,  ..., -0.8081,  0.8611, -0.8364],\n",
            "        [-0.5894, -0.5931,  0.6010,  ..., -0.6570,  0.6033, -0.6107],\n",
            "        [-0.3297, -0.3455,  0.3657,  ..., -0.3739,  0.3429, -0.3881],\n",
            "        ...,\n",
            "        [ 0.2740,  0.2790, -0.2884,  ...,  0.2594, -0.2503,  0.2457],\n",
            "        [ 0.2798,  0.2444, -0.2620,  ...,  0.1963, -0.1963,  0.2506],\n",
            "        [ 0.1641,  0.1730, -0.2427,  ...,  0.2005, -0.2251,  0.2307]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 4400/10000] train_loss: -42.6713, val_loss: -35.24812, val_recall@20: 0.15362, val_precision@20: 0.04629, val_ndcg@20: 0.10846\n",
            "items_emb_final tensor([[-0.8169, -0.8371,  0.8047,  ..., -0.8244,  0.8773, -0.8527],\n",
            "        [-0.6008, -0.6045,  0.6125,  ..., -0.6684,  0.6147, -0.6221],\n",
            "        [-0.3358, -0.3517,  0.3718,  ..., -0.3801,  0.3490, -0.3943],\n",
            "        ...,\n",
            "        [ 0.2813,  0.2862, -0.2956,  ...,  0.2666, -0.2576,  0.2529],\n",
            "        [ 0.2851,  0.2497, -0.2673,  ...,  0.2016, -0.2017,  0.2560],\n",
            "        [ 0.1685,  0.1774, -0.2472,  ...,  0.2049, -0.2296,  0.2351]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 4600/10000] train_loss: -44.29283, val_loss: -36.44839, val_recall@20: 0.15334, val_precision@20: 0.04629, val_ndcg@20: 0.10861\n",
            "items_emb_final tensor([[-0.8318, -0.8519,  0.8195,  ..., -0.8392,  0.8921, -0.8675],\n",
            "        [-0.6115, -0.6151,  0.6231,  ..., -0.6790,  0.6254, -0.6327],\n",
            "        [-0.3410, -0.3569,  0.3771,  ..., -0.3853,  0.3543, -0.3995],\n",
            "        ...,\n",
            "        [ 0.2857,  0.2906, -0.3000,  ...,  0.2710, -0.2619,  0.2573],\n",
            "        [ 0.2915,  0.2561, -0.2737,  ...,  0.2080, -0.2080,  0.2623],\n",
            "        [ 0.1730,  0.1819, -0.2516,  ...,  0.2094, -0.2341,  0.2395]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 4800/10000] train_loss: -44.57549, val_loss: -37.85974, val_recall@20: 0.15395, val_precision@20: 0.04629, val_ndcg@20: 0.10849\n",
            "items_emb_final tensor([[-0.8457, -0.8658,  0.8334,  ..., -0.8531,  0.9061, -0.8815],\n",
            "        [-0.6233, -0.6270,  0.6350,  ..., -0.6909,  0.6372, -0.6446],\n",
            "        [-0.3463, -0.3622,  0.3823,  ..., -0.3906,  0.3595, -0.4048],\n",
            "        ...,\n",
            "        [ 0.2919,  0.2969, -0.3063,  ...,  0.2773, -0.2682,  0.2636],\n",
            "        [ 0.2972,  0.2618, -0.2794,  ...,  0.2138, -0.2138,  0.2680],\n",
            "        [ 0.1771,  0.1860, -0.2558,  ...,  0.2135, -0.2383,  0.2437]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 5000/10000] train_loss: -47.90051, val_loss: -39.49327, val_recall@20: 0.15445, val_precision@20: 0.04675, val_ndcg@20: 0.10865\n",
            "items_emb_final tensor([[-0.8581, -0.8782,  0.8458,  ..., -0.8655,  0.9184, -0.8939],\n",
            "        [-0.6330, -0.6366,  0.6446,  ..., -0.7005,  0.6468, -0.6542],\n",
            "        [-0.3512, -0.3671,  0.3872,  ..., -0.3955,  0.3644, -0.4097],\n",
            "        ...,\n",
            "        [ 0.2959,  0.3009, -0.3103,  ...,  0.2812, -0.2722,  0.2675],\n",
            "        [ 0.3012,  0.2658, -0.2833,  ...,  0.2177, -0.2178,  0.2720],\n",
            "        [ 0.1827,  0.1915, -0.2614,  ...,  0.2191, -0.2439,  0.2493]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 5200/10000] train_loss: -48.93916, val_loss: -40.09566, val_recall@20: 0.15427, val_precision@20: 0.04665, val_ndcg@20: 0.10882\n",
            "items_emb_final tensor([[-0.8701, -0.8902,  0.8578,  ..., -0.8775,  0.9305, -0.9059],\n",
            "        [-0.6426, -0.6463,  0.6542,  ..., -0.7102,  0.6565, -0.6638],\n",
            "        [-0.3561, -0.3721,  0.3921,  ..., -0.4004,  0.3693, -0.4146],\n",
            "        ...,\n",
            "        [ 0.2985,  0.3036, -0.3129,  ...,  0.2839, -0.2749,  0.2702],\n",
            "        [ 0.3069,  0.2715, -0.2891,  ...,  0.2235, -0.2235,  0.2778],\n",
            "        [ 0.1851,  0.1938, -0.2639,  ...,  0.2215, -0.2463,  0.2516]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 5400/10000] train_loss: -49.99365, val_loss: -41.56292, val_recall@20: 0.15427, val_precision@20: 0.04665, val_ndcg@20: 0.10899\n",
            "items_emb_final tensor([[-0.8811, -0.9012,  0.8688,  ..., -0.8885,  0.9415, -0.9169],\n",
            "        [-0.6512, -0.6549,  0.6628,  ..., -0.7188,  0.6651, -0.6725],\n",
            "        [-0.3623, -0.3783,  0.3983,  ..., -0.4065,  0.3755, -0.4208],\n",
            "        ...,\n",
            "        [ 0.3021,  0.3071, -0.3165,  ...,  0.2874, -0.2784,  0.2737],\n",
            "        [ 0.3104,  0.2750, -0.2926,  ...,  0.2270, -0.2270,  0.2813],\n",
            "        [ 0.1883,  0.1970, -0.2672,  ...,  0.2248, -0.2496,  0.2548]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 5600/10000] train_loss: -55.22674, val_loss: -42.76534, val_recall@20: 0.15427, val_precision@20: 0.04665, val_ndcg@20: 0.10874\n",
            "items_emb_final tensor([[-0.8917, -0.9118,  0.8793,  ..., -0.8991,  0.9520, -0.9275],\n",
            "        [-0.6588, -0.6624,  0.6704,  ..., -0.7263,  0.6727, -0.6800],\n",
            "        [-0.3660, -0.3820,  0.4019,  ..., -0.4103,  0.3792, -0.4245],\n",
            "        ...,\n",
            "        [ 0.3053,  0.3103, -0.3197,  ...,  0.2906, -0.2816,  0.2769],\n",
            "        [ 0.3137,  0.2782, -0.2958,  ...,  0.2302, -0.2302,  0.2845],\n",
            "        [ 0.1898,  0.1986, -0.2687,  ...,  0.2263, -0.2512,  0.2564]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 5800/10000] train_loss: -53.23901, val_loss: -43.93924, val_recall@20: 0.1543, val_precision@20: 0.04656, val_ndcg@20: 0.10869\n",
            "items_emb_final tensor([[-0.9025, -0.9226,  0.8902,  ..., -0.9099,  0.9629, -0.9383],\n",
            "        [-0.6664, -0.6701,  0.6780,  ..., -0.7340,  0.6803, -0.6877],\n",
            "        [-0.3705, -0.3865,  0.4064,  ..., -0.4148,  0.3837, -0.4290],\n",
            "        ...,\n",
            "        [ 0.3088,  0.3138, -0.3232,  ...,  0.2941, -0.2851,  0.2804],\n",
            "        [ 0.3185,  0.2831, -0.3007,  ...,  0.2351, -0.2351,  0.2894],\n",
            "        [ 0.1935,  0.2022, -0.2724,  ...,  0.2300, -0.2549,  0.2600]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 6000/10000] train_loss: -55.01349, val_loss: -44.25325, val_recall@20: 0.15463, val_precision@20: 0.04675, val_ndcg@20: 0.10883\n",
            "items_emb_final tensor([[-0.9126, -0.9326,  0.9002,  ..., -0.9200,  0.9729, -0.9483],\n",
            "        [-0.6734, -0.6770,  0.6850,  ..., -0.7410,  0.6873, -0.6946],\n",
            "        [-0.3745, -0.3905,  0.4104,  ..., -0.4187,  0.3877, -0.4330],\n",
            "        ...,\n",
            "        [ 0.3124,  0.3174, -0.3267,  ...,  0.2977, -0.2887,  0.2841],\n",
            "        [ 0.3215,  0.2861, -0.3037,  ...,  0.2380, -0.2381,  0.2924],\n",
            "        [ 0.1969,  0.2056, -0.2759,  ...,  0.2335, -0.2583,  0.2635]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 6200/10000] train_loss: -56.90883, val_loss: -45.89462, val_recall@20: 0.15455, val_precision@20: 0.04665, val_ndcg@20: 0.10854\n",
            "items_emb_final tensor([[-0.9225, -0.9426,  0.9101,  ..., -0.9299,  0.9828, -0.9583],\n",
            "        [-0.6801, -0.6838,  0.6917,  ..., -0.7477,  0.6940, -0.7013],\n",
            "        [-0.3784, -0.3944,  0.4143,  ..., -0.4226,  0.3916, -0.4369],\n",
            "        ...,\n",
            "        [ 0.3155,  0.3205, -0.3298,  ...,  0.3009, -0.2918,  0.2871],\n",
            "        [ 0.3236,  0.2881, -0.3057,  ...,  0.2401, -0.2401,  0.2944],\n",
            "        [ 0.1996,  0.2082, -0.2786,  ...,  0.2361, -0.2610,  0.2662]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 6400/10000] train_loss: -55.40331, val_loss: -46.87012, val_recall@20: 0.15443, val_precision@20: 0.04647, val_ndcg@20: 0.10841\n",
            "items_emb_final tensor([[-0.9314, -0.9514,  0.9190,  ..., -0.9388,  0.9917, -0.9672],\n",
            "        [-0.6875, -0.6912,  0.6991,  ..., -0.7551,  0.7014, -0.7087],\n",
            "        [-0.3824, -0.3985,  0.4184,  ..., -0.4267,  0.3956, -0.4410],\n",
            "        ...,\n",
            "        [ 0.3199,  0.3249, -0.3342,  ...,  0.3052, -0.2962,  0.2915],\n",
            "        [ 0.3256,  0.2901, -0.3077,  ...,  0.2421, -0.2421,  0.2964],\n",
            "        [ 0.2006,  0.2093, -0.2797,  ...,  0.2372, -0.2621,  0.2672]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 6600/10000] train_loss: -59.25153, val_loss: -46.78319, val_recall@20: 0.15466, val_precision@20: 0.04665, val_ndcg@20: 0.10871\n",
            "items_emb_final tensor([[-0.9396, -0.9597,  0.9272,  ..., -0.9470,  0.9999, -0.9754],\n",
            "        [-0.6933, -0.6970,  0.7049,  ..., -0.7609,  0.7072, -0.7145],\n",
            "        [-0.3868, -0.4029,  0.4227,  ..., -0.4311,  0.4000, -0.4453],\n",
            "        ...,\n",
            "        [ 0.3228,  0.3278, -0.3371,  ...,  0.3082, -0.2992,  0.2945],\n",
            "        [ 0.3305,  0.2951, -0.3127,  ...,  0.2470, -0.2470,  0.3013],\n",
            "        [ 0.2030,  0.2116, -0.2821,  ...,  0.2396, -0.2645,  0.2696]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 6800/10000] train_loss: -60.16494, val_loss: -47.6665, val_recall@20: 0.15448, val_precision@20: 0.04665, val_ndcg@20: 0.10881\n",
            "items_emb_final tensor([[-0.9481, -0.9681,  0.9357,  ..., -0.9555,  1.0084, -0.9838],\n",
            "        [-0.6992, -0.7029,  0.7108,  ..., -0.7668,  0.7131, -0.7204],\n",
            "        [-0.3901, -0.4062,  0.4260,  ..., -0.4344,  0.4033, -0.4487],\n",
            "        ...,\n",
            "        [ 0.3254,  0.3303, -0.3397,  ...,  0.3107, -0.3017,  0.2970],\n",
            "        [ 0.3327,  0.2973, -0.3149,  ...,  0.2492, -0.2492,  0.3035],\n",
            "        [ 0.2048,  0.2135, -0.2840,  ...,  0.2414, -0.2664,  0.2714]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 7000/10000] train_loss: -61.47345, val_loss: -49.09681, val_recall@20: 0.15448, val_precision@20: 0.04665, val_ndcg@20: 0.10882\n",
            "items_emb_final tensor([[-0.9558, -0.9758,  0.9434,  ..., -0.9632,  1.0161, -0.9915],\n",
            "        [-0.7040, -0.7077,  0.7155,  ..., -0.7716,  0.7179, -0.7252],\n",
            "        [-0.3923, -0.4084,  0.4282,  ..., -0.4366,  0.4055, -0.4509],\n",
            "        ...,\n",
            "        [ 0.3290,  0.3339, -0.3433,  ...,  0.3143, -0.3053,  0.3006],\n",
            "        [ 0.3353,  0.2999, -0.3175,  ...,  0.2518, -0.2518,  0.3061],\n",
            "        [ 0.2069,  0.2155, -0.2861,  ...,  0.2435, -0.2685,  0.2735]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 7200/10000] train_loss: -60.40928, val_loss: -50.04899, val_recall@20: 0.15439, val_precision@20: 0.04656, val_ndcg@20: 0.10877\n",
            "items_emb_final tensor([[-0.9631, -0.9831,  0.9507,  ..., -0.9705,  1.0234, -0.9988],\n",
            "        [-0.7091, -0.7127,  0.7206,  ..., -0.7766,  0.7229, -0.7302],\n",
            "        [-0.3960, -0.4121,  0.4319,  ..., -0.4402,  0.4092, -0.4545],\n",
            "        ...,\n",
            "        [ 0.3304,  0.3354, -0.3447,  ...,  0.3158, -0.3068,  0.3021],\n",
            "        [ 0.3371,  0.3017, -0.3193,  ...,  0.2536, -0.2536,  0.3079],\n",
            "        [ 0.2081,  0.2168, -0.2873,  ...,  0.2448, -0.2698,  0.2748]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 7400/10000] train_loss: -62.83176, val_loss: -50.73801, val_recall@20: 0.15439, val_precision@20: 0.04656, val_ndcg@20: 0.10865\n",
            "items_emb_final tensor([[-0.9695, -0.9895,  0.9571,  ..., -0.9768,  1.0298, -1.0052],\n",
            "        [-0.7136, -0.7172,  0.7251,  ..., -0.7811,  0.7274, -0.7348],\n",
            "        [-0.3987, -0.4148,  0.4346,  ..., -0.4429,  0.4119, -0.4572],\n",
            "        ...,\n",
            "        [ 0.3322,  0.3372, -0.3465,  ...,  0.3176, -0.3086,  0.3039],\n",
            "        [ 0.3398,  0.3044, -0.3220,  ...,  0.2564, -0.2564,  0.3107],\n",
            "        [ 0.2101,  0.2188, -0.2894,  ...,  0.2468, -0.2718,  0.2768]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 7600/10000] train_loss: -64.98183, val_loss: -51.14729, val_recall@20: 0.15439, val_precision@20: 0.04656, val_ndcg@20: 0.10877\n",
            "items_emb_final tensor([[-0.9755, -0.9955,  0.9631,  ..., -0.9828,  1.0357, -1.0112],\n",
            "        [-0.7189, -0.7226,  0.7304,  ..., -0.7864,  0.7328, -0.7400],\n",
            "        [-0.4011, -0.4172,  0.4370,  ..., -0.4454,  0.4143, -0.4597],\n",
            "        ...,\n",
            "        [ 0.3343,  0.3393, -0.3486,  ...,  0.3197, -0.3106,  0.3059],\n",
            "        [ 0.3422,  0.3068, -0.3244,  ...,  0.2587, -0.2587,  0.3130],\n",
            "        [ 0.2124,  0.2210, -0.2916,  ...,  0.2491, -0.2741,  0.2790]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 7800/10000] train_loss: -65.73417, val_loss: -52.57365, val_recall@20: 0.15439, val_precision@20: 0.04656, val_ndcg@20: 0.10879\n",
            "items_emb_final tensor([[-0.9817, -1.0016,  0.9692,  ..., -0.9890,  1.0419, -1.0174],\n",
            "        [-0.7233, -0.7270,  0.7348,  ..., -0.7909,  0.7372, -0.7445],\n",
            "        [-0.4032, -0.4193,  0.4391,  ..., -0.4475,  0.4164, -0.4618],\n",
            "        ...,\n",
            "        [ 0.3369,  0.3419, -0.3512,  ...,  0.3223, -0.3133,  0.3086],\n",
            "        [ 0.3437,  0.3083, -0.3259,  ...,  0.2602, -0.2602,  0.3145],\n",
            "        [ 0.2138,  0.2224, -0.2931,  ...,  0.2506, -0.2756,  0.2805]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 8000/10000] train_loss: -62.28659, val_loss: -52.80795, val_recall@20: 0.15439, val_precision@20: 0.04656, val_ndcg@20: 0.10883\n",
            "items_emb_final tensor([[-0.9876, -1.0076,  0.9752,  ..., -0.9949,  1.0478, -1.0233],\n",
            "        [-0.7274, -0.7311,  0.7389,  ..., -0.7950,  0.7413, -0.7486],\n",
            "        [-0.4059, -0.4220,  0.4418,  ..., -0.4502,  0.4192, -0.4645],\n",
            "        ...,\n",
            "        [ 0.3389,  0.3439, -0.3532,  ...,  0.3242, -0.3152,  0.3105],\n",
            "        [ 0.3459,  0.3104, -0.3280,  ...,  0.2624, -0.2624,  0.3167],\n",
            "        [ 0.2159,  0.2245, -0.2952,  ...,  0.2526, -0.2776,  0.2825]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 8200/10000] train_loss: -65.82524, val_loss: -52.67251, val_recall@20: 0.15439, val_precision@20: 0.04656, val_ndcg@20: 0.10883\n",
            "items_emb_final tensor([[-0.9931, -1.0130,  0.9806,  ..., -1.0004,  1.0533, -1.0288],\n",
            "        [-0.7313, -0.7349,  0.7428,  ..., -0.7988,  0.7451, -0.7524],\n",
            "        [-0.4090, -0.4252,  0.4450,  ..., -0.4533,  0.4223, -0.4676],\n",
            "        ...,\n",
            "        [ 0.3403,  0.3453, -0.3546,  ...,  0.3257, -0.3166,  0.3120],\n",
            "        [ 0.3482,  0.3128, -0.3304,  ...,  0.2647, -0.2647,  0.3190],\n",
            "        [ 0.2177,  0.2263, -0.2970,  ...,  0.2545, -0.2795,  0.2844]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 8400/10000] train_loss: -66.329, val_loss: -53.85769, val_recall@20: 0.15439, val_precision@20: 0.04656, val_ndcg@20: 0.10879\n",
            "items_emb_final tensor([[-0.9984, -1.0184,  0.9860,  ..., -1.0057,  1.0586, -1.0341],\n",
            "        [-0.7354, -0.7391,  0.7469,  ..., -0.8030,  0.7493, -0.7566],\n",
            "        [-0.4112, -0.4273,  0.4471,  ..., -0.4555,  0.4245, -0.4698],\n",
            "        ...,\n",
            "        [ 0.3425,  0.3474, -0.3568,  ...,  0.3278, -0.3188,  0.3141],\n",
            "        [ 0.3494,  0.3140, -0.3316,  ...,  0.2660, -0.2660,  0.3203],\n",
            "        [ 0.2188,  0.2274, -0.2981,  ...,  0.2555, -0.2806,  0.2855]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 8600/10000] train_loss: -69.25948, val_loss: -54.58735, val_recall@20: 0.15439, val_precision@20: 0.04656, val_ndcg@20: 0.10878\n",
            "items_emb_final tensor([[-1.0033, -1.0232,  0.9908,  ..., -1.0106,  1.0635, -1.0390],\n",
            "        [-0.7389, -0.7425,  0.7504,  ..., -0.8064,  0.7527, -0.7600],\n",
            "        [-0.4132, -0.4294,  0.4491,  ..., -0.4575,  0.4264, -0.4718],\n",
            "        ...,\n",
            "        [ 0.3439,  0.3489, -0.3582,  ...,  0.3293, -0.3202,  0.3156],\n",
            "        [ 0.3516,  0.3162, -0.3337,  ...,  0.2681, -0.2681,  0.3224],\n",
            "        [ 0.2208,  0.2294, -0.3002,  ...,  0.2576, -0.2827,  0.2875]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 8800/10000] train_loss: -66.31082, val_loss: -54.55414, val_recall@20: 0.15439, val_precision@20: 0.04656, val_ndcg@20: 0.10883\n",
            "items_emb_final tensor([[-1.0080, -1.0279,  0.9955,  ..., -1.0153,  1.0682, -1.0437],\n",
            "        [-0.7424, -0.7461,  0.7539,  ..., -0.8100,  0.7563, -0.7636],\n",
            "        [-0.4152, -0.4314,  0.4511,  ..., -0.4595,  0.4285, -0.4738],\n",
            "        ...,\n",
            "        [ 0.3452,  0.3502, -0.3596,  ...,  0.3306, -0.3216,  0.3169],\n",
            "        [ 0.3533,  0.3178, -0.3354,  ...,  0.2698, -0.2698,  0.3241],\n",
            "        [ 0.2221,  0.2307, -0.3015,  ...,  0.2589, -0.2840,  0.2888]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 9000/10000] train_loss: -65.79442, val_loss: -55.73655, val_recall@20: 0.15439, val_precision@20: 0.04656, val_ndcg@20: 0.10877\n",
            "items_emb_final tensor([[-1.0124, -1.0323,  0.9999,  ..., -1.0196,  1.0726, -1.0481],\n",
            "        [-0.7459, -0.7496,  0.7574,  ..., -0.8135,  0.7598, -0.7671],\n",
            "        [-0.4175, -0.4336,  0.4534,  ..., -0.4617,  0.4307, -0.4761],\n",
            "        ...,\n",
            "        [ 0.3466,  0.3516, -0.3609,  ...,  0.3320, -0.3230,  0.3183],\n",
            "        [ 0.3547,  0.3193, -0.3368,  ...,  0.2712, -0.2712,  0.3255],\n",
            "        [ 0.2228,  0.2314, -0.3022,  ...,  0.2596, -0.2847,  0.2895]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 9200/10000] train_loss: -69.88347, val_loss: -56.11047, val_recall@20: 0.15439, val_precision@20: 0.04656, val_ndcg@20: 0.10877\n",
            "items_emb_final tensor([[-1.0165, -1.0365,  1.0041,  ..., -1.0238,  1.0768, -1.0522],\n",
            "        [-0.7487, -0.7524,  0.7602,  ..., -0.8163,  0.7626, -0.7699],\n",
            "        [-0.4190, -0.4352,  0.4549,  ..., -0.4633,  0.4323, -0.4776],\n",
            "        ...,\n",
            "        [ 0.3480,  0.3530, -0.3624,  ...,  0.3334, -0.3244,  0.3197],\n",
            "        [ 0.3564,  0.3210, -0.3385,  ...,  0.2729, -0.2729,  0.3272],\n",
            "        [ 0.2237,  0.2323, -0.3031,  ...,  0.2605, -0.2856,  0.2904]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 9400/10000] train_loss: -69.82861, val_loss: -56.34251, val_recall@20: 0.15439, val_precision@20: 0.04656, val_ndcg@20: 0.10876\n",
            "items_emb_final tensor([[-1.0207, -1.0407,  1.0083,  ..., -1.0280,  1.0810, -1.0565],\n",
            "        [-0.7514, -0.7551,  0.7629,  ..., -0.8190,  0.7653, -0.7726],\n",
            "        [-0.4213, -0.4375,  0.4572,  ..., -0.4655,  0.4345, -0.4799],\n",
            "        ...,\n",
            "        [ 0.3499,  0.3548, -0.3642,  ...,  0.3352, -0.3262,  0.3215],\n",
            "        [ 0.3579,  0.3224, -0.3400,  ...,  0.2744, -0.2744,  0.3287],\n",
            "        [ 0.2247,  0.2333, -0.3042,  ...,  0.2616, -0.2866,  0.2914]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 9600/10000] train_loss: -71.28371, val_loss: -57.12302, val_recall@20: 0.15439, val_precision@20: 0.04656, val_ndcg@20: 0.10877\n",
            "items_emb_final tensor([[-1.0247, -1.0447,  1.0123,  ..., -1.0320,  1.0850, -1.0605],\n",
            "        [-0.7545, -0.7582,  0.7660,  ..., -0.8221,  0.7684, -0.7756],\n",
            "        [-0.4226, -0.4388,  0.4584,  ..., -0.4668,  0.4358, -0.4812],\n",
            "        ...,\n",
            "        [ 0.3508,  0.3557, -0.3651,  ...,  0.3361, -0.3271,  0.3224],\n",
            "        [ 0.3587,  0.3233, -0.3409,  ...,  0.2753, -0.2753,  0.3296],\n",
            "        [ 0.2257,  0.2343, -0.3052,  ...,  0.2625, -0.2876,  0.2924]],\n",
            "       grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 9800/10000] train_loss: -66.87175, val_loss: -57.38356, val_recall@20: 0.15439, val_precision@20: 0.04656, val_ndcg@20: 0.10877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neg_items_emb_final2 #= neg_items_emb_02 = items_emb_final2 = items_emb_02= neg_item_indices2 "
      ],
      "metadata": {
        "id": "w-5pBJEq0g0H",
        "outputId": "69b886f3-846c-4045-9f79-14bfd8bbf6d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3648,  0.3692, -0.3440,  ...,  0.3401, -0.2879,  0.3315],\n",
              "        [-0.2128, -0.2331,  0.1982,  ..., -0.2033,  0.1756, -0.2596],\n",
              "        [ 0.2545,  0.2763, -0.2188,  ...,  0.2247, -0.2597,  0.2179],\n",
              "        ...,\n",
              "        [ 0.3375,  0.3599, -0.3432,  ...,  0.3869, -0.3470,  0.3629],\n",
              "        [-0.1665, -0.1621,  0.1888,  ..., -0.1561,  0.1548, -0.1509],\n",
              "        [-0.8667, -0.8519,  0.8400,  ..., -0.8518,  0.8237, -0.8526]],\n",
              "       grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "items_emb_final2"
      ],
      "metadata": {
        "id": "lYBffBix3mRX",
        "outputId": "59e60ba7-fef7-4eb2-8d5e-c200dedb1d18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.0282, -1.0481,  1.0157,  ..., -1.0355,  1.0884, -1.0639],\n",
              "        [-0.7572, -0.7609,  0.7687,  ..., -0.8248,  0.7711, -0.7784],\n",
              "        [-0.4236, -0.4398,  0.4595,  ..., -0.4678,  0.4368, -0.4822],\n",
              "        ...,\n",
              "        [ 0.3525,  0.3575, -0.3669,  ...,  0.3379, -0.3289,  0.3242],\n",
              "        [ 0.3598,  0.3243, -0.3419,  ...,  0.2763, -0.2763,  0.3306],\n",
              "        [ 0.2264,  0.2349, -0.3058,  ...,  0.2632, -0.2883,  0.2931]],\n",
              "       grad_fn=<SplitWithSizesBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "items_emb_02"
      ],
      "metadata": {
        "id": "6jTGTWJX3xsz",
        "outputId": "80145e2f-e56d-497e-c746-40cfa0159ec3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-4.1128, -4.1926,  4.0630,  ..., -4.1419,  4.3537, -4.2557],\n",
              "        [-3.0289, -3.0437,  3.0750,  ..., -3.2992,  3.0845, -3.1135],\n",
              "        [-1.6943, -1.7591,  1.8378,  ..., -1.8714,  1.7473, -1.9287],\n",
              "        ...,\n",
              "        [ 1.4102,  1.4301, -1.4675,  ...,  1.3516, -1.3156,  1.2969],\n",
              "        [ 1.4391,  1.2973, -1.3676,  ...,  1.1051, -1.1052,  1.3224],\n",
              "        [ 0.9054,  0.9398, -1.2234,  ...,  1.0529, -1.1533,  1.1724]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "items_emb_02[neg_item_indices2]"
      ],
      "metadata": {
        "id": "TkkJ9Z6n4CUh",
        "outputId": "471cf595-c5f9-440e-a04b-f0cb149ab83f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.4593,  1.4769, -1.3761,  ...,  1.3603, -1.1518,  1.3259],\n",
              "        [-0.8510, -0.9326,  0.7929,  ..., -0.8131,  0.7023, -1.0383],\n",
              "        [ 1.0182,  1.1052, -0.8752,  ...,  0.8988, -1.0389,  0.8718],\n",
              "        ...,\n",
              "        [ 1.3499,  1.4397, -1.3728,  ...,  1.5476, -1.3881,  1.4515],\n",
              "        [-0.6660, -0.6483,  0.7554,  ..., -0.6244,  0.6193, -0.6034],\n",
              "        [-3.4670, -3.4076,  3.3600,  ..., -3.4073,  3.2948, -3.4103]],\n",
              "       grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iters = [iter * ITERS_PER_EVAL for iter in range(len(train_losses))]\n",
        "plt.plot(iters, train_losses, label='train')\n",
        "plt.plot(iters, val_losses, label='validation')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('loss')\n",
        "plt.title('training and validation loss curves')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v4wiSzh_pAcy",
        "outputId": "ea3fcf07-90a2-4547-b83a-c4795872afaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6UjCTMQ_N5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b80cefbf-5b30-4966-af53-b602d1a2fa48"
      },
      "source": [
        "# evaluate on test set\n",
        "model.eval()\n",
        "test_edge_index = test_edge_index.to(device)\n",
        "test_sparse_edge_index = test_sparse_edge_index.to(device)\n",
        "\n",
        "test_loss, test_recall, test_precision, test_ndcg = evaluation(\n",
        "            model, test_edge_index, test_sparse_edge_index, [train_edge_index, val_edge_index], K, LAMBDA)\n",
        "\n",
        "print(f\"[test_loss: {round(test_loss, 5)}, test_recall@{K}: {round(test_recall, 5)}, test_precision@{K}: {round(test_precision, 5)}, test_ndcg@{K}: {round(test_ndcg, 5)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test_loss: -52.53061, test_recall@20: 0.12583, test_precision@20: 0.04638, test_ndcg@20: 0.10166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At4zWPfaVW6q"
      },
      "source": [
        "# Make New Recommendatios for a Given User"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzuMPxFVZlQn"
      },
      "source": [
        "model.eval()\n",
        "df = pd.read_csv(movie_path)\n",
        "movieid_title = pd.Series(df.title.values,index=df.movieId).to_dict()\n",
        "movieid_genres = pd.Series(df.genres.values,index=df.movieId).to_dict()\n",
        "\n",
        "user_pos_items = get_user_positive_items(edge_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(user_id, num_recs):\n",
        "    user = user_mapping[user_id]\n",
        "    e_u = model.users_emb.weight[user]\n",
        "    scores = model.items_emb.weight @ e_u\n",
        "\n",
        "    values, indices = torch.topk(scores, k=len(user_pos_items[user]) + num_recs)\n",
        "\n",
        "    movies = [index.cpu().item() for index in indices if index in user_pos_items[user]][:num_recs]\n",
        "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
        "    titles = [movieid_title[id] for id in movie_ids]\n",
        "    genres = [movieid_genres[id] for id in movie_ids]\n",
        "\n",
        "    print(f\"Here are some movies that user {user_id} rated highly\")\n",
        "    for i in range(num_recs):\n",
        "        print(f\"title: {titles[i]}, genres: {genres[i]} \")\n",
        "\n",
        "    print()\n",
        "\n",
        "    movies = [index.cpu().item() for index in indices if index not in user_pos_items[user]][:num_recs]\n",
        "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
        "    titles = [movieid_title[id] for id in movie_ids]\n",
        "    genres = [movieid_genres[id] for id in movie_ids]\n",
        "\n",
        "    print(f\"Here are some suggested movies for user {user_id}\")\n",
        "    for i in range(num_recs):\n",
        "        print(f\"title: {titles[i]}, genres: {genres[i]} \")"
      ],
      "metadata": {
        "id": "oWR-LQUDaqgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USER_ID = 1\n",
        "NUM_RECS = 10\n",
        "\n",
        "make_predictions(USER_ID, NUM_RECS)"
      ],
      "metadata": {
        "id": "Cvc-P1a6rZhD",
        "outputId": "e16cffc7-e2a0-4383-8917-3ca37c7ea027",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some movies that user 1 rated highly\n",
            "title: Forrest Gump (1994), genres: Comedy|Drama|Romance|War \n",
            "title: Matrix, The (1999), genres: Action|Sci-Fi|Thriller \n",
            "title: Silence of the Lambs, The (1991), genres: Crime|Horror|Thriller \n",
            "title: Star Wars: Episode IV - A New Hope (1977), genres: Action|Adventure|Sci-Fi \n",
            "title: Fight Club (1999), genres: Action|Crime|Drama|Thriller \n",
            "title: Schindler's List (1993), genres: Drama|War \n",
            "title: Star Wars: Episode V - The Empire Strikes Back (1980), genres: Action|Adventure|Sci-Fi \n",
            "title: Braveheart (1995), genres: Action|Drama|War \n",
            "title: American Beauty (1999), genres: Drama|Romance \n",
            "title: Usual Suspects, The (1995), genres: Crime|Mystery|Thriller \n",
            "\n",
            "Here are some suggested movies for user 1\n",
            "title: Shawshank Redemption, The (1994), genres: Crime|Drama \n",
            "title: Pulp Fiction (1994), genres: Comedy|Crime|Drama|Thriller \n",
            "title: Godfather, The (1972), genres: Crime|Drama \n",
            "title: Terminator 2: Judgment Day (1991), genres: Action|Sci-Fi \n",
            "title: Lord of the Rings: The Return of the King, The (2003), genres: Action|Adventure|Drama|Fantasy \n",
            "title: Lord of the Rings: The Fellowship of the Ring, The (2001), genres: Adventure|Fantasy \n",
            "title: Apollo 13 (1995), genres: Adventure|Drama|IMAX \n",
            "title: Lord of the Rings: The Two Towers, The (2002), genres: Adventure|Fantasy \n",
            "title: Sixth Sense, The (1999), genres: Drama|Horror|Mystery \n",
            "title: Lion King, The (1994), genres: Adventure|Animation|Children|Drama|Musical|IMAX \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSFgwnaecWBw",
        "outputId": "828828ac-78f5-47b2-9c72-ff8deff7b58f"
      },
      "source": [
        "USER_ID = 1\n",
        "NUM_RECS = 10\n",
        "\n",
        "make_predictions(USER_ID, NUM_RECS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some movies that user 1 rated highly\n",
            "title: Forrest Gump (1994), genres: Comedy|Drama|Romance|War \n",
            "title: Matrix, The (1999), genres: Action|Sci-Fi|Thriller \n",
            "title: Silence of the Lambs, The (1991), genres: Crime|Horror|Thriller \n",
            "title: Star Wars: Episode IV - A New Hope (1977), genres: Action|Adventure|Sci-Fi \n",
            "title: Fight Club (1999), genres: Action|Crime|Drama|Thriller \n",
            "title: Schindler's List (1993), genres: Drama|War \n",
            "title: Star Wars: Episode V - The Empire Strikes Back (1980), genres: Action|Adventure|Sci-Fi \n",
            "title: Braveheart (1995), genres: Action|Drama|War \n",
            "title: Usual Suspects, The (1995), genres: Crime|Mystery|Thriller \n",
            "title: Star Wars: Episode VI - Return of the Jedi (1983), genres: Action|Adventure|Sci-Fi \n",
            "\n",
            "Here are some suggested movies for user 1\n",
            "title: Shawshank Redemption, The (1994), genres: Crime|Drama \n",
            "title: Pulp Fiction (1994), genres: Comedy|Crime|Drama|Thriller \n",
            "title: Godfather, The (1972), genres: Crime|Drama \n",
            "title: Terminator 2: Judgment Day (1991), genres: Action|Sci-Fi \n",
            "title: Lord of the Rings: The Return of the King, The (2003), genres: Action|Adventure|Drama|Fantasy \n",
            "title: Lord of the Rings: The Fellowship of the Ring, The (2001), genres: Adventure|Fantasy \n",
            "title: Sixth Sense, The (1999), genres: Drama|Horror|Mystery \n",
            "title: Lord of the Rings: The Two Towers, The (2002), genres: Adventure|Fantasy \n",
            "title: Apollo 13 (1995), genres: Adventure|Drama|IMAX \n",
            "title: Aladdin (1992), genres: Adventure|Animation|Children|Comedy|Musical \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLkRpNldrSQe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}