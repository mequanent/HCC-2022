{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lightgcn_pyg.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mequanent/Music-Recommendation-Exercises/blob/main/LightGCN%20using%20Pytorch%20Geometric.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: LightGCN with PyTorch Geometric from [Medium](https://medium.com/stanford-cs224w/lightgcn-with-pytorch-geometric-91bab836471e).\n",
        "\n",
        "@hhotta@stanford.edu"
      ],
      "metadata": {
        "id": "-HEi2gj_sPQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To install the correct version of Pytorch Geometric.\n",
        "# This cell is modified from: https://gist.github.com/ameya98/b193856171d11d37ada46458f60e73e7\n",
        "\n",
        "import torch\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "CUDA_version = torch.version.cuda\n",
        "\n",
        "TORCH = TORCH_version.split('+')[0]\n",
        "CUDA = 'cu' + CUDA_version.replace('.', '')\n",
        "\n",
        "!pip install -q torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-geometric "
      ],
      "metadata": {
        "id": "EGuLx-U-krHR",
        "outputId": "c66ed62e-bdaa-4c5c-ac76-e2a92eb7e009",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.9 MB 2.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 3.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 2.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 750 kB 2.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 407 kB 5.5 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWkNAZvtNQ6R"
      },
      "source": [
        "# Implementing a Recommender System using LightGCN\n",
        "\n",
        "In this colab, we explain how to set up a graph recommender system using the [LighGCN](https://arxiv.org/abs/2002.02126) model. Specifically, we apply LightGCN to a movie recommendation task using [PyTorch](https://pytorch.org/) and [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/).\n",
        "\n",
        "We use the [MovieLens](https://grouplens.org/datasets/movielens/) (*small*) dataset which has 100,000 ratings applied to 9,000 movies by 600 users. \n",
        "\n",
        "Our implementation was inspired by the following documentation and repositories:\n",
        "- https://github.com/gusye1234/LightGCN-PyTorch\n",
        "- https://www.kaggle.com/dipanjandas96/lightgcn-pytorch-from-scratch\n",
        "- https://pytorch-geometric.readthedocs.io/en/latest/notes/load_csv.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OBSacx6Q03m"
      },
      "source": [
        "# import required modules\n",
        "from pathlib import Path\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing as prep\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim, Tensor\n",
        "\n",
        "from torch_sparse import SparseTensor, matmul\n",
        "\n",
        "from torch_geometric.utils import structured_negative_sampling\n",
        "from torch_geometric.data import download_url, extract_zip\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.typing import Adj"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mZ6-zPxPklE"
      },
      "source": [
        "# Loading the Dataset\n",
        "\n",
        "We load the dataset and set ratings >=4 on a 0.5 ~ 5 scale as an edge between users and movies.\n",
        "\n",
        "We split the edges of the graph using a 80/10/10 train/validation/test split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cRC_IazQ4Oj",
        "outputId": "c0bdda7f-7f1f-4fcc-e6c4-65ec91322eee"
      },
      "source": [
        "# Movie\n",
        "# download the dataset\n",
        "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
        "extract_zip(download_url(url, '.'), '.')\n",
        "\n",
        "movie_path = './ml-latest-small/movies.csv'\n",
        "rating_path = './ml-latest-small/ratings.csv'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Extracting ./ml-latest-small.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Music\n",
        "metaurl = \"http://deepyeti.ucsd.edu/jianmo/amazon/metaFiles2/meta_Digital_Music.json.gz\"\n",
        "reviewurl = \"http://deepyeti.ucsd.edu/jianmo/amazon/categoryFiles/Digital_Music.json.gz\"\n",
        "ratingurl = \"http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Digital_Music.csv\"\n",
        "\n",
        "columns = ['movieId','userId','rating','timestamp']\n",
        "meta = pd.read_json(metaurl, lines = True)\n",
        "review = pd.read_json(reviewurl, lines = True)\n",
        "rating = pd.read_csv(ratingurl, names=columns, header = None)\n",
        "\n",
        "# Re-order the user and item columns\n",
        "columns = ['userId','movieId','rating','timestamp']\n",
        "rating = rating.reindex(columns=columns)\n",
        "rating.head(2)\n",
        "\n",
        "moviecols = ['movieId',\t'title',\t'genres'] # For music review"
      ],
      "metadata": {
        "id": "Gw2NNxgbv2tP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = rating[rating['rating']>4]\n",
        "df.shape"
      ],
      "metadata": {
        "id": "WUrz-DUGE_qM",
        "outputId": "eb7d140b-7a0f-416f-9ed7-a1c47ce7c3d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1280147, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['userId'].value_counts().index.tolist())"
      ],
      "metadata": {
        "id": "AhdAnGvGKiEP",
        "outputId": "ea469a04-5ad5-449f-8b1a-fb5da4de31a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "713286"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#a = df['userId'].value_counts().index.tolist()[:-60000]\n",
        "a = df['userId'].value_counts().index.tolist()[48000:]\n",
        "df = df.loc[df['userId'].isin(a)]\n",
        "df.shape"
      ],
      "metadata": {
        "id": "T5PjX0AHIoWr",
        "outputId": "eb3c7983-ec5b-4831-9d2e-0d1b2c94ac7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(857275, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u = review.asin.unique().tolist()\n",
        "v = meta.asin.unique().tolist()\n",
        "n = df.movieId.unique().tolist()\n",
        "m = set(n).intersection(v, u)\n",
        "\n",
        "print(len(u), len(n), len(v), len(m))\n",
        "\n",
        "met = meta.loc[meta['asin'].isin(m)]\n",
        "rev = review.loc[review['asin'].isin(m)]\n",
        "rat = df.loc[rating['movieId'].isin(m)]"
      ],
      "metadata": {
        "id": "gf5E4Bj4Frt4",
        "outputId": "9d6385db-d39d-4bc1-d572-3d73c4f6411d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "456992 294140 66013 42791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Original\n",
        "u = review.asin.unique().tolist()\n",
        "v = meta.asin.unique().tolist()\n",
        "n = rating.movieId.unique().tolist()\n",
        "m = set(n).intersection(v, u)\n",
        "\n",
        "print(len(u), len(n), len(v), len(m))\n",
        "\n",
        "met = meta.loc[meta['asin'].isin(m)]\n",
        "rev = review.loc[review['asin'].isin(m)]\n",
        "rat = rating.loc[rating['movieId'].isin(m)]"
      ],
      "metadata": {
        "id": "I23sZpIbHSlV",
        "outputId": "27f4aa20-ab7f-4eab-9eda-9a0e73e1de42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "456992 456992 66013 66010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = rev[['asin']]\n",
        "b = met[['asin', 'title', 'brand']]\n",
        "a_b = pd.merge(a, b, on = 'asin', how = 'inner').drop_duplicates()\n",
        "a_b.rename(columns = {'asin': 'movieId', 'brand': 'genres'}, inplace = True) \n",
        "ratng = pd.merge(rat, a_b, on = 'movieId', how = 'inner')\n",
        "ratng = ratng[:100000]"
      ],
      "metadata": {
        "id": "UXNR9hohGDay"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratng.shape"
      ],
      "metadata": {
        "id": "0Y4BfBKEjmBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Original\n",
        "a = rev[['asin']]\n",
        "b = met[['asin', 'title', 'brand']]\n",
        "existing = ['asin'\t'title'\t'brand']\n",
        "a_b = pd.merge(a, b, on = 'asin', how = 'inner').drop_duplicates()\n",
        "#a_b[a_b['asin']=='B00NPZI1ZS']['title'].values[0]\n",
        "a_b.rename(columns = {'asin': 'movieId', 'brand': 'genres'}, inplace = True) \n",
        "# ['movieId',\t'title',\t'genres']\n",
        "ratng = pd.merge(rat, a_b, on = 'movieId', how = 'inner')\n",
        "ratng"
      ],
      "metadata": {
        "id": "4xJYOXYq3t4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "leu = prep.LabelEncoder() # ['userId','movieId','rating','timestamp']\n",
        "lem = prep.LabelEncoder()\n",
        "\n",
        "ratng['movieId'] = leu.fit_transform(ratng['movieId'].values)\n",
        "ratng['userId'] = lem.fit_transform(ratng['userId'].values)\n",
        "ratng.head(2)"
      ],
      "metadata": {
        "id": "dJhfhHmbbkTK",
        "outputId": "a1ad4d83-ed62-42c6-b5dc-93454ba47b75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId  movieId  rating   timestamp                          title  \\\n",
              "0   23808        1     5.0  1387670400  So You Wanna Go Back to Egypt   \n",
              "1   76028        1     5.0  1378857600  So You Wanna Go Back to Egypt   \n",
              "\n",
              "        genres  \n",
              "0  Keith Green  \n",
              "1  Keith Green  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f51f4b9d-5afa-4a21-9aba-1d307b847e93\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23808</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1387670400</td>\n",
              "      <td>So You Wanna Go Back to Egypt</td>\n",
              "      <td>Keith Green</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>76028</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1378857600</td>\n",
              "      <td>So You Wanna Go Back to Egypt</td>\n",
              "      <td>Keith Green</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f51f4b9d-5afa-4a21-9aba-1d307b847e93')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f51f4b9d-5afa-4a21-9aba-1d307b847e93 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f51f4b9d-5afa-4a21-9aba-1d307b847e93');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = ratng[['userId', 'movieId',\t'rating',\t'timestamp'\t]]\n",
        "movie = ratng[['movieId',\t'title',\t'genres'\t]].drop_duplicates()"
      ],
      "metadata": {
        "id": "Vg6i_1sdh5AO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie"
      ],
      "metadata": {
        "id": "4OCKoldlqUeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#path = Path('/content/drive/MyDrive/Colab Notebooks/') \n",
        "path = Path('./ml-latest-small/')\n",
        "movie_file = path/'movie.csv'\n",
        "rating_file = path/'rating.csv'\n",
        "\n",
        "#movie.to_csv(movie_file,columns = ['movieId',\t'title',\t'genres'], index=False)#  sep=' ')\n",
        "movie.to_csv(movie_file, index=False)\n",
        "ratings.to_csv(rating_file, index=False)\n",
        "#ratings.to_csv(rating_file, columns = ['userId',\t'movieId',\t'rating',\t'timestamp'])#, sep=' ')\n",
        "#np.savetxt(movie_file, movie, fmt='%s')\n",
        "#np.savetxt(rating_file, ratings, fmt='%s')"
      ],
      "metadata": {
        "id": "vVD-GitQOonp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_path = './ml-latest-small/movie.csv'\n",
        "rating_path = './ml-latest-small/rating.csv'"
      ],
      "metadata": {
        "id": "cMGO9I8EaCPf"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = pd.read_csv(movie_path)\n",
        "r.head(2) "
      ],
      "metadata": {
        "id": "BAR03PlVrs3p",
        "outputId": "e1e9d01a-6229-4139-dd9c-cadfc6496612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   movieId                          title       genres\n",
              "0        1  So You Wanna Go Back to Egypt  Keith Green\n",
              "1        2      Early Works - Dallas Holm  Dallas Holm"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-047e3e0c-293a-4a5b-a5ca-a6caa4dc9b58\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>So You Wanna Go Back to Egypt</td>\n",
              "      <td>Keith Green</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Early Works - Dallas Holm</td>\n",
              "      <td>Dallas Holm</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-047e3e0c-293a-4a5b-a5ca-a6caa4dc9b58')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-047e3e0c-293a-4a5b-a5ca-a6caa4dc9b58 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-047e3e0c-293a-4a5b-a5ca-a6caa4dc9b58');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4lKu660qE4e3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2P3zYR8Q8EX"
      },
      "source": [
        "# load user and movie nodes\n",
        "def load_node_csv(path, index_col):\n",
        "    \"\"\"Loads csv containing node information\n",
        "\n",
        "    Args:\n",
        "        path (str): path to csv file\n",
        "        index_col (str): column name of index column\n",
        "\n",
        "    Returns:\n",
        "        dict: mapping of csv row to node id\n",
        "    \"\"\" \n",
        "    df = pd.read_csv(path, index_col=index_col)\n",
        "    mapping = {index: i for i, index in enumerate(df.index.unique())}\n",
        "    return mapping\n",
        "\n",
        "\n",
        "user_mapping = load_node_csv(rating_path, index_col='userId')\n",
        "movie_mapping = load_node_csv(movie_path, index_col='movieId')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkJzQlxSRDEq"
      },
      "source": [
        "# load edges between users and movies\n",
        "def load_edge_csv(path, src_index_col, src_mapping, dst_index_col, dst_mapping, link_index_col, rating_threshold=4):\n",
        "    \"\"\"Loads csv containing edges between users and items\n",
        "\n",
        "    Args:\n",
        "        path (str): path to csv file\n",
        "        src_index_col (str): column name of users\n",
        "        src_mapping (dict): mapping between row number and user id\n",
        "        dst_index_col (str): column name of items\n",
        "        dst_mapping (dict): mapping between row number and item id\n",
        "        link_index_col (str): column name of user item interaction\n",
        "        rating_threshold (int, optional): Threshold to determine positivity of edge. Defaults to 4.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: 2 by N matrix containing the node ids of N user-item edges\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path)\n",
        "    edge_index = None\n",
        "    src = [src_mapping[index] for index in df[src_index_col]]\n",
        "    dst = [dst_mapping[index] for index in df[dst_index_col]]\n",
        "    edge_attr = torch.from_numpy(df[link_index_col].values).view(-1, 1).to(torch.long) >= rating_threshold\n",
        "\n",
        "\n",
        "    edge_index = [[], []]\n",
        "    for i in range(edge_attr.shape[0]):\n",
        "        if edge_attr[i]:\n",
        "            edge_index[0].append(src[i])\n",
        "            edge_index[1].append(dst[i])\n",
        "\n",
        "    return torch.tensor(edge_index)\n",
        "\n",
        "\n",
        "edge_index = load_edge_csv(\n",
        "    rating_path,\n",
        "    src_index_col='userId',\n",
        "    src_mapping=user_mapping,\n",
        "    dst_index_col='movieId',\n",
        "    dst_mapping=movie_mapping,\n",
        "    link_index_col='rating',\n",
        "    rating_threshold=4,\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIueYZfaT6_H"
      },
      "source": [
        "# split the edges of the graph using a 80/10/10 train/validation/test split\n",
        "num_users, num_movies = len(user_mapping), len(movie_mapping)\n",
        "num_interactions = edge_index.shape[1]\n",
        "all_indices = [i for i in range(num_interactions)]\n",
        "\n",
        "train_indices, test_indices = train_test_split(\n",
        "    all_indices, test_size=0.2, random_state=1)\n",
        "val_indices, test_indices = train_test_split(\n",
        "    test_indices, test_size=0.5, random_state=1)\n",
        "\n",
        "train_edge_index = edge_index[:, train_indices]\n",
        "val_edge_index = edge_index[:, val_indices]\n",
        "test_edge_index = edge_index[:, test_indices]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5yKILBJUAN6"
      },
      "source": [
        "# convert edge indices into Sparse Tensors: https://pytorch-geometric.readthedocs.io/en/latest/notes/sparse_tensor.html\n",
        "train_sparse_edge_index = SparseTensor(row=train_edge_index[0], col=train_edge_index[1], sparse_sizes=(\n",
        "    num_users + num_movies, num_users + num_movies))\n",
        "val_sparse_edge_index = SparseTensor(row=val_edge_index[0], col=val_edge_index[1], sparse_sizes=(\n",
        "    num_users + num_movies, num_users + num_movies))\n",
        "test_sparse_edge_index = SparseTensor(row=test_edge_index[0], col=test_edge_index[1], sparse_sizes=(\n",
        "    num_users + num_movies, num_users + num_movies))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqKI1VduKcwf"
      },
      "source": [
        "# function which random samples a mini-batch of positive and negative samples\n",
        "def sample_mini_batch(batch_size, edge_index):\n",
        "    \"\"\"Randomly samples indices of a minibatch given an adjacency matrix\n",
        "\n",
        "    Args:\n",
        "        batch_size (int): minibatch size\n",
        "        edge_index (torch.Tensor): 2 by N list of edges\n",
        "\n",
        "    Returns:\n",
        "        tuple: user indices, positive item indices, negative item indices\n",
        "    \"\"\"\n",
        "    edges = structured_negative_sampling(edge_index)\n",
        "    edges = torch.stack(edges, dim=0)\n",
        "    indices = random.choices(\n",
        "        [i for i in range(edges[0].shape[0])], k=batch_size)\n",
        "    batch = edges[:, indices]\n",
        "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
        "    return user_indices, pos_item_indices, neg_item_indices"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOB5kDmtUrUY"
      },
      "source": [
        "# Implementing LightGCN\n",
        "\n",
        "## Light Graph Convolution\n",
        "Between each layer, LightGCN uses the following propagation rule for user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "e_u^{(k+1)} = \\sum_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|}\\sqrt{|N_i|}} e_i^{(k)} \\quad e_i^{(k+1)} = \\sum_{u \\in N_i} \\frac{1}{\\sqrt{|N_i|}\\sqrt{|N_u|}} e_u^{(k)}\n",
        "\\end{equation}\n",
        "\n",
        "$N_u$: the set of all neighbors of user $u$ (items liked by $u$)\n",
        "\n",
        "$N_i$: the set of all neighbors of item $i$ (users who liked $i$)\n",
        "\n",
        "$e_u^{(k)}$ : k-th layer user embedding\n",
        "\n",
        "$e_i^{(k)}$ : k-th layer item embedding\n",
        "\n",
        "\n",
        "\n",
        "## Layer Combination and Model Prediction\n",
        "The only trainable parameters of LightGCN are the 0-th layer embeddings $e_u^{(0)}$ and $e_i^{(0)}$ for each user and item. We combine the embeddings obtained at each layer of propagation to form the final embeddings for all user and item, $e_u$ and $e_i$ via the follwing equation.\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "e_u = \\sum_{k = 0}^K \\alpha_k e_u^{(k)} \\quad e_i = \\sum_{k = 0}^K \\alpha_k e_i^{(k)}\n",
        "\\end{equation}\n",
        "\n",
        "$\\alpha_k$ : hyperparameter which weights the contribution of the k-th layer embedding to the final embedding\n",
        "\n",
        "The model prediction is obtained by taking the inner product of the final user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{y}_{ui} = e_u^Te_i\n",
        "\\end{equation}\n",
        "\n",
        "## Matrix Form\n",
        "In our implementation, we utilize the matrix form of LightGCN. We perform multi-scale diffusion to obtain the final embedding, which sums embeddings diffused across multi-hop scales. \n",
        "\n",
        "\\begin{equation}\n",
        "E^{(K)} = \\alpha_0 E^{(0)} + \\alpha_1 \\tilde{A}^1 E^{(0)} + \\alpha_2 \\tilde{A}^2 E^{(0)} + \\cdot \\cdot \\cdot + \\alpha_K \\tilde{A}^K \\tilde{A} E^{(0)}\n",
        "\\end{equation}\n",
        "\n",
        "$E^{(0)} \\in \\mathcal{R}^{(M + N)} \\times T$ : stacked initial item and user embeddings where $M$, $N$, and $T$ denote the number of users, number of items, and the dimension of each embedding respectively\n",
        "\n",
        "$\\tilde{A} = D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$ : symmetrically normalized adjacency matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modified Aggregation\n",
        "# defines LightGCN model\n",
        "class LightGCN(MessagePassing):\n",
        "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_users, num_items, embedding_dim=64, K=3, add_self_loops=True): # add_self_loops=False originally\n",
        "        \"\"\"Initializes LightGCN Model\n",
        "\n",
        "        Args:\n",
        "            num_users (int): Number of users\n",
        "            num_items (int): Number of items\n",
        "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
        "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
        "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
        "        \"\"\"\n",
        "    #def __init__(self, nn, embedding_dim=32, **kwargs):\n",
        "        #super(GINPNAConv, self).__init__(nn, **kwargs)\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Linear(embedding_dim*12, embedding_dim) # modification\n",
        "        self.delta = 2.5749     # modification\n",
        "\n",
        "        self.num_users, self.num_items = num_users, num_items\n",
        "        self.embedding_dim, self.K = embedding_dim, K\n",
        "        self.add_self_loops = add_self_loops\n",
        "\n",
        "        self.users_emb = nn.Embedding(\n",
        "            num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n",
        "        self.items_emb = nn.Embedding(\n",
        "            num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n",
        "\n",
        "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
        "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
        "\n",
        "    def forward(self, edge_index: SparseTensor):\n",
        "        \"\"\"Forward propagation of LightGCN Model.\n",
        "\n",
        "        Args:\n",
        "            edge_index (SparseTensor): adjacency matrix\n",
        "\n",
        "        Returns:\n",
        "            tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
        "        \"\"\"\n",
        "        # compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
        "        edge_index_norm = gcn_norm(\n",
        "            edge_index, add_self_loops=self.add_self_loops)\n",
        "\n",
        "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
        "        embs = [emb_0]\n",
        "        emb_k = emb_0\n",
        "\n",
        "        # multi-scale diffusion\n",
        "        for i in range(self.K):\n",
        "            emb_k = self.propagate(edge_index_norm, x=emb_k)\n",
        "            embs.append(emb_k)\n",
        "\n",
        "        embs = torch.stack(embs, dim=1)\n",
        "        emb_final_sum = torch.sum(embs, dim=1) # E^K\n",
        "        emb_final_mean = torch.mean(embs, dim=1)\n",
        "        emb_final_max = torch.max(embs, dim=1)[0]\n",
        "        #emb_final_min = torch.min(embs, dim=1)[0]\n",
        "        emb_final_std = torch.std(embs, dim=1)\n",
        "\n",
        "\n",
        "        users_emb_final, items_emb_final = torch.split(\n",
        "            emb_final, [self.num_users, self.num_items]) # splits into e_u^K and e_i^K\n",
        "\n",
        "        # returns e_u^K, e_u^0, e_i^K, e_i^0\n",
        "        return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
        "\n",
        "    def message(self, x_j: Tensor) -> Tensor:\n",
        "        return x_j\n",
        "\n",
        "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
        "        # computes \\tilde{A} @ x\n",
        "        return matmul(adj_t, x)\n",
        "\n",
        "model = LightGCN(num_users, num_movies)"
      ],
      "metadata": {
        "id": "gjamYbIV2IYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = torch.sum(b, dim = 1)\n",
        "mn = torch.mean(b, dim = 1)\n",
        "mx = torch.max(b, dim = 1)[0]\n",
        "st = torch.std(b, dim = 1)"
      ],
      "metadata": {
        "id": "BUMF6INsa1Ez"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = nn.Linear(64*12, 64) # modification\n",
        "delta = 2.5749"
      ],
      "metadata": {
        "id": "yyh3gtj1vz8p"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = torch.min(b, dim = 1)[1]\n",
        "index"
      ],
      "metadata": {
        "id": "SCc1NAK2z7gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aggrs = [s, mx, mn, st]\n",
        "c_idx = index.bincount().float().view(-1, 1)\n",
        "l_idx = torch.log(c_idx + 1.)\n",
        "        \n",
        "amplification_scaler = [c_idx / delta * a for a in aggrs]\n",
        "attenuation_scaler = [delta / c_idx * a for a in aggrs]\n",
        "combinations = torch.cat(aggrs + amplification_scaler + attenuation_scaler, dim=1)\n",
        "x = mlp(combinations)\n",
        "x"
      ],
      "metadata": {
        "id": "7yPaOhWa0HC9",
        "outputId": "eff50ef2-e32c-4e41-ec90-6c3d338cf088",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-399d6b5fef76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mamplification_scaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc_idx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maggrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mattenuation_scaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdelta\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mc_idx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maggrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcombinations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maggrs\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mamplification_scaler\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mattenuation_scaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01c1MnTCaV08",
        "outputId": "8075b8c8-5a39-46da-d233-cdfb122005eb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  3.7524,   1.7524,   7.7524,   6.7524,   5.7524],\n",
              "        [ -8.2273, -10.2273,  -4.2273,  -5.2273,  -6.2273],\n",
              "        [ -2.6800,  -4.6800,   1.3200,   0.3200,  -0.6800],\n",
              "        [  2.5842,   0.5842,   6.5842,   5.5842,   4.5842],\n",
              "        [ 12.2485,  10.2485,  16.2485,  15.2485,  14.2485],\n",
              "        [ -1.1481,  -3.1481,   2.8519,   1.8519,   0.8519],\n",
              "        [ -2.8417,  -4.8417,   1.1583,   0.1583,  -0.8417],\n",
              "        [ -3.5658,  -5.5658,   0.4342,  -0.5658,  -1.5658],\n",
              "        [  5.5001,   3.5001,   9.5001,   8.5001,   7.5001],\n",
              "        [  2.7301,   0.7301,   6.7301,   5.7301,   4.7301],\n",
              "        [  4.9473,   2.9473,   8.9473,   7.9473,   6.9473],\n",
              "        [  4.6801,   2.6801,   8.6801,   7.6801,   6.6801],\n",
              "        [  4.4888,   2.4888,   8.4888,   7.4888,   6.4888],\n",
              "        [  5.1431,   3.1431,   9.1431,   8.1431,   7.1431],\n",
              "        [ -3.4150,  -5.4150,   0.5850,  -0.4150,  -1.4150],\n",
              "        [  4.5591,   2.5591,   8.5591,   7.5591,   6.5591],\n",
              "        [  5.9248,   3.9248,   9.9248,   8.9248,   7.9248],\n",
              "        [  4.9250,   2.9250,   8.9250,   7.9250,   6.9250],\n",
              "        [  7.6483,   5.6483,  11.6483,  10.6483,   9.6483],\n",
              "        [  3.1754,   1.1754,   7.1754,   6.1754,   5.1754],\n",
              "        [  2.6547,   0.6547,   6.6547,   5.6547,   4.6547],\n",
              "        [  6.6172,   4.6172,  10.6172,   9.6172,   8.6172],\n",
              "        [  4.4792,   2.4792,   8.4792,   7.4792,   6.4792],\n",
              "        [  3.1225,   1.1225,   7.1225,   6.1225,   5.1225],\n",
              "        [  0.9037,  -1.0963,   4.9037,   3.9037,   2.9037],\n",
              "        [  1.9147,  -0.0853,   5.9147,   4.9147,   3.9147],\n",
              "        [  4.3212,   2.3212,   8.3212,   7.3212,   6.3212],\n",
              "        [ 10.2625,   8.2625,  14.2625,  13.2625,  12.2625],\n",
              "        [  2.7099,   0.7099,   6.7099,   5.7099,   4.7099],\n",
              "        [ -0.8191,  -2.8191,   3.1809,   2.1809,   1.1809],\n",
              "        [  1.7780,  -0.2220,   5.7780,   4.7780,   3.7780],\n",
              "        [ 14.2878,  12.2878,  18.2878,  17.2878,  16.2878],\n",
              "        [  6.2953,   4.2953,  10.2953,   9.2953,   8.2953],\n",
              "        [ 10.8101,   8.8101,  14.8101,  13.8101,  12.8101],\n",
              "        [  2.0854,   0.0854,   6.0854,   5.0854,   4.0854],\n",
              "        [  9.1422,   7.1422,  13.1422,  12.1422,  11.1422],\n",
              "        [  1.6008,  -0.3992,   5.6008,   4.6008,   3.6008],\n",
              "        [ 10.1475,   8.1475,  14.1475,  13.1475,  12.1475],\n",
              "        [  4.8342,   2.8342,   8.8342,   7.8342,   6.8342],\n",
              "        [  5.8723,   3.8723,   9.8723,   8.8723,   7.8723],\n",
              "        [ -5.1777,  -7.1777,  -1.1777,  -2.1777,  -3.1777],\n",
              "        [ -0.1517,  -2.1517,   3.8483,   2.8483,   1.8483],\n",
              "        [  3.4297,   1.4297,   7.4297,   6.4297,   5.4297],\n",
              "        [ -7.6865,  -9.6865,  -3.6865,  -4.6865,  -5.6865],\n",
              "        [  8.4325,   6.4325,  12.4325,  11.4325,  10.4325],\n",
              "        [  5.1382,   3.1382,   9.1382,   8.1382,   7.1382],\n",
              "        [  4.7862,   2.7862,   8.7862,   7.7862,   6.7862],\n",
              "        [ -5.7708,  -7.7708,  -1.7708,  -2.7708,  -3.7708],\n",
              "        [  9.7918,   7.7918,  13.7918,  12.7918,  11.7918],\n",
              "        [ -2.0987,  -4.0987,   1.9013,   0.9013,  -0.0987]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randint(10, (5,))\n",
        "b = a + (torch.randn(50, 1) * 5).float()"
      ],
      "metadata": {
        "id": "zxd_OzdnY1ag"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9GvYg9ehDOX"
      },
      "source": [
        "# Original\n",
        "# defines LightGCN model\n",
        "class LightGCN(MessagePassing):\n",
        "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_users, num_items, embedding_dim=64, K=3, add_self_loops=False):\n",
        "        \"\"\"Initializes LightGCN Model\n",
        "\n",
        "        Args:\n",
        "            num_users (int): Number of users\n",
        "            num_items (int): Number of items\n",
        "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
        "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
        "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_users, self.num_items = num_users, num_items\n",
        "        self.embedding_dim, self.K = embedding_dim, K\n",
        "        self.add_self_loops = add_self_loops\n",
        "\n",
        "        self.users_emb = nn.Embedding(\n",
        "            num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n",
        "        self.items_emb = nn.Embedding(\n",
        "            num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n",
        "\n",
        "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
        "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
        "\n",
        "    def forward(self, edge_index: SparseTensor):\n",
        "        \"\"\"Forward propagation of LightGCN Model.\n",
        "\n",
        "        Args:\n",
        "            edge_index (SparseTensor): adjacency matrix\n",
        "\n",
        "        Returns:\n",
        "            tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
        "        \"\"\"\n",
        "        # compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
        "        edge_index_norm = gcn_norm(\n",
        "            edge_index, add_self_loops=self.add_self_loops)\n",
        "\n",
        "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
        "        embs = [emb_0]\n",
        "        emb_k = emb_0\n",
        "\n",
        "        # multi-scale diffusion\n",
        "        for i in range(self.K):\n",
        "            emb_k = self.propagate(edge_index_norm, x=emb_k)\n",
        "            embs.append(emb_k)\n",
        "\n",
        "        embs = torch.stack(embs, dim=1)\n",
        "        emb_final = torch.mean(embs, dim=1) # E^K\n",
        "\n",
        "        users_emb_final, items_emb_final = torch.split(\n",
        "            emb_final, [self.num_users, self.num_items]) # splits into e_u^K and e_i^K\n",
        "\n",
        "        # returns e_u^K, e_u^0, e_i^K, e_i^0\n",
        "        return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
        "\n",
        "    def message(self, x_j: Tensor) -> Tensor:\n",
        "        return x_j\n",
        "\n",
        "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
        "        # computes \\tilde{A} @ x\n",
        "        return matmul(adj_t, x)\n",
        "\n",
        "model = LightGCN(num_users, num_movies)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My8eqloiBccE"
      },
      "source": [
        "# Loss Function\n",
        "\n",
        "\n",
        "\n",
        "We utilize a Bayesian Personalized Ranking (BPR) loss, a pairwise objective which encourages the predictions of positive samples to be higher than negative samples for each user.\n",
        "\n",
        "\\begin{equation}\n",
        "L_{BPR} = -\\sum_{u = 1}^M \\sum_{i \\in N_u} \\sum_{j \\notin N_u} \\ln{\\sigma(\\hat{y}_{ui} - \\hat{y}_{uj})} + \\lambda ||E^{(0)}||^2 \n",
        "\\end{equation}\n",
        "\n",
        "$\\hat{y}_{u}$: predicted score of a positive sample\n",
        "\n",
        "$\\hat{y}_{uj}$: predicted score of a negative sample\n",
        "\n",
        "$\\lambda$: hyperparameter which controls the L2 regularization strength"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmPs1xS-BYfe"
      },
      "source": [
        "def bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, lambda_val):\n",
        "    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n",
        "\n",
        "    Args:\n",
        "        users_emb_final (torch.Tensor): e_u_k\n",
        "        users_emb_0 (torch.Tensor): e_u_0\n",
        "        pos_items_emb_final (torch.Tensor): positive e_i_k\n",
        "        pos_items_emb_0 (torch.Tensor): positive e_i_0\n",
        "        neg_items_emb_final (torch.Tensor): negative e_i_k\n",
        "        neg_items_emb_0 (torch.Tensor): negative e_i_0\n",
        "        lambda_val (float): lambda value for regularization loss term\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: scalar bpr loss value\n",
        "    \"\"\"\n",
        "    reg_loss = lambda_val * (users_emb_0.norm(2).pow(2) +\n",
        "                             pos_items_emb_0.norm(2).pow(2) +\n",
        "                             neg_items_emb_0.norm(2).pow(2)) # L2 loss\n",
        "\n",
        "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
        "    pos_scores = torch.sum(pos_scores, dim=-1) # predicted scores of positive samples\n",
        "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
        "    neg_scores = torch.sum(neg_scores, dim=-1) # predicted scores of negative samples\n",
        "\n",
        "    loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores)) + reg_loss\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS7HVr3qLQGx"
      },
      "source": [
        "# Evaluation Metrics\n",
        "\n",
        "We evalaluate our model using the following metrics\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{Recall} = \\frac{TP}{TP + FP}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{Precision} = \\frac{TP}{TP + FN}\n",
        "\\end{equation}\n",
        "\n",
        "**Dicounted Cumulative Gain (DCG)** at rank position p is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{DCG}_\\text{p} = \\sum_{i = 1}^p \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
        "\\end{equation}\n",
        "\n",
        "p: a particular rank position\n",
        "\n",
        "$rel_i \\in \\{0, 1\\}$ : graded relevance of the result at position $i$\n",
        "\n",
        "**Idealised Dicounted Cumulative Gain (IDCG)**, namely the maximum possible DCG, at rank position $p$ is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{IDCG}_\\text{p} = \\sum_{i = 1}^{|REL_p|} \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
        "\\end{equation}\n",
        "\n",
        "$|REL_p|$ : list of items ordered by their relevance up to position p\n",
        "\n",
        "**Normalized Dicounted Cumulative Gain (NDCG)** at rank position $p$ is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{nDCG}_\\text{p} = \\frac{\\text{DCG}_p}{\\text{nDCG}_p}\n",
        "\\end{equation}\n",
        "\n",
        "Specifically, we use the metrics recall@K, precision@K, and NDCG@K. @K indicates that these metrics are computed on the top K recommendations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHO2gdhRSwzJ"
      },
      "source": [
        "# helper function to get N_u\n",
        "def get_user_positive_items(edge_index):\n",
        "    \"\"\"Generates dictionary of positive items for each user\n",
        "\n",
        "    Args:\n",
        "        edge_index (torch.Tensor): 2 by N list of edges\n",
        "\n",
        "    Returns:\n",
        "        dict: dictionary of positive items for each user\n",
        "    \"\"\"\n",
        "    user_pos_items = {}\n",
        "    for i in range(edge_index.shape[1]):\n",
        "        user = edge_index[0][i].item()\n",
        "        item = edge_index[1][i].item()\n",
        "        if user not in user_pos_items:\n",
        "            user_pos_items[user] = []\n",
        "        user_pos_items[user].append(item)\n",
        "    return user_pos_items"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8We4BTtfS4NV"
      },
      "source": [
        "# computes recall@K and precision@K\n",
        "def RecallPrecision_ATk(groundTruth, r, k):\n",
        "    \"\"\"Computers recall @ k and precision @ k\n",
        "\n",
        "    Args:\n",
        "        groundTruth (list): list of lists containing highly rated items of each user\n",
        "        r (list): list of lists indicating whether each top k item recommended to each user\n",
        "            is a top k ground truth item or not\n",
        "        k (intg): determines the top k items to compute precision and recall on\n",
        "\n",
        "    Returns:\n",
        "        tuple: recall @ k, precision @ k\n",
        "    \"\"\"\n",
        "    num_correct_pred = torch.sum(r, dim=-1)  # number of correctly predicted items per user\n",
        "    # number of items liked by each user in the test set\n",
        "    user_num_liked = torch.Tensor([len(groundTruth[i])\n",
        "                                  for i in range(len(groundTruth))])\n",
        "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
        "    precision = torch.mean(num_correct_pred) / k\n",
        "    return recall.item(), precision.item()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v4A3Ek4TE02"
      },
      "source": [
        "# computes NDCG@K\n",
        "def NDCGatK_r(groundTruth, r, k):\n",
        "    \"\"\"Computes Normalized Discounted Cumulative Gain (NDCG) @ k\n",
        "\n",
        "    Args:\n",
        "        groundTruth (list): list of lists containing highly rated items of each user\n",
        "        r (list): list of lists indicating whether each top k item recommended to each user\n",
        "            is a top k ground truth item or not\n",
        "        k (int): determines the top k items to compute ndcg on\n",
        "\n",
        "    Returns:\n",
        "        float: ndcg @ k\n",
        "    \"\"\"\n",
        "    assert len(r) == len(groundTruth)\n",
        "\n",
        "    test_matrix = torch.zeros((len(r), k))\n",
        "\n",
        "    for i, items in enumerate(groundTruth):\n",
        "        length = min(len(items), k)\n",
        "        test_matrix[i, :length] = 1\n",
        "    max_r = test_matrix\n",
        "    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)), axis=1)\n",
        "    dcg = r * (1. / torch.log2(torch.arange(2, k + 2)))\n",
        "    dcg = torch.sum(dcg, axis=1)\n",
        "    idcg[idcg == 0.] = 1.\n",
        "    ndcg = dcg / idcg\n",
        "    ndcg[torch.isnan(ndcg)] = 0.\n",
        "    return torch.mean(ndcg).item()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6_741LlTMwI"
      },
      "source": [
        "# wrapper function to get evaluation metrics\n",
        "def get_metrics(model, edge_index, exclude_edge_indices, k):\n",
        "    \"\"\"Computes the evaluation metrics: recall, precision, and ndcg @ k\n",
        "\n",
        "    Args:\n",
        "        model (LighGCN): lightgcn model\n",
        "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
        "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
        "        k (int): determines the top k items to compute metrics on\n",
        "\n",
        "    Returns:\n",
        "        tuple: recall @ k, precision @ k, ndcg @ k\n",
        "    \"\"\"\n",
        "    user_embedding = model.users_emb.weight\n",
        "    item_embedding = model.items_emb.weight\n",
        "\n",
        "    # get ratings between every user and item - shape is num users x num movies\n",
        "    rating = torch.matmul(user_embedding, item_embedding.T)\n",
        "\n",
        "    for exclude_edge_index in exclude_edge_indices:\n",
        "        # gets all the positive items for each user from the edge index\n",
        "        user_pos_items = get_user_positive_items(exclude_edge_index)\n",
        "        # get coordinates of all edges to exclude\n",
        "        exclude_users = []\n",
        "        exclude_items = []\n",
        "        for user, items in user_pos_items.items():\n",
        "            exclude_users.extend([user] * len(items))\n",
        "            exclude_items.extend(items)\n",
        "\n",
        "        # set ratings of excluded edges to large negative value\n",
        "        rating[exclude_users, exclude_items] = -(1 << 10)\n",
        "\n",
        "    # get the top k recommended items for each user\n",
        "    _, top_K_items = torch.topk(rating, k=k)\n",
        "\n",
        "    # get all unique users in evaluated split\n",
        "    users = edge_index[0].unique()\n",
        "\n",
        "    test_user_pos_items = get_user_positive_items(edge_index)\n",
        "\n",
        "    # convert test user pos items dictionary into a list\n",
        "    test_user_pos_items_list = [\n",
        "        test_user_pos_items[user.item()] for user in users]\n",
        "\n",
        "    # determine the correctness of topk predictions\n",
        "    r = []\n",
        "    for user in users:\n",
        "        ground_truth_items = test_user_pos_items[user.item()]\n",
        "        label = list(map(lambda x: x in ground_truth_items, top_K_items[user]))\n",
        "        r.append(label)\n",
        "    r = torch.Tensor(np.array(r).astype('float'))\n",
        "\n",
        "    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n",
        "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
        "\n",
        "    return recall, precision, ndcg"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr_qESXASsVw"
      },
      "source": [
        "# wrapper function to evaluate model\n",
        "def evaluation(model, edge_index, sparse_edge_index, exclude_edge_indices, k, lambda_val):\n",
        "    \"\"\"Evaluates model loss and metrics including recall, precision, ndcg @ k\n",
        "\n",
        "    Args:\n",
        "        model (LighGCN): lightgcn model\n",
        "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
        "        sparse_edge_index (sparseTensor): sparse adjacency matrix for split to evaluate\n",
        "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
        "        k (int): determines the top k items to compute metrics on\n",
        "        lambda_val (float): determines lambda for bpr loss\n",
        "\n",
        "    Returns:\n",
        "        tuple: bpr loss, recall @ k, precision @ k, ndcg @ k\n",
        "    \"\"\"\n",
        "    # get embeddings\n",
        "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
        "        sparse_edge_index)\n",
        "    edges = structured_negative_sampling(\n",
        "        edge_index, contains_neg_self_loops=False)\n",
        "    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
        "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
        "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
        "        pos_item_indices], items_emb_0[pos_item_indices]\n",
        "    print(\"items_emb_final\", items_emb_final)\n",
        "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
        "        neg_item_indices], items_emb_0[neg_item_indices]\n",
        "\n",
        "    loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0,\n",
        "                    neg_items_emb_final, neg_items_emb_0, lambda_val).item()\n",
        "\n",
        "    recall, precision, ndcg = get_metrics(\n",
        "        model, edge_index, exclude_edge_indices, k)\n",
        "\n",
        "    return loss, recall, precision, ndcg"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYw1cUgPTjws"
      },
      "source": [
        "# Training\n",
        "\n",
        "Your test set performance should be in line with the following (*K=20*):\n",
        "\n",
        "*Recall@K: 0.13, Precision@K: 0.045, NDCG@K: 0.10*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQL2W-NQTeFd"
      },
      "source": [
        "# define constants\n",
        "ITERATIONS = 10000\n",
        "#ITERATIONS = 100\n",
        "BATCH_SIZE = 1024\n",
        "LR = 1e-3\n",
        "ITERS_PER_EVAL = 200\n",
        "ITERS_PER_LR_DECAY = 200\n",
        "#ITERS_PER_EVAL = 5\n",
        "#ITERS_PER_LR_DECAY = 5\n",
        "K = 20\n",
        "LAMBDA = 1e-6"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49JDkBtKTfE-",
        "outputId": "809a22ce-e8f1-4416-d54f-9f2fa03a780e"
      },
      "source": [
        "# setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"CUDA: \", device)\n",
        "print(f\"Using device {device}.\")\n",
        "\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "print(\"CUDA: \", device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "edge_index = edge_index.to(device)\n",
        "train_edge_index = train_edge_index.to(device)\n",
        "train_sparse_edge_index = train_sparse_edge_index.to(device)\n",
        "\n",
        "val_edge_index = val_edge_index.to(device)\n",
        "val_sparse_edge_index = val_sparse_edge_index.to(device)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA:  cuda\n",
            "Using device cuda.\n",
            "CUDA:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.current_device()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHak7uNAJdrs",
        "outputId": "3d66854f-7407-41ba-b25f-7f8f2c97e330"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.device('cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkGKyxQSJ9iq",
        "outputId": "72a98d8b-7595-49f9-d125-b7c406c13d95"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYjrDp1w-hiP",
        "outputId": "4978d19a-3d3d-4086-a45d-f2bcb616f539"
      },
      "source": [
        "# training loop\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "neg_items_emb_final2 = neg_items_emb_02 = items_emb_final2 = items_emb_02 = neg_item_indices2 = []\n",
        "\n",
        "for iter in range(ITERATIONS):\n",
        "    # forward propagation\n",
        "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
        "        train_sparse_edge_index)\n",
        "\n",
        "    # mini batching\n",
        "    user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(\n",
        "        BATCH_SIZE, train_edge_index)\n",
        "    user_indices, pos_item_indices, neg_item_indices = user_indices.to(\n",
        "        device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
        "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
        "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
        "        pos_item_indices], items_emb_0[pos_item_indices]\n",
        "\n",
        "    items_emb_final2, items_emb_02, neg_item_indices2 = items_emb_final, items_emb_0, neg_item_indices \n",
        "    #neg_item_indices2 = neg_item_indices\n",
        "\n",
        "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
        "        neg_item_indices], items_emb_0[neg_item_indices]\n",
        "    \n",
        "    neg_items_emb_final2, neg_items_emb_02 = neg_items_emb_final, neg_items_emb_0\n",
        "    # loss computation\n",
        "    train_loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final,\n",
        "                          pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, LAMBDA)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if iter % ITERS_PER_EVAL == 0:\n",
        "        model.eval()\n",
        "        val_loss, recall, precision, ndcg = evaluation(\n",
        "            model, val_edge_index, val_sparse_edge_index, [train_edge_index], K, LAMBDA)\n",
        "        print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\")\n",
        "        train_losses.append(train_loss.item())\n",
        "        val_losses.append(val_loss)\n",
        "        model.train()\n",
        "\n",
        "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
        "        scheduler.step()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "items_emb_final tensor([[-0.0128,  0.0235,  0.0491,  ..., -0.0389,  0.0126, -0.0476],\n",
            "        [ 0.0037,  0.0241,  0.0082,  ..., -0.0015, -0.0124,  0.0279],\n",
            "        [-0.0077, -0.0042,  0.0121,  ..., -0.0148, -0.0042, -0.0113],\n",
            "        ...,\n",
            "        [ 0.0349,  0.0237,  0.0219,  ...,  0.0196,  0.0421,  0.0109],\n",
            "        [-0.0604, -0.0379,  0.0692,  ..., -0.0260, -0.0055,  0.0382],\n",
            "        [ 0.0355, -0.0100, -0.0004,  ..., -0.0044,  0.0151, -0.0102]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 0/10000] train_loss: -0.69132, val_loss: -0.68386, val_recall@20: 0.00245, val_precision@20: 0.00054, val_ndcg@20: 0.00105\n",
            "items_emb_final tensor([[-0.0162,  0.0317,  0.0389,  ..., -0.0419,  0.0337, -0.0694],\n",
            "        [ 0.0158,  0.0147,  0.0041,  ...,  0.0017,  0.0015,  0.0121],\n",
            "        [-0.0012,  0.0015,  0.0032,  ..., -0.0130,  0.0025, -0.0252],\n",
            "        ...,\n",
            "        [ 0.0318,  0.0180,  0.0180,  ...,  0.0186,  0.0361,  0.0114],\n",
            "        [-0.0590, -0.0465,  0.0688,  ..., -0.0280, -0.0086,  0.0439],\n",
            "        [ 0.0312, -0.0069, -0.0002,  ...,  0.0035,  0.0167, -0.0042]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 200/10000] train_loss: -0.69851, val_loss: -0.6891, val_recall@20: 0.05265, val_precision@20: 0.01447, val_ndcg@20: 0.03305\n",
            "items_emb_final tensor([[-0.0820,  0.1029, -0.0348,  ..., -0.1135,  0.1117, -0.1485],\n",
            "        [-0.0115,  0.0597, -0.0525,  ..., -0.0442,  0.0589, -0.0426],\n",
            "        [-0.0172,  0.0214, -0.0186,  ..., -0.0359,  0.0196, -0.0477],\n",
            "        ...,\n",
            "        [ 0.0415,  0.0042,  0.0322,  ...,  0.0346,  0.0183,  0.0314],\n",
            "        [-0.0435, -0.0613,  0.0879,  ..., -0.0079, -0.0342,  0.0681],\n",
            "        [ 0.0418, -0.0209,  0.0131,  ...,  0.0147,  0.0006,  0.0110]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 400/10000] train_loss: -0.87107, val_loss: -0.81825, val_recall@20: 0.14422, val_precision@20: 0.04204, val_ndcg@20: 0.10438\n",
            "items_emb_final tensor([[-0.1717,  0.1928, -0.1202,  ..., -0.2031,  0.1956, -0.2309],\n",
            "        [-0.0811,  0.1298, -0.1203,  ..., -0.1144,  0.1259, -0.1078],\n",
            "        [-0.0453,  0.0502, -0.0467,  ..., -0.0642,  0.0463, -0.0749],\n",
            "        ...,\n",
            "        [ 0.0693, -0.0253,  0.0591,  ...,  0.0633, -0.0089,  0.0594],\n",
            "        [-0.0163, -0.0876,  0.1133,  ...,  0.0185, -0.0595,  0.0928],\n",
            "        [ 0.0647, -0.0430,  0.0352,  ...,  0.0367, -0.0208,  0.0331]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 600/10000] train_loss: -1.75434, val_loss: -1.52858, val_recall@20: 0.14569, val_precision@20: 0.04403, val_ndcg@20: 0.1065\n",
            "items_emb_final tensor([[-0.2486,  0.2682, -0.1936,  ..., -0.2784,  0.2682, -0.3037],\n",
            "        [-0.1390,  0.1869, -0.1761,  ..., -0.1719,  0.1809, -0.1628],\n",
            "        [-0.0749,  0.0802, -0.0755,  ..., -0.0946,  0.0746, -0.1029],\n",
            "        ...,\n",
            "        [ 0.0950, -0.0519,  0.0850,  ...,  0.0890, -0.0341,  0.0851],\n",
            "        [ 0.0066, -0.1108,  0.1356,  ...,  0.0411, -0.0816,  0.1147],\n",
            "        [ 0.0811, -0.0597,  0.0514,  ...,  0.0526, -0.0366,  0.0493]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 800/10000] train_loss: -3.57655, val_loss: -2.86241, val_recall@20: 0.14691, val_precision@20: 0.04476, val_ndcg@20: 0.10726\n",
            "items_emb_final tensor([[-0.3090,  0.3274, -0.2520,  ..., -0.3374,  0.3262, -0.3616],\n",
            "        [-0.1774,  0.2255, -0.2138,  ..., -0.2103,  0.2182, -0.2001],\n",
            "        [-0.1052,  0.1102, -0.1057,  ..., -0.1251,  0.1036, -0.1321],\n",
            "        ...,\n",
            "        [ 0.1176, -0.0748,  0.1074,  ...,  0.1116, -0.0562,  0.1069],\n",
            "        [ 0.0310, -0.1354,  0.1594,  ...,  0.0655, -0.1051,  0.1387],\n",
            "        [ 0.0965, -0.0756,  0.0669,  ...,  0.0683, -0.0519,  0.0645]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 1000/10000] train_loss: -5.57863, val_loss: -4.44205, val_recall@20: 0.15051, val_precision@20: 0.04566, val_ndcg@20: 0.10819\n",
            "items_emb_final tensor([[-0.3609,  0.3788, -0.3029,  ..., -0.3886,  0.3764, -0.4118],\n",
            "        [-0.2209,  0.2689, -0.2564,  ..., -0.2535,  0.2605, -0.2421],\n",
            "        [-0.1292,  0.1343, -0.1294,  ..., -0.1492,  0.1271, -0.1556],\n",
            "        ...,\n",
            "        [ 0.1330, -0.0901,  0.1225,  ...,  0.1267, -0.0715,  0.1219],\n",
            "        [ 0.0497, -0.1543,  0.1778,  ...,  0.0840, -0.1230,  0.1570],\n",
            "        [ 0.1109, -0.0900,  0.0815,  ...,  0.0828, -0.0659,  0.0794]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 1200/10000] train_loss: -7.76776, val_loss: -6.26219, val_recall@20: 0.15144, val_precision@20: 0.04566, val_ndcg@20: 0.10823\n",
            "items_emb_final tensor([[-0.4098,  0.4273, -0.3510,  ..., -0.4371,  0.4241, -0.4594],\n",
            "        [-0.2574,  0.3053, -0.2922,  ..., -0.2897,  0.2960, -0.2778],\n",
            "        [-0.1524,  0.1573, -0.1523,  ..., -0.1723,  0.1499, -0.1781],\n",
            "        ...,\n",
            "        [ 0.1482, -0.1056,  0.1374,  ...,  0.1417, -0.0867,  0.1366],\n",
            "        [ 0.0665, -0.1711,  0.1944,  ...,  0.1008, -0.1397,  0.1736],\n",
            "        [ 0.1270, -0.1063,  0.0977,  ...,  0.0985, -0.0817,  0.0953]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 1400/10000] train_loss: -9.71186, val_loss: -8.15498, val_recall@20: 0.15277, val_precision@20: 0.0462, val_ndcg@20: 0.10879\n",
            "items_emb_final tensor([[-0.4551,  0.4722, -0.3956,  ..., -0.4819,  0.4684, -0.5036],\n",
            "        [-0.2935,  0.3412, -0.3277,  ..., -0.3254,  0.3314, -0.3133],\n",
            "        [-0.1712,  0.1762, -0.1711,  ..., -0.1914,  0.1684, -0.1968],\n",
            "        ...,\n",
            "        [ 0.1634, -0.1205,  0.1520,  ...,  0.1564, -0.1013,  0.1513],\n",
            "        [ 0.0853, -0.1898,  0.2130,  ...,  0.1196, -0.1584,  0.1921],\n",
            "        [ 0.1432, -0.1222,  0.1138,  ...,  0.1145, -0.0976,  0.1114]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 1600/10000] train_loss: -12.30175, val_loss: -10.1781, val_recall@20: 0.15185, val_precision@20: 0.04584, val_ndcg@20: 0.10834\n",
            "items_emb_final tensor([[-0.4933,  0.5102, -0.4335,  ..., -0.5198,  0.5061, -0.5411],\n",
            "        [-0.3213,  0.3690, -0.3553,  ..., -0.3532,  0.3587, -0.3407],\n",
            "        [-0.1845,  0.1894, -0.1841,  ..., -0.2046,  0.1817, -0.2100],\n",
            "        ...,\n",
            "        [ 0.1714, -0.1285,  0.1599,  ...,  0.1643, -0.1093,  0.1594],\n",
            "        [ 0.0988, -0.2032,  0.2264,  ...,  0.1330, -0.1718,  0.2056],\n",
            "        [ 0.1590, -0.1383,  0.1298,  ...,  0.1305, -0.1133,  0.1272]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 1800/10000] train_loss: -15.258, val_loss: -12.07168, val_recall@20: 0.1528, val_precision@20: 0.04602, val_ndcg@20: 0.10877\n",
            "items_emb_final tensor([[-0.5323,  0.5491, -0.4724,  ..., -0.5586,  0.5447, -0.5796],\n",
            "        [-0.3501,  0.3977, -0.3837,  ..., -0.3818,  0.3872, -0.3691],\n",
            "        [-0.2042,  0.2091, -0.2037,  ..., -0.2243,  0.2012, -0.2294],\n",
            "        ...,\n",
            "        [ 0.1856, -0.1427,  0.1742,  ...,  0.1786, -0.1232,  0.1734],\n",
            "        [ 0.1101, -0.2146,  0.2378,  ...,  0.1443, -0.1832,  0.2169],\n",
            "        [ 0.1686, -0.1479,  0.1395,  ...,  0.1400, -0.1229,  0.1367]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 2000/10000] train_loss: -17.36575, val_loss: -14.12648, val_recall@20: 0.15191, val_precision@20: 0.04575, val_ndcg@20: 0.10837\n",
            "items_emb_final tensor([[-0.5665,  0.5832, -0.5063,  ..., -0.5926,  0.5785, -0.6135],\n",
            "        [-0.3747,  0.4222, -0.4081,  ..., -0.4063,  0.4115, -0.3934],\n",
            "        [-0.2197,  0.2246, -0.2191,  ..., -0.2398,  0.2165, -0.2447],\n",
            "        ...,\n",
            "        [ 0.1983, -0.1555,  0.1870,  ...,  0.1912, -0.1358,  0.1861],\n",
            "        [ 0.1220, -0.2263,  0.2496,  ...,  0.1560, -0.1949,  0.2288],\n",
            "        [ 0.1790, -0.1582,  0.1499,  ...,  0.1503, -0.1331,  0.1470]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 2200/10000] train_loss: -19.70225, val_loss: -16.29816, val_recall@20: 0.15307, val_precision@20: 0.04629, val_ndcg@20: 0.10909\n",
            "items_emb_final tensor([[-0.5986,  0.6153, -0.5383,  ..., -0.6247,  0.6104, -0.6453],\n",
            "        [-0.3975,  0.4449, -0.4307,  ..., -0.4289,  0.4341, -0.4160],\n",
            "        [-0.2312,  0.2361, -0.2306,  ..., -0.2513,  0.2279, -0.2562],\n",
            "        ...,\n",
            "        [ 0.2098, -0.1671,  0.1986,  ...,  0.2029, -0.1474,  0.1975],\n",
            "        [ 0.1326, -0.2368,  0.2601,  ...,  0.1665, -0.2053,  0.2392],\n",
            "        [ 0.1886, -0.1677,  0.1594,  ...,  0.1598, -0.1425,  0.1565]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 2400/10000] train_loss: -21.49827, val_loss: -18.02916, val_recall@20: 0.15191, val_precision@20: 0.04602, val_ndcg@20: 0.10862\n",
            "items_emb_final tensor([[-0.6286,  0.6452, -0.5681,  ..., -0.6546,  0.6401, -0.6750],\n",
            "        [-0.4192,  0.4665, -0.4521,  ..., -0.4504,  0.4556, -0.4375],\n",
            "        [-0.2445,  0.2494, -0.2439,  ..., -0.2647,  0.2412, -0.2694],\n",
            "        ...,\n",
            "        [ 0.2162, -0.1735,  0.2050,  ...,  0.2092, -0.1538,  0.2040],\n",
            "        [ 0.1417, -0.2461,  0.2694,  ...,  0.1756, -0.2145,  0.2485],\n",
            "        [ 0.1961, -0.1753,  0.1671,  ...,  0.1673, -0.1500,  0.1640]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 2600/10000] train_loss: -24.93695, val_loss: -20.15694, val_recall@20: 0.15243, val_precision@20: 0.04611, val_ndcg@20: 0.10866\n",
            "items_emb_final tensor([[-0.6549,  0.6714, -0.5942,  ..., -0.6808,  0.6663, -0.7011],\n",
            "        [-0.4402,  0.4875, -0.4731,  ..., -0.4715,  0.4765, -0.4584],\n",
            "        [-0.2536,  0.2585, -0.2529,  ..., -0.2738,  0.2502, -0.2784],\n",
            "        ...,\n",
            "        [ 0.2272, -0.1845,  0.2160,  ...,  0.2202, -0.1648,  0.2149],\n",
            "        [ 0.1523, -0.2566,  0.2801,  ...,  0.1862, -0.2250,  0.2590],\n",
            "        [ 0.2106, -0.1896,  0.1813,  ...,  0.1817, -0.1642,  0.1784]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 2800/10000] train_loss: -26.64981, val_loss: -21.96709, val_recall@20: 0.1522, val_precision@20: 0.04611, val_ndcg@20: 0.10852\n",
            "items_emb_final tensor([[-0.6802,  0.6966, -0.6194,  ..., -0.7061,  0.6914, -0.7263],\n",
            "        [-0.4585,  0.5057, -0.4913,  ..., -0.4897,  0.4946, -0.4766],\n",
            "        [-0.2675,  0.2724, -0.2668,  ..., -0.2878,  0.2641, -0.2923],\n",
            "        ...,\n",
            "        [ 0.2353, -0.1926,  0.2241,  ...,  0.2283, -0.1727,  0.2230],\n",
            "        [ 0.1571, -0.2615,  0.2850,  ...,  0.1911, -0.2299,  0.2639],\n",
            "        [ 0.2156, -0.1947,  0.1864,  ...,  0.1868, -0.1693,  0.1835]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 3000/10000] train_loss: -29.71596, val_loss: -23.81626, val_recall@20: 0.1522, val_precision@20: 0.04611, val_ndcg@20: 0.10858\n",
            "items_emb_final tensor([[-0.7044,  0.7208, -0.6436,  ..., -0.7302,  0.7155, -0.7504],\n",
            "        [-0.4773,  0.5244, -0.5100,  ..., -0.5084,  0.5132, -0.4952],\n",
            "        [-0.2776,  0.2825, -0.2769,  ..., -0.2979,  0.2741, -0.3024],\n",
            "        ...,\n",
            "        [ 0.2459, -0.2031,  0.2346,  ...,  0.2389, -0.1832,  0.2335],\n",
            "        [ 0.1666, -0.2710,  0.2943,  ...,  0.2005, -0.2392,  0.2732],\n",
            "        [ 0.2242, -0.2032,  0.1949,  ...,  0.1953, -0.1778,  0.1921]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 3200/10000] train_loss: -30.17258, val_loss: -25.53701, val_recall@20: 0.15236, val_precision@20: 0.04629, val_ndcg@20: 0.10854\n",
            "items_emb_final tensor([[-0.7285,  0.7449, -0.6676,  ..., -0.7543,  0.7395, -0.7744],\n",
            "        [-0.4929,  0.5401, -0.5256,  ..., -0.5241,  0.5289, -0.5108],\n",
            "        [-0.2909,  0.2958, -0.2902,  ..., -0.3113,  0.2874, -0.3157],\n",
            "        ...,\n",
            "        [ 0.2560, -0.2132,  0.2447,  ...,  0.2490, -0.1933,  0.2437],\n",
            "        [ 0.1763, -0.2808,  0.3041,  ...,  0.2102, -0.2489,  0.2830],\n",
            "        [ 0.2305, -0.2096,  0.2013,  ...,  0.2016, -0.1841,  0.1984]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 3400/10000] train_loss: -33.11581, val_loss: -27.24221, val_recall@20: 0.15231, val_precision@20: 0.04611, val_ndcg@20: 0.10849\n",
            "items_emb_final tensor([[-0.7501,  0.7664, -0.6891,  ..., -0.7758,  0.7610, -0.7958],\n",
            "        [-0.5106,  0.5578, -0.5432,  ..., -0.5417,  0.5465, -0.5285],\n",
            "        [-0.3009,  0.3058, -0.3002,  ..., -0.3213,  0.2974, -0.3257],\n",
            "        ...,\n",
            "        [ 0.2625, -0.2197,  0.2512,  ...,  0.2556, -0.1998,  0.2502],\n",
            "        [ 0.1833, -0.2878,  0.3112,  ...,  0.2172, -0.2560,  0.2900],\n",
            "        [ 0.2381, -0.2172,  0.2089,  ...,  0.2093, -0.1917,  0.2061]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 3600/10000] train_loss: -35.88597, val_loss: -28.55779, val_recall@20: 0.1519, val_precision@20: 0.04611, val_ndcg@20: 0.10846\n",
            "items_emb_final tensor([[-0.7710,  0.7873, -0.7100,  ..., -0.7967,  0.7818, -0.8167],\n",
            "        [-0.5261,  0.5733, -0.5587,  ..., -0.5572,  0.5620, -0.5440],\n",
            "        [-0.3080,  0.3129, -0.3072,  ..., -0.3284,  0.3044, -0.3327],\n",
            "        ...,\n",
            "        [ 0.2698, -0.2271,  0.2585,  ...,  0.2629, -0.2071,  0.2575],\n",
            "        [ 0.1931, -0.2975,  0.3208,  ...,  0.2269, -0.2656,  0.2997],\n",
            "        [ 0.2439, -0.2230,  0.2148,  ...,  0.2151, -0.1975,  0.2120]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 3800/10000] train_loss: -37.65072, val_loss: -30.22192, val_recall@20: 0.15246, val_precision@20: 0.04611, val_ndcg@20: 0.10868\n",
            "items_emb_final tensor([[-0.7899,  0.8062, -0.7289,  ..., -0.8156,  0.8007, -0.8355],\n",
            "        [-0.5374,  0.5845, -0.5699,  ..., -0.5684,  0.5732, -0.5552],\n",
            "        [-0.3170,  0.3219, -0.3162,  ..., -0.3374,  0.3134, -0.3417],\n",
            "        ...,\n",
            "        [ 0.2746, -0.2319,  0.2633,  ...,  0.2678, -0.2119,  0.2623],\n",
            "        [ 0.2008, -0.3053,  0.3286,  ...,  0.2347, -0.2734,  0.3074],\n",
            "        [ 0.2496, -0.2286,  0.2204,  ...,  0.2208, -0.2032,  0.2177]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 4000/10000] train_loss: -38.74022, val_loss: -32.18452, val_recall@20: 0.15215, val_precision@20: 0.04611, val_ndcg@20: 0.1086\n",
            "items_emb_final tensor([[-0.8085,  0.8247, -0.7474,  ..., -0.8341,  0.8191, -0.8540],\n",
            "        [-0.5491,  0.5963, -0.5816,  ..., -0.5801,  0.5849, -0.5669],\n",
            "        [-0.3271,  0.3320, -0.3264,  ..., -0.3476,  0.3235, -0.3519],\n",
            "        ...,\n",
            "        [ 0.2811, -0.2385,  0.2698,  ...,  0.2742, -0.2183,  0.2688],\n",
            "        [ 0.2072, -0.3117,  0.3350,  ...,  0.2411, -0.2798,  0.3138],\n",
            "        [ 0.2548, -0.2339,  0.2256,  ...,  0.2260, -0.2084,  0.2230]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 4200/10000] train_loss: -39.9811, val_loss: -33.36148, val_recall@20: 0.15195, val_precision@20: 0.04602, val_ndcg@20: 0.10828\n",
            "items_emb_final tensor([[-0.8263,  0.8425, -0.7652,  ..., -0.8519,  0.8370, -0.8718],\n",
            "        [-0.5623,  0.6095, -0.5949,  ..., -0.5934,  0.5982, -0.5801],\n",
            "        [-0.3329,  0.3378, -0.3321,  ..., -0.3533,  0.3292, -0.3576],\n",
            "        ...,\n",
            "        [ 0.2876, -0.2449,  0.2763,  ...,  0.2807, -0.2248,  0.2752],\n",
            "        [ 0.2120, -0.3165,  0.3398,  ...,  0.2459, -0.2846,  0.3185],\n",
            "        [ 0.2595, -0.2385,  0.2303,  ...,  0.2307, -0.2131,  0.2277]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 4400/10000] train_loss: -43.64149, val_loss: -34.59009, val_recall@20: 0.1522, val_precision@20: 0.04611, val_ndcg@20: 0.10859\n",
            "items_emb_final tensor([[-0.8423,  0.8585, -0.7812,  ..., -0.8679,  0.8530, -0.8878],\n",
            "        [-0.5756,  0.6228, -0.6082,  ..., -0.6067,  0.6115, -0.5934],\n",
            "        [-0.3405,  0.3455, -0.3398,  ..., -0.3610,  0.3368, -0.3653],\n",
            "        ...,\n",
            "        [ 0.2930, -0.2503,  0.2818,  ...,  0.2861, -0.2303,  0.2807],\n",
            "        [ 0.2166, -0.3211,  0.3443,  ...,  0.2505, -0.2891,  0.3231],\n",
            "        [ 0.2641, -0.2431,  0.2349,  ...,  0.2353, -0.2177,  0.2323]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 4600/10000] train_loss: -43.68713, val_loss: -36.57888, val_recall@20: 0.15219, val_precision@20: 0.04611, val_ndcg@20: 0.10857\n",
            "items_emb_final tensor([[-0.8558,  0.8720, -0.7946,  ..., -0.8814,  0.8664, -0.9012],\n",
            "        [-0.5852,  0.6324, -0.6178,  ..., -0.6163,  0.6210, -0.6029],\n",
            "        [-0.3467,  0.3517, -0.3460,  ..., -0.3673,  0.3431, -0.3716],\n",
            "        ...,\n",
            "        [ 0.2975, -0.2548,  0.2863,  ...,  0.2906, -0.2348,  0.2852],\n",
            "        [ 0.2218, -0.3263,  0.3495,  ...,  0.2557, -0.2943,  0.3283],\n",
            "        [ 0.2681, -0.2471,  0.2390,  ...,  0.2393, -0.2216,  0.2363]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 4800/10000] train_loss: -45.89561, val_loss: -37.54554, val_recall@20: 0.1518, val_precision@20: 0.04602, val_ndcg@20: 0.10851\n",
            "items_emb_final tensor([[-0.8698,  0.8860, -0.8086,  ..., -0.8954,  0.8804, -0.9152],\n",
            "        [-0.5947,  0.6420, -0.6273,  ..., -0.6258,  0.6306, -0.6125],\n",
            "        [-0.3519,  0.3569, -0.3512,  ..., -0.3724,  0.3482, -0.3767],\n",
            "        ...,\n",
            "        [ 0.3037, -0.2609,  0.2924,  ...,  0.2967, -0.2409,  0.2913],\n",
            "        [ 0.2264, -0.3308,  0.3541,  ...,  0.2602, -0.2989,  0.3330],\n",
            "        [ 0.2700, -0.2491,  0.2409,  ...,  0.2412, -0.2236,  0.2383]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 5000/10000] train_loss: -49.14638, val_loss: -39.3362, val_recall@20: 0.15182, val_precision@20: 0.04602, val_ndcg@20: 0.10852\n",
            "items_emb_final tensor([[-0.8829,  0.8990, -0.8217,  ..., -0.9085,  0.8935, -0.9283],\n",
            "        [-0.6036,  0.6508, -0.6362,  ..., -0.6347,  0.6395, -0.6213],\n",
            "        [-0.3567,  0.3618, -0.3561,  ..., -0.3773,  0.3531, -0.3816],\n",
            "        ...,\n",
            "        [ 0.3069, -0.2643,  0.2957,  ...,  0.3000, -0.2442,  0.2945],\n",
            "        [ 0.2298, -0.3343,  0.3576,  ...,  0.2637, -0.3024,  0.3364],\n",
            "        [ 0.2728, -0.2518,  0.2437,  ...,  0.2440, -0.2263,  0.2410]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 5200/10000] train_loss: -47.224, val_loss: -40.34384, val_recall@20: 0.1522, val_precision@20: 0.04611, val_ndcg@20: 0.10858\n",
            "items_emb_final tensor([[-0.8947,  0.9108, -0.8335,  ..., -0.9202,  0.9052, -0.9400],\n",
            "        [-0.6129,  0.6601, -0.6455,  ..., -0.6440,  0.6488, -0.6306],\n",
            "        [-0.3616,  0.3666, -0.3609,  ..., -0.3822,  0.3579, -0.3864],\n",
            "        ...,\n",
            "        [ 0.3112, -0.2685,  0.2999,  ...,  0.3042, -0.2484,  0.2987],\n",
            "        [ 0.2336, -0.3380,  0.3613,  ...,  0.2674, -0.3061,  0.3401],\n",
            "        [ 0.2775, -0.2566,  0.2484,  ...,  0.2488, -0.2310,  0.2458]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 5400/10000] train_loss: -51.41805, val_loss: -41.26614, val_recall@20: 0.15182, val_precision@20: 0.04602, val_ndcg@20: 0.10843\n",
            "items_emb_final tensor([[-0.9065,  0.9226, -0.8453,  ..., -0.9320,  0.9170, -0.9518],\n",
            "        [-0.6224,  0.6697, -0.6550,  ..., -0.6536,  0.6583, -0.6402],\n",
            "        [-0.3661,  0.3712, -0.3655,  ..., -0.3867,  0.3625, -0.3910],\n",
            "        ...,\n",
            "        [ 0.3153, -0.2726,  0.3039,  ...,  0.3083, -0.2525,  0.3028],\n",
            "        [ 0.2377, -0.3421,  0.3654,  ...,  0.2715, -0.3102,  0.3442],\n",
            "        [ 0.2800, -0.2590,  0.2509,  ...,  0.2513, -0.2335,  0.2483]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 5600/10000] train_loss: -50.28497, val_loss: -42.48615, val_recall@20: 0.15237, val_precision@20: 0.0462, val_ndcg@20: 0.10849\n",
            "items_emb_final tensor([[-0.9172,  0.9334, -0.8560,  ..., -0.9427,  0.9277, -0.9625],\n",
            "        [-0.6303,  0.6775, -0.6628,  ..., -0.6614,  0.6662, -0.6480],\n",
            "        [-0.3696,  0.3746, -0.3690,  ..., -0.3902,  0.3660, -0.3945],\n",
            "        ...,\n",
            "        [ 0.3186, -0.2759,  0.3073,  ...,  0.3117, -0.2559,  0.3062],\n",
            "        [ 0.2404, -0.3448,  0.3681,  ...,  0.2742, -0.3129,  0.3469],\n",
            "        [ 0.2825, -0.2616,  0.2535,  ...,  0.2538, -0.2361,  0.2509]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 5800/10000] train_loss: -53.15616, val_loss: -43.5545, val_recall@20: 0.15244, val_precision@20: 0.04629, val_ndcg@20: 0.10859\n",
            "items_emb_final tensor([[-0.9279,  0.9440, -0.8666,  ..., -0.9534,  0.9384, -0.9732],\n",
            "        [-0.6389,  0.6861, -0.6714,  ..., -0.6700,  0.6747, -0.6566],\n",
            "        [-0.3743,  0.3793, -0.3736,  ..., -0.3949,  0.3706, -0.3991],\n",
            "        ...,\n",
            "        [ 0.3224, -0.2797,  0.3111,  ...,  0.3155, -0.2596,  0.3100],\n",
            "        [ 0.2432, -0.3476,  0.3709,  ...,  0.2770, -0.3157,  0.3497],\n",
            "        [ 0.2860, -0.2651,  0.2570,  ...,  0.2573, -0.2396,  0.2544]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 6000/10000] train_loss: -56.87651, val_loss: -44.35613, val_recall@20: 0.15244, val_precision@20: 0.04629, val_ndcg@20: 0.10862\n",
            "items_emb_final tensor([[-0.9381,  0.9543, -0.8769,  ..., -0.9636,  0.9486, -0.9834],\n",
            "        [-0.6466,  0.6938, -0.6791,  ..., -0.6777,  0.6824, -0.6643],\n",
            "        [-0.3783,  0.3833, -0.3776,  ..., -0.3989,  0.3746, -0.4031],\n",
            "        ...,\n",
            "        [ 0.3264, -0.2836,  0.3150,  ...,  0.3194, -0.2636,  0.3139],\n",
            "        [ 0.2473, -0.3517,  0.3750,  ...,  0.2811, -0.3198,  0.3538],\n",
            "        [ 0.2869, -0.2660,  0.2580,  ...,  0.2582, -0.2405,  0.2554]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 6200/10000] train_loss: -54.82373, val_loss: -45.50474, val_recall@20: 0.15333, val_precision@20: 0.04638, val_ndcg@20: 0.10895\n",
            "items_emb_final tensor([[-0.9469,  0.9630, -0.8856,  ..., -0.9724,  0.9573, -0.9921],\n",
            "        [-0.6541,  0.7013, -0.6866,  ..., -0.6852,  0.6899, -0.6718],\n",
            "        [-0.3831,  0.3881, -0.3825,  ..., -0.4037,  0.3794, -0.4079],\n",
            "        ...,\n",
            "        [ 0.3298, -0.2871,  0.3185,  ...,  0.3229, -0.2670,  0.3174],\n",
            "        [ 0.2510, -0.3554,  0.3787,  ...,  0.2848, -0.3235,  0.3576],\n",
            "        [ 0.2895, -0.2687,  0.2606,  ...,  0.2609, -0.2431,  0.2580]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 6400/10000] train_loss: -56.88322, val_loss: -46.33723, val_recall@20: 0.15333, val_precision@20: 0.04638, val_ndcg@20: 0.10902\n",
            "items_emb_final tensor([[-0.9556,  0.9717, -0.8943,  ..., -0.9811,  0.9661, -1.0009],\n",
            "        [-0.6608,  0.7081, -0.6933,  ..., -0.6919,  0.6967, -0.6786],\n",
            "        [-0.3865,  0.3915, -0.3858,  ..., -0.4071,  0.3828, -0.4113],\n",
            "        ...,\n",
            "        [ 0.3337, -0.2910,  0.3224,  ...,  0.3268, -0.2709,  0.3213],\n",
            "        [ 0.2544, -0.3588,  0.3821,  ...,  0.2882, -0.3269,  0.3609],\n",
            "        [ 0.2935, -0.2726,  0.2646,  ...,  0.2648, -0.2470,  0.2619]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 6600/10000] train_loss: -58.57674, val_loss: -47.87561, val_recall@20: 0.15341, val_precision@20: 0.04647, val_ndcg@20: 0.10908\n",
            "items_emb_final tensor([[-0.9641,  0.9802, -0.9028,  ..., -0.9895,  0.9745, -1.0093],\n",
            "        [-0.6667,  0.7140, -0.6993,  ..., -0.6979,  0.7026, -0.6845],\n",
            "        [-0.3909,  0.3959, -0.3903,  ..., -0.4116,  0.3872, -0.4158],\n",
            "        ...,\n",
            "        [ 0.3365, -0.2938,  0.3252,  ...,  0.3296, -0.2737,  0.3240],\n",
            "        [ 0.2589, -0.3633,  0.3865,  ...,  0.2927, -0.3313,  0.3654],\n",
            "        [ 0.2966, -0.2758,  0.2677,  ...,  0.2680, -0.2502,  0.2651]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 6800/10000] train_loss: -58.99072, val_loss: -48.25014, val_recall@20: 0.15401, val_precision@20: 0.04656, val_ndcg@20: 0.10927\n",
            "items_emb_final tensor([[-0.9720,  0.9881, -0.9107,  ..., -0.9975,  0.9825, -1.0172],\n",
            "        [-0.6729,  0.7202, -0.7055,  ..., -0.7041,  0.7088, -0.6907],\n",
            "        [-0.3927,  0.3978, -0.3921,  ..., -0.4134,  0.3890, -0.4176],\n",
            "        ...,\n",
            "        [ 0.3396, -0.2970,  0.3283,  ...,  0.3327, -0.2768,  0.3272],\n",
            "        [ 0.2614, -0.3658,  0.3890,  ...,  0.2952, -0.3338,  0.3679],\n",
            "        [ 0.2990, -0.2781,  0.2701,  ...,  0.2703, -0.2525,  0.2675]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 7000/10000] train_loss: -61.39973, val_loss: -48.80154, val_recall@20: 0.1522, val_precision@20: 0.04647, val_ndcg@20: 0.10887\n",
            "items_emb_final tensor([[-0.9795,  0.9957, -0.9183,  ..., -1.0050,  0.9900, -1.0248],\n",
            "        [-0.6786,  0.7258, -0.7111,  ..., -0.7097,  0.7145, -0.6964],\n",
            "        [-0.3951,  0.4001, -0.3945,  ..., -0.4158,  0.3914, -0.4200],\n",
            "        ...,\n",
            "        [ 0.3431, -0.3004,  0.3317,  ...,  0.3362, -0.2803,  0.3306],\n",
            "        [ 0.2637, -0.3681,  0.3914,  ...,  0.2975, -0.3361,  0.3702],\n",
            "        [ 0.3004, -0.2795,  0.2715,  ...,  0.2717, -0.2539,  0.2689]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 7200/10000] train_loss: -57.85418, val_loss: -50.15365, val_recall@20: 0.15406, val_precision@20: 0.04665, val_ndcg@20: 0.1092\n",
            "items_emb_final tensor([[-0.9870,  1.0031, -0.9257,  ..., -1.0125,  0.9974, -1.0322],\n",
            "        [-0.6842,  0.7314, -0.7167,  ..., -0.7153,  0.7200, -0.7019],\n",
            "        [-0.3980,  0.4030, -0.3973,  ..., -0.4186,  0.3942, -0.4228],\n",
            "        ...,\n",
            "        [ 0.3461, -0.3034,  0.3347,  ...,  0.3392, -0.2833,  0.3336],\n",
            "        [ 0.2662, -0.3706,  0.3938,  ...,  0.3000, -0.3386,  0.3727],\n",
            "        [ 0.3022, -0.2814,  0.2734,  ...,  0.2736, -0.2558,  0.2708]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 7400/10000] train_loss: -61.29612, val_loss: -50.19307, val_recall@20: 0.15401, val_precision@20: 0.04656, val_ndcg@20: 0.10906\n",
            "items_emb_final tensor([[-0.9940,  1.0101, -0.9327,  ..., -1.0194,  1.0044, -1.0392],\n",
            "        [-0.6889,  0.7362, -0.7214,  ..., -0.7200,  0.7248, -0.7067],\n",
            "        [-0.4007,  0.4057, -0.4001,  ..., -0.4214,  0.3970, -0.4256],\n",
            "        ...,\n",
            "        [ 0.3471, -0.3044,  0.3357,  ...,  0.3402, -0.2843,  0.3346],\n",
            "        [ 0.2688, -0.3732,  0.3965,  ...,  0.3027, -0.3413,  0.3754],\n",
            "        [ 0.3043, -0.2834,  0.2754,  ...,  0.2757, -0.2578,  0.2729]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 7600/10000] train_loss: -60.23517, val_loss: -51.47667, val_recall@20: 0.15406, val_precision@20: 0.04665, val_ndcg@20: 0.1092\n",
            "items_emb_final tensor([[-1.0003,  1.0165, -0.9391,  ..., -1.0258,  1.0108, -1.0456],\n",
            "        [-0.6938,  0.7410, -0.7263,  ..., -0.7249,  0.7297, -0.7115],\n",
            "        [-0.4026,  0.4076, -0.4020,  ..., -0.4233,  0.3989, -0.4275],\n",
            "        ...,\n",
            "        [ 0.3490, -0.3063,  0.3376,  ...,  0.3421, -0.2862,  0.3365],\n",
            "        [ 0.2700, -0.3744,  0.3977,  ...,  0.3038, -0.3424,  0.3765],\n",
            "        [ 0.3060, -0.2851,  0.2771,  ...,  0.2773, -0.2595,  0.2745]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 7800/10000] train_loss: -61.01019, val_loss: -51.72546, val_recall@20: 0.15403, val_precision@20: 0.04656, val_ndcg@20: 0.10908\n",
            "items_emb_final tensor([[-1.0066,  1.0228, -0.9454,  ..., -1.0321,  1.0171, -1.0519],\n",
            "        [-0.6982,  0.7454, -0.7307,  ..., -0.7293,  0.7341, -0.7160],\n",
            "        [-0.4054,  0.4105, -0.4048,  ..., -0.4261,  0.4017, -0.4303],\n",
            "        ...,\n",
            "        [ 0.3509, -0.3082,  0.3395,  ...,  0.3440, -0.2881,  0.3384],\n",
            "        [ 0.2726, -0.3770,  0.4003,  ...,  0.3064, -0.3450,  0.3791],\n",
            "        [ 0.3078, -0.2869,  0.2789,  ...,  0.2792, -0.2613,  0.2764]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 8000/10000] train_loss: -62.87851, val_loss: -52.64095, val_recall@20: 0.15411, val_precision@20: 0.04665, val_ndcg@20: 0.10915\n",
            "items_emb_final tensor([[-1.0126,  1.0287, -0.9513,  ..., -1.0381,  1.0230, -1.0578],\n",
            "        [-0.7020,  0.7492, -0.7345,  ..., -0.7331,  0.7379, -0.7197],\n",
            "        [-0.4085,  0.4135, -0.4078,  ..., -0.4292,  0.4047, -0.4334],\n",
            "        ...,\n",
            "        [ 0.3530, -0.3103,  0.3417,  ...,  0.3461, -0.2902,  0.3405],\n",
            "        [ 0.2745, -0.3788,  0.4021,  ...,  0.3083, -0.3469,  0.3810],\n",
            "        [ 0.3085, -0.2876,  0.2796,  ...,  0.2798, -0.2620,  0.2771]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 8200/10000] train_loss: -66.01949, val_loss: -52.82378, val_recall@20: 0.15403, val_precision@20: 0.04656, val_ndcg@20: 0.10909\n",
            "items_emb_final tensor([[-1.0179,  1.0340, -0.9566,  ..., -1.0434,  1.0283, -1.0631],\n",
            "        [-0.7055,  0.7528, -0.7381,  ..., -0.7367,  0.7414, -0.7233],\n",
            "        [-0.4107,  0.4157, -0.4101,  ..., -0.4314,  0.4070, -0.4356],\n",
            "        ...,\n",
            "        [ 0.3546, -0.3118,  0.3432,  ...,  0.3476, -0.2917,  0.3421],\n",
            "        [ 0.2767, -0.3810,  0.4043,  ...,  0.3105, -0.3491,  0.3832],\n",
            "        [ 0.3100, -0.2891,  0.2811,  ...,  0.2814, -0.2635,  0.2786]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 8400/10000] train_loss: -65.69131, val_loss: -53.30801, val_recall@20: 0.15403, val_precision@20: 0.04656, val_ndcg@20: 0.10909\n",
            "items_emb_final tensor([[-1.0234,  1.0395, -0.9621,  ..., -1.0489,  1.0338, -1.0686],\n",
            "        [-0.7094,  0.7566, -0.7419,  ..., -0.7405,  0.7453, -0.7272],\n",
            "        [-0.4133,  0.4183, -0.4127,  ..., -0.4340,  0.4096, -0.4382],\n",
            "        ...,\n",
            "        [ 0.3559, -0.3132,  0.3445,  ...,  0.3490, -0.2931,  0.3434],\n",
            "        [ 0.2784, -0.3828,  0.4060,  ...,  0.3122, -0.3508,  0.3850],\n",
            "        [ 0.3112, -0.2903,  0.2824,  ...,  0.2826, -0.2648,  0.2799]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 8600/10000] train_loss: -66.9156, val_loss: -54.75177, val_recall@20: 0.15403, val_precision@20: 0.04656, val_ndcg@20: 0.10909\n",
            "items_emb_final tensor([[-1.0281,  1.0442, -0.9668,  ..., -1.0536,  1.0385, -1.0733],\n",
            "        [-0.7132,  0.7605, -0.7457,  ..., -0.7444,  0.7491, -0.7310],\n",
            "        [-0.4153,  0.4203, -0.4147,  ..., -0.4360,  0.4116, -0.4402],\n",
            "        ...,\n",
            "        [ 0.3584, -0.3157,  0.3470,  ...,  0.3515, -0.2956,  0.3459],\n",
            "        [ 0.2801, -0.3845,  0.4078,  ...,  0.3140, -0.3526,  0.3867],\n",
            "        [ 0.3131, -0.2922,  0.2842,  ...,  0.2845, -0.2666,  0.2818]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 8800/10000] train_loss: -67.65616, val_loss: -55.10249, val_recall@20: 0.15403, val_precision@20: 0.04656, val_ndcg@20: 0.10909\n",
            "items_emb_final tensor([[-1.0324,  1.0485, -0.9711,  ..., -1.0578,  1.0428, -1.0776],\n",
            "        [-0.7164,  0.7637, -0.7490,  ..., -0.7476,  0.7523, -0.7342],\n",
            "        [-0.4177,  0.4227, -0.4171,  ..., -0.4384,  0.4140, -0.4426],\n",
            "        ...,\n",
            "        [ 0.3599, -0.3172,  0.3485,  ...,  0.3530, -0.2971,  0.3474],\n",
            "        [ 0.2817, -0.3861,  0.4094,  ...,  0.3156, -0.3542,  0.3883],\n",
            "        [ 0.3146, -0.2937,  0.2858,  ...,  0.2860, -0.2682,  0.2833]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 9000/10000] train_loss: -69.02504, val_loss: -56.52158, val_recall@20: 0.15411, val_precision@20: 0.04656, val_ndcg@20: 0.10912\n",
            "items_emb_final tensor([[-1.0369,  1.0530, -0.9756,  ..., -1.0624,  1.0473, -1.0821],\n",
            "        [-0.7194,  0.7667, -0.7520,  ..., -0.7506,  0.7554, -0.7372],\n",
            "        [-0.4194,  0.4245, -0.4188,  ..., -0.4401,  0.4157, -0.4443],\n",
            "        ...,\n",
            "        [ 0.3615, -0.3188,  0.3501,  ...,  0.3546, -0.2987,  0.3490],\n",
            "        [ 0.2829, -0.3873,  0.4105,  ...,  0.3167, -0.3553,  0.3894],\n",
            "        [ 0.3158, -0.2949,  0.2869,  ...,  0.2872, -0.2693,  0.2844]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 9200/10000] train_loss: -65.69173, val_loss: -55.57207, val_recall@20: 0.15411, val_precision@20: 0.04656, val_ndcg@20: 0.10912\n",
            "items_emb_final tensor([[-1.0411,  1.0572, -0.9798,  ..., -1.0666,  1.0515, -1.0863],\n",
            "        [-0.7233,  0.7706, -0.7559,  ..., -0.7545,  0.7592, -0.7411],\n",
            "        [-0.4213,  0.4263, -0.4207,  ..., -0.4420,  0.4176, -0.4462],\n",
            "        ...,\n",
            "        [ 0.3629, -0.3202,  0.3515,  ...,  0.3560, -0.3001,  0.3504],\n",
            "        [ 0.2844, -0.3888,  0.4121,  ...,  0.3183, -0.3569,  0.3910],\n",
            "        [ 0.3170, -0.2962,  0.2882,  ...,  0.2884, -0.2706,  0.2857]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 9400/10000] train_loss: -72.12803, val_loss: -56.74294, val_recall@20: 0.15411, val_precision@20: 0.04656, val_ndcg@20: 0.10913\n",
            "items_emb_final tensor([[-1.0448,  1.0609, -0.9835,  ..., -1.0703,  1.0552, -1.0900],\n",
            "        [-0.7263,  0.7736, -0.7588,  ..., -0.7575,  0.7622, -0.7441],\n",
            "        [-0.4231,  0.4281, -0.4225,  ..., -0.4438,  0.4194, -0.4480],\n",
            "        ...,\n",
            "        [ 0.3640, -0.3213,  0.3526,  ...,  0.3571, -0.3012,  0.3515],\n",
            "        [ 0.2855, -0.3899,  0.4132,  ...,  0.3194, -0.3580,  0.3921],\n",
            "        [ 0.3185, -0.2976,  0.2897,  ...,  0.2899, -0.2720,  0.2872]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 9600/10000] train_loss: -69.94511, val_loss: -56.44764, val_recall@20: 0.15411, val_precision@20: 0.04656, val_ndcg@20: 0.10912\n",
            "items_emb_final tensor([[-1.0485,  1.0647, -0.9873,  ..., -1.0740,  1.0590, -1.0937],\n",
            "        [-0.7291,  0.7763, -0.7616,  ..., -0.7602,  0.7650, -0.7469],\n",
            "        [-0.4247,  0.4297, -0.4241,  ..., -0.4454,  0.4210, -0.4496],\n",
            "        ...,\n",
            "        [ 0.3653, -0.3226,  0.3540,  ...,  0.3584, -0.3025,  0.3528],\n",
            "        [ 0.2867, -0.3911,  0.4143,  ...,  0.3205, -0.3592,  0.3933],\n",
            "        [ 0.3199, -0.2991,  0.2911,  ...,  0.2913, -0.2735,  0.2886]],\n",
            "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)\n",
            "[Iteration 9800/10000] train_loss: -71.24261, val_loss: -57.18551, val_recall@20: 0.15414, val_precision@20: 0.04665, val_ndcg@20: 0.10919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neg_items_emb_final2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUzRRR3BF_4I",
        "outputId": "a25c7bff-edaa-4b27-fcda-d37097eb9258"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3683, -0.3108,  0.3540,  ...,  0.3342, -0.3758,  0.3297],\n",
              "        [ 0.0682, -0.0765,  0.0882,  ...,  0.1013, -0.1202,  0.1109],\n",
              "        [ 0.3298, -0.3559,  0.3319,  ...,  0.3704, -0.3239,  0.3393],\n",
              "        ...,\n",
              "        [-0.3662,  0.4021, -0.3583,  ..., -0.4148,  0.4180, -0.3916],\n",
              "        [ 0.3221, -0.3285,  0.3645,  ...,  0.3541, -0.3404,  0.3344],\n",
              "        [ 0.2971, -0.3408,  0.3188,  ...,  0.3401, -0.3423,  0.3538]],\n",
              "       device='cuda:0', grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CUDA_LAUNCH_BLOCKING=1"
      ],
      "metadata": {
        "id": "Q9RSD1TXHCI_"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neg_items_emb_final2 #= neg_items_emb_02 = items_emb_final2 = items_emb_02= neg_item_indices2 "
      ],
      "metadata": {
        "id": "w-5pBJEq0g0H",
        "outputId": "4754b91f-a6c1-4cbd-eec2-5d6b10e871da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3683, -0.3108,  0.3540,  ...,  0.3342, -0.3758,  0.3297],\n",
              "        [ 0.0682, -0.0765,  0.0882,  ...,  0.1013, -0.1202,  0.1109],\n",
              "        [ 0.3298, -0.3559,  0.3319,  ...,  0.3704, -0.3239,  0.3393],\n",
              "        ...,\n",
              "        [-0.3662,  0.4021, -0.3583,  ..., -0.4148,  0.4180, -0.3916],\n",
              "        [ 0.3221, -0.3285,  0.3645,  ...,  0.3541, -0.3404,  0.3344],\n",
              "        [ 0.2971, -0.3408,  0.3188,  ...,  0.3401, -0.3423,  0.3538]],\n",
              "       device='cuda:0', grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "items_emb_final2"
      ],
      "metadata": {
        "id": "lYBffBix3mRX",
        "outputId": "59e60ba7-fef7-4eb2-8d5e-c200dedb1d18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.0282, -1.0481,  1.0157,  ..., -1.0355,  1.0884, -1.0639],\n",
              "        [-0.7572, -0.7609,  0.7687,  ..., -0.8248,  0.7711, -0.7784],\n",
              "        [-0.4236, -0.4398,  0.4595,  ..., -0.4678,  0.4368, -0.4822],\n",
              "        ...,\n",
              "        [ 0.3525,  0.3575, -0.3669,  ...,  0.3379, -0.3289,  0.3242],\n",
              "        [ 0.3598,  0.3243, -0.3419,  ...,  0.2763, -0.2763,  0.3306],\n",
              "        [ 0.2264,  0.2349, -0.3058,  ...,  0.2632, -0.2883,  0.2931]],\n",
              "       grad_fn=<SplitWithSizesBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "items_emb_02"
      ],
      "metadata": {
        "id": "6jTGTWJX3xsz",
        "outputId": "80145e2f-e56d-497e-c746-40cfa0159ec3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-4.1128, -4.1926,  4.0630,  ..., -4.1419,  4.3537, -4.2557],\n",
              "        [-3.0289, -3.0437,  3.0750,  ..., -3.2992,  3.0845, -3.1135],\n",
              "        [-1.6943, -1.7591,  1.8378,  ..., -1.8714,  1.7473, -1.9287],\n",
              "        ...,\n",
              "        [ 1.4102,  1.4301, -1.4675,  ...,  1.3516, -1.3156,  1.2969],\n",
              "        [ 1.4391,  1.2973, -1.3676,  ...,  1.1051, -1.1052,  1.3224],\n",
              "        [ 0.9054,  0.9398, -1.2234,  ...,  1.0529, -1.1533,  1.1724]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "items_emb_02[neg_item_indices2]"
      ],
      "metadata": {
        "id": "TkkJ9Z6n4CUh",
        "outputId": "471cf595-c5f9-440e-a04b-f0cb149ab83f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.4593,  1.4769, -1.3761,  ...,  1.3603, -1.1518,  1.3259],\n",
              "        [-0.8510, -0.9326,  0.7929,  ..., -0.8131,  0.7023, -1.0383],\n",
              "        [ 1.0182,  1.1052, -0.8752,  ...,  0.8988, -1.0389,  0.8718],\n",
              "        ...,\n",
              "        [ 1.3499,  1.4397, -1.3728,  ...,  1.5476, -1.3881,  1.4515],\n",
              "        [-0.6660, -0.6483,  0.7554,  ..., -0.6244,  0.6193, -0.6034],\n",
              "        [-3.4670, -3.4076,  3.3600,  ..., -3.4073,  3.2948, -3.4103]],\n",
              "       grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iters = [iter * ITERS_PER_EVAL for iter in range(len(train_losses))]\n",
        "plt.plot(iters, train_losses, label='train')\n",
        "plt.plot(iters, val_losses, label='validation')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('loss')\n",
        "plt.title('training and validation loss curves')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v4wiSzh_pAcy",
        "outputId": "ea3fcf07-90a2-4547-b83a-c4795872afaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hU1dbA4d9KIwmEECCUUEMPhB6KNEFREakKgohSRbF7FT/bVa+9XXtBQEAQREQBpQjqpffQQwcpCRA6gZAQUvb3xzlgwAQmZCYzSdb7PPNw5pQ968yEWXP23mdvMcaglFJKOcLL3QEopZTKPzRpKKWUcpgmDaWUUg7TpKGUUsphmjSUUko5TJOGUkoph2nSUJeIyEgR+bez93UnEVkoIkNdUO4+EeloL78gImMc2fc6XqetiOy43jivUm5VETEi4uPsslXBpn8wBYSI7AOGGmP+uN4yjDEPuWLfgs4Y85azyhIRA9Q0xuy2y14C1HZW+Urlll5pFBL6i1Lld2LR7yw30w+gABCRiUBl4FcRSRSRZzNVPwwRkQPA/+x9fxSReBFJEJHFIlIvUznjReQNe7m9iMSJyNMiclREDovIoOvct5SI/CoiZ0RkjYi8ISJLr3I+14rxCxGZLSJnRWSViFTPtP0WEdluH/s5INm8RpiIJItIyUzrGovIcRHxFZHqIvI/ETlhr5skIiWyKetVEfku0/P7RGS/feyLV+zbXERWiMhp+336XET87G2L7d022p9jn4vvbabjI+wqt9MiskVEujn63lyN/X78IiInRWS3iDxwRczR9ud3REQ+tNf7i8h39nmetj/bstmUX0lEfhaRY/b+n2fz3l1WbWaf65sisgxIAkaISPQVZT8lIr/Yy0VE5AMROWDHOlJEAuxtpUVklh3rSRFZIpqEckzfsALAGHMfcADoaowpZox5L9PmG4EI4Db7+VygJlAGWAdMukrR5YBgoAIwBPhCREKuY98vgHP2PgPsx9VcK8a+wH+AEGA38CZYXwrAz8BLQGlgD9A6qxcwxhwCVgB3ZVrdD5hmjEnFSjZvA2FY718l4NVrxI2I1AW+Au6zjy0FVMy0SzrwlB3fDcDNwMN2TO3sfRran+MPV5TtC/wKzMd6bx4DJolI5uqrLN8bB0wB4uyYewFvichN9rZPgE+MMcWB6sBUe/0ArM+8kn2eDwHJWbwn3sAsYD9QFetvZIqDcYH1Xg4DgoCRQG0RqZlpez9gsr38DlALaATUsF/rZXvb0/Y5hgJlgRcAHUcpp4wx+igAD2Af0DHT86pY/yGqXeWYEvY+wfbz8cAb9nJ7rC8An0z7HwVa5mRfwBtIBWpn2vYGsNTB88oqxjGZtncGttvL9wMrM20TrC+JodmUPRT4X6Z9Y4F22ezbA1if1fuNlUy+s5dfBqZk2q8ocCHzZ3NFuU8C0zM9N0CNTM/bA3H2clsgHvDKtP174NVrvTdZvO7Fvw8frC/9dCAo0/a3gfH28mKsRFT6ijIGA8uBBtf4DG8AjmX++8i07dJ7d2Vc9vOFwGtXHPMd8LK9XBM4CwTan+E5oPoVr73XXn4NmJn5/dVHzh96pVHwxV5cEBFvEXlHRPaIyBmsLz6wfvVm5YQxJi3T8ySgWA73DcX6YorNtC3z8mUcjDE+m5jCMpdtrG+KbF8L+Am4QUTKA+2ADGCJHUdZEZkiIgftOL4j+/cpsytjOAecyHR+tewqkni73LccLPdS2caYjEzr9mP9mr4ou/fmWuWeNMaczabcIVi/3rfbVVBd7PUTgXnAFBE5JCLv2VdDV6oE7L/i7yMnrvwMJwP32Mv9gBnGmCSsv7VAYK1dBXUa+M1eD/A+1tXXfBH5S0Seu854CjVNGgVHdpfZmdf3A7oDHbGqFara67Os93eSY0Aal1fRVLrK/rmJ8XDmskVErvZaxphTWFU9fezXnWInGrC+zA1Q31jVMv2vM4ZArKqbi74CtmP1kCqOVUXi6Pt/CKh0RT18ZeCgg8dfrdySIhKUVbnGmF3GmHuwqsTeBaaJSFFjTKox5j/GmLpAK6AL1tXelWKBypJ1Z4xzWF/0F5XLYp8r/7Z/B0JFpBFW8rhYNXUc64q3njGmhP0INsYUs8/jrDHmaWNMNaAb8C8RuTnrt0RlR5NGwXEEqHaNfYKAFKxfvoFYX4wuZYxJx2pneFVEAkWkDll/sTgjxtlAPRG50/6Cepysv4Qym2zH04u/v3wuxpEIJIhIBWCEgzFMA7qISBu7gfs1Lv9/FgScARLt92L4Fcdf7XNchXX18KxYjfXtga7krH3gH4wxsVjVTG/bjdsNsK4uvgMQkf4iEmpf4Zy2D8sQkQ4iUt9usziDVQ2ZkcVLrMZKpu+ISFH7NS62NW0A2olIZREJBp53IN5U4EesK4eSWEkEO77RwEciUsaOvYKI3GYvdxGRGvaPiQSsKrms4lVXoUmj4HgbeMm+LH8mm30mYFU7HAS2AivzKLZHsa4a4rGqNL7HSgxZue4YjTHHgd5YjaEnsOq7l13jsF/s/eKNMRszrf8P0ATry2U2VuJzJIYtwCNYCegwcAqrXeWiZ7Cuas5ifcH9cEURrwLf2p/j3VeUfQErSdyO9av6S+B+Y8x2R2K7hnuwruoOAdOBV8zf9/x0AraISCJWo3hfY0wyVkKehpUwtgGLsD7fy9g/HLpiNUwfwHo/+tjbfsd6DzYBa7EazB0xGetq9Mcrqr3+D6sKaqVd/fcHf9/nUtN+nojVCeJLY8wCB19P2eTvq3Gl8oaIvAuUM8ZcqxeVUsrD6JWGcjkRqSMiDcTSHKvqY7q741JK5ZzeJazyQhBWlVQYVp39f7G6Piql8hmtnlJKKeUwrZ5SSinlsAJRPVW6dGlTtWpVd4ehlFL5ytq1a48bY0KvveffCkTSqFq1KtHR0dfeUSml1CUisj+nx2j1lFJKKYdp0lBKKeUwTRpKKaUc5rFtGiLSCWvIAm+s4Z7fcXNISqk8kpqaSlxcHOfPn3d3KAWCv78/FStWxNc3q0GIc8Yjk4Y9ANoXwC1Y49SsEZFfjDFb3RuZUiovxMXFERQURNWqVbHGF1TXyxjDiRMniIuLIzw8PNfleWr1VHNgtzHmL3uQtilYw2UrpQqB8+fPU6pUKU0YTiAilCpVymlXbZ6aNCpw+cQrcVw+0QwiMkyseYujjx07lqfBKaVcTxOG8zjzvfTI6ilHGGNGAaMAoqKirmsslP3boolf/j3i5Q1eXohYD7y8EW9vAkqUJ7hcFULDquMXUgF8/Z16Dkopld94atI4yOUzrlUk97OT/cPxvZtoETvG4f0TvIJJLFKW9EqtqNTxIaRMhLNDUkp5gNOnTzN58mQefvjhHB3XuXNnJk+eTIkSJVwUmft55ICF9qxrO4GbsZLFGqCfPcHNP0RFRZnruSPcGEN6hiE9I4P09HTS09Psf9NJTb3A8fgDnDq8n3PH9pN+Og6fxMMEnT9IlNmCn6RzunQTgts8gNTtAX6B135BpZRDtm3bRkSE+36U7du3jy5duhATE3PZ+rS0NHx8PPW39tVl9Z6KyFpjTFROyvHIszfGpInIo1iT1nsDY7NLGLkhIvh4Cz7eXuDrAxS5bHu5MmWhQbPL1qWmZzBnxSYOLvqGTkfnU2LGcFJnP4tPo75I82EQWsvZYSql8thzzz3Hnj17aNSoEb6+vvj7+xMSEsL27dvZuXMnPXr0IDY2lvPnz/PEE08wbNgw4O8hjRITE7n99ttp06YNy5cvp0KFCsycOZOAgAA3n1nueeSVRk5d75VGbqSmZ/Dz2liW/DGTjslz6ey9Bh8xeLV9CtqNAJ8i1y5EKZWlzL+K//PrFrYeOuPU8uuGFeeVrvWy3Z75SmPhwoXccccdxMTEXOqyevLkSUqWLElycjLNmjVj0aJFlCpV6rKkUaNGDaKjo2nUqBF333033bp1o3///k49j5xw1pWGp/ae8ni+3l70aV6FD599lOSuX9OzyGhmpLWExe9jRraBA3k1/bZSytWaN29+2T0On376KQ0bNqRly5bExsaya9eufxwTHh5Oo0aNAGjatCn79u3Lq3BdyiOrp/ITPx8v7mleme6Nwnjup6rM3DyXD0+Po+TYTkizodDxFSgS5O4wlcq3rnZFkFeKFi16aXnhwoX88ccfrFixgsDAQNq3b5/lPRBFivxd2+Dt7U1ycnKexOpqeqXhJIF+PnzStxFtb+/LjefeYYZfF8yaMfBFC9g5393hKaVyICgoiLNnz2a5LSEhgZCQEAIDA9m+fTsrVxauWgW90nAiEWFo22pElC/Oo5OD+IkWjGQ8xSb3hpaPQMdXwcfP3WEqpa6hVKlStG7dmsjISAICAihbtuylbZ06dWLkyJFERERQu3ZtWrZs6cZI8542hLtI7MkkHpy4lj3xJ5hadTYND0+Fis2h9zgIruju8JTyaO7uclsQaUO4h6tUMpCfhrfi9oZV6L63B9PCX8cc3QYj28Ku390dnlJKXRdNGi4U4OfNR30aMbBVVZ7ZVp1Pqo3CFC8Pk3rBn69Depq7Q1RKqRzRNg0XExFe6VoXPx8vPl78FyeiPuG1sG+RJR9A7CroNQ6K5Whed6WUchu90sgDIsLzt9fhkQ7VmRh9lBEXHiCj+5cQtwZGd4DDm9wdolJKOUSTRh4REZ65tTZPdazFtLVxPLWjLmkD50JGOoy9DbbMcHeISil1TZo08pCI8ETHmoy4rTYzNxziiUWQOvR/ULYe/DgAFrwFGRnuDlMppbKlScMNHulQgxc7RzB782EemXmQC/1/hUb3wqJ34cf7ISXR3SEqpXKgWLFiABw6dIhevXpluU/79u251q0BH3/8MUlJSZeed+7cmdOnTzsvUCfQpOEmD7Srxqtd6zJ/6xGGT4kh5Y5P4ba3YPtsq7rq9AF3h6iUyqGwsDCmTZt23cdfmTTmzJnjcXNzaNJwo4Gtw3mjRyR/bj/KsInrOB/1ENw7DU7HwpiOcGi9u0NUqlB67rnn+OKLLy49f/XVV3njjTe4+eabadKkCfXr12fmzJn/OG7fvn1ERkYCkJycTN++fYmIiKBnz56XjT01fPhwoqKiqFevHq+88gpgDYJ46NAhOnToQIcOHQBrqPXjx48D8OGHHxIZGUlkZCQff/zxpdeLiIjggQceoF69etx6660uH+NKu9y6Wf+WVfDz9uL/ft7EkG/XMOb+9gQMmQ+TesO4O6D3eKh1q7vDVMp95j4H8ZudW2a5+nD7O9lu7tOnD08++SSPPPIIAFOnTmXevHk8/vjjFC9enOPHj9OyZUu6deuW7fzbX331FYGBgWzbto1NmzbRpEmTS9vefPNNSpYsSXp6OjfffDObNm3i8ccf58MPP2TBggWULl36srLWrl3LuHHjWLVqFcYYWrRowY033khISAi7du3i+++/Z/To0dx999389NNPLh2CXa80PMDdzSrx394NWbHnBAPHreZccA0Y+geUrgHf94E137g7RKUKlcaNG3P06FEOHTrExo0bCQkJoVy5crzwwgs0aNCAjh07cvDgQY4cOZJtGYsXL7705d2gQQMaNGhwadvUqVNp0qQJjRs3ZsuWLWzduvWq8SxdupSePXtStGhRihUrxp133smSJUuAvB+CXa80PMSdTSri7SX8a+pGBoxdzbhBzQgaOAemDYbZ/7LaOG5+Bbw0z6tC5ipXBK7Uu3dvpk2bRnx8PH369GHSpEkcO3aMtWvX4uvrS9WqVbMcEv1a9u7dywcffMCaNWsICQlh4MCB11XORXk9BLt+A3mQ7o0q8Pk9jdkQe5pHJ68n3bco9J0MUUNg2cfw81BIS3F3mEoVCn369GHKlClMmzaN3r17k5CQQJkyZfD19WXBggXs37//qse3a9eOyZMnAxATE8OmTdZNvGfOnKFo0aIEBwdz5MgR5s6de+mY7IZkb9u2LTNmzCApKYlz584xffp02rZt68SzdZxeaXiY2+uX57WkVF6Yvpm352zjpS514Y7/QonK8McrcOYw9J0EgSXdHapSBVq9evU4e/YsFSpUoHz58tx777107dqV+vXrExUVRZ06da56/PDhwxk0aBARERFERETQtGlTABo2bEjjxo2pU6cOlSpVonXr1peOGTZsGJ06dSIsLIwFCxZcWt+kSRMGDhxI8+bNARg6dCiNGzd2y2yAbhkaXUR6A68CEUBzY0x0pm3PA0OAdOBxY8y8a5XniUOj59arv2xh/PJ9vN+rAb2jKlkrY36C6Q9BSDj0n2YlEqUKIB0a3fny+9DoMcCdwOLMK0WkLtAXqAd0Ar4UEe+8D8/9XrojgjY1SvPi9BjW7j9prYy8C+6bAYnxdpfcDe4NUilV6LglaRhjthljdmSxqTswxRiTYozZC+wGmudtdJ7Bx9uLz/s1JqyEPw9OXMvB03bjVtXWMHg+ePvBuM46N4dSKk95WkN4BSA20/M4e12hVCLQjzEDmpGSmsHQb6NJumDPv1GmDgz5HUpVg8l9YO237g1UKRcoCLOKegpnvpcuSxoi8oeIxGTx6O6k8oeJSLSIRB87dswZRXqkGmWK8Wm/xuyIP8PTUzeSkWF/+MXLw6C5UK09/Pq4Ndih/idTBYS/vz8nTpzQxOEExhhOnDiBv7+/U8pzWe8pY0zH6zjsIFAp0/OK9rqsyh8FjAKrIfw6Xivf6FC7DC90juCN2dt4bdZWXrojAh9vLygSBP1+gF+ftAY7TDoBt7+v93KofK9ixYrExcVRkH8Q5iV/f38qVqzolLI8rcvtL8BkEfkQCANqAqvdG5JnGNImnIOnkxm3bB+7jyby6T2NKVnUD7x9ofvnVhfc5Z9C8mnoOdJar1Q+5evrS3h4uLvDUFlwy09SEekpInHADcBsEZkHYIzZAkwFtgK/AY8YY9LdEaOnsaaNrcd7dzVg9b6TdP1sKTEHEy5uhFtfh46vQsw0mNIPLiRdrTillLoubrlPw9kK4n0aV7Mx9jTDv1vLiXMXeLNnfXo1zXTZGT0OZj0FlVvCPVMgwLOGVVZKeY78dJ+GyoWGlUrw62NtaFolhGd+3MjLM2O4kGbP+Bc1CHqNhbho+LYLJB51b7BKqQJFk0Y+VapYESYMbs6wdtWYsGI/g8evIf1iz6rIO6HfFDixB8Z2sv5VSikn0KSRj/l4e/FC5wje7BnJ0t3H+XpxpuRQoyPcPxOST8E3t8CBVe4LVClVYGjSKAD6Na/MHfXL89HvO/9uHAeo1Nyal8O/BHzb1Rq7SimlckGTRgEgIrzZM5KQQD+e+mED51MzdTgrVd1KHBWaWHNzLPmv3gSolLpumjQKiBKBfrzfuyG7jiby3m9XDOsVWNIa6DCyF/z5GvzyGKSnuidQpVS+pkmjALmxVigDbqjC2GV7Wbb7+OUbff3hrjHQbgSsnwjf3QXnz7gnUKVUvqVJo4B57vYIqocW5ZkfN5KQdMXVhAjc9BJ0/xL2L4OJPeF8QtYFKaVUFjRpFDABft581KcRx86m8PIvMVnv1Phe6D0eDm+ECT2sHlZKKeUATRoFUIOKJXji5prM3HCIXzYeynqniK7QZyIciYEJ3SHpZN4GqZTKlzRpFFDD21enceUSvDh9Myv2nMh6p9q3Q59JcHQ7fNsNzmWzn1JK2TRpFFA+3l58dk9jyhb3p/83q/h2+b6s5yaodSvcMxlO7LLu5UjUoaiVUtnTpFGAVQwJZPrDrehQO5RXftnC//20iZS0LAYNrtHRGtzw5F/WeFVnj+R9sEqpfEGTRgEX5O/LqPuiePymGkyNjqPvqJUcOXP+nztW7wD3/ginD8DomyB+c94Hq5TyeJo0CgEvL+Fft9ZmZP8m7Ig/S9fPlrL+QBY9psLbWlPImgz45jbYNivvg1VKeTRNGoVIp8jy/PxwK/x9venz9UoW7cyi/SKsEQxbAKG14Yd7ddgRpdRlNGkUMnXKFeeXR1tTvUwxHpm0jm2Hs7grPKgcDJrz97AjPw+D1CyqtJRShY4mjUKoRKAfYwdGUbSIN4PHr8m6jcM3wBp25KaXYPNUbSBXSgGaNAqt8sEBjB3YjITkVIZ8u4ZzKWn/3EnEGqvq7glwZIvVQH54U94Hq5TyGJo0CrF6YcF80a8JWw+d4Ykp6/+e+e9KdbvD4N8AA2O1gVypwswtSUNE3heR7SKySUSmi0iJTNueF5HdIrJDRG5zR3yFSYc6ZfhPt3r8se0or8/amv2O5RvCA/+DMhF2A/mH2kCuVCHkriuN34FIY0wDYCfwPICI1AX6AvWATsCXIuLtphgLjftuqMqQNuGMX76Pccv2Zr9jUDkYOBsi74I//wPTH4K0lLwLVCnldm5JGsaY+caYi5XoK4GK9nJ3YIoxJsUYsxfYDTR3R4yFzQudI7i1bllen7WVBTuOZr+jbwDc9Q10eAk2TdGhR5QqZDyhTWMwMNdergDEZtoWZ6/7BxEZJiLRIhJ97Jh+aeWWt5fwcd9G1CobxIgfN3Ii8SpXECJw4wjo/a3VMD76Jji+O++CVUq5jcuShoj8ISIxWTy6Z9rnRSANmJTT8o0xo4wxUcaYqNDQUGeGXmgF+vnwUZ9GJCSn8tKMmKwHOMysXg/rfo7UJKuB/ND6vAlUKeU2LksaxpiOxpjILB4zAURkINAFuNf8/e10EKiUqZiK9jqVRyLKF+dft9Rmbkw8MzdkMxdHZhWawJD54BcI47vAX4tcH6RSym3c1XuqE/As0M0Yk5Rp0y9AXxEpIiLhQE1gtTtiLMyGtatG0yoh/HtmDIcTkq99QKnqMHg+lKgMk3rBlhmuD1Ip5RbuatP4HAgCfheRDSIyEsAYswWYCmwFfgMeMcZkMZa3ciVvL+G/vRuSlm54dtqma1dTARQvb1VVhTWBHwdC9FiXx6mUynvu6j1VwxhTyRjTyH48lGnbm8aY6saY2saYuVcrR7lO1dJFeeGOCJbsOs53K/c7dlBACNw3HWreCrOegkXv6b0cShUwntB7Snmo/i0q065WKG/N2c7e4+ccO8gvEPpOgob3wII3Yep9kHzatYEqpfKMJg2VLRHhvbsa4OstPD11Q/bDjFzJ2xd6fAW3vgE75sLX7eDgOtcGq5TKE5o01FWVC/bn9R6RrDtwmg/m73CsfQOsezlaPWZN6pSRbnXJXTVKq6uUyuc0aahr6tYwjLujKvLVwj08PGkdZ8+nOn5wpebw0BKo1gHmjoCp98P5BNcFq5RyKU0a6ppEhHfvasCLnSOYv/UI3T9fxs4jZx0vILAk3DMFbnkNts+2qqviY1wXsFLKZTRpKIeICA+0q8bkoS04m5JG98+XMXNDDu679PKC1k9Y1VVpKfDNrVZ7h1IqX9GkoXKkRbVSzH6sDZEVivPElA28MjOGC2kZjhdQuQU8sABK14Tv74Hln2k7h1L5iCYNlWNlivsz+YGWDGkTzrcr9tN/zCqSLmQx8192ipe3rjjqdoP5L8Evj0HaBdcFrJRyGk0a6rr4envx7y51+aRvI6L3n+SRSetITc/BFYdfIPQaD22fgfUT4bs7Iemky+JVSjmHJg2VK90bVeCNHvVZsOMYz/202fEuuWC1c9z8b+g5CmJXwZib4dhO1wWrlMo1TRoq1/q1qMxTHWvx07o43pu3I+cFNOwDA2bB+TMwugPE/Oz8IJVSTqFJQznF4zfX4N4Wlflq4R7GLr3KlLHZqdwCHlwMZerCtEEw9/+0nUMpD6RJQzmFiPBa90g61SvHa7O28stGB+biuFJwBWsO8hbDYdVIGH8HJOh0Kkp5Ek0aymkuThnbPLwkT0/dwNJdx3NeiI8f3P4O9B4PR7fC121hz/+cHqtS6vpo0lBO5e/rzej7o6geWoxhE6Ov74oDoF5PGLYQipaBiXfCovchIwe9s5RSLqFJQzldcIAvEwY3p065IB7/fj0jftzIuZQc3MdxUema8MCfUL83LHgDfhwAKYnOD1gp5TBNGsolyhT3Z+qDN/DYTTWYti6Orp8tJebgdQxU6FcU7hxlDbO+fZY1Wu6pfU6PVynlGE0aymV8vL14+tbaTB7akqQL6fT8chljlvxFhqPzclx0cZj1e3+EhFgY1QH2LnZN0Eqpq9KkoVzuhuqlmPtEW9rXLsMbs7cxaPwaEpJyMLz6RTU6WuNWFQ2FCT1g9Wgdt0qpPOaWpCEir4vIJhHZICLzRSTMXi8i8qmI7La3N3FHfMr5Qor6Meq+przeI5IVe07wwMRoUtLSc15Qqeow9A+oeQvMecYatyo12fkBK6Wy5K4rjfeNMQ2MMY2AWcDL9vrbgZr2YxjwlZviUy4gItzXsgrv927A6r0neXbappxXVQH4F4e+k6Ht09a4VaPaw5EtTo9XKfVPbkkaxpgzmZ4WBS5+c3QHJhjLSqCEiJTP8wCVS3VvVIERt9Vm5oZDfPj7dY415eUNN78M/X+2Bjoc1UGnk1UqD7itTUNE3hSRWOBe/r7SqADEZtotzl6X1fHDRCRaRKKPHTvm2mCV0z3cvjp9m1Xi8wW7mbL6wPUXVONmGL4cqt1oTSf7fV84dx03FSqlHOKypCEif4hITBaP7gDGmBeNMZWAScCjOS3fGDPKGBNljIkKDQ11dvjKxUSE13tE0q5WKC/OiGHxzlwk/mKh0G8q3P4e7FkAX7W2/lVKOZ3LkoYxpqMxJjKLx8wrdp0E3GUvHwQqZdpW0V6nCiBfby++6NeYmmWK8fCkdWw7fObaB2VHBFo8CA/8D/yDYWIPa4InHfRQKadyV++pmpmedge228u/APfbvahaAgnGmMN5HqDKM0H+vowb1IyiRbwZNG4NhxNy2ROqXKQ1/EjUYGsqWZ2jQymnclebxjt2VdUm4FbgCXv9HOAvYDcwGnjYTfGpPFQ+OICxA5tx9nwqPb9YzsbY07kr0C8Qunxk9bBKiIOv20H0OG0kV8oJJEczrXmoqKgoEx0d7e4wVC5tOZTAsAlrOZaYwps9IukdVenaB13LmcMw4yH4ayHU6QLdPoPAkrkvV6kCQETWGmOicnKM3hGuPEa9sGB+fawNUVVCGDFtE6/+siVn845npXh56D/dGrtq5zz4qpU2kiuVC5o0lEcpWdSPCYObMyu+xRQAACAASURBVKRNOOOX76P/mFUcT0zJXaFeXtbYVQ/8CUWCrEbyOc/ChSTnBK1UIaJJQ3kcH28v/t2lLh/1aciG2NN0+2wpm+Jy2c4BUL6hNaVsi4dg9dcw6kY4uC735SpViGjSUB6rZ+OK/DS8lbX85XLe+20751OvY7yqzHwD4PZ34b4Z1twc39wCi96D9OuY70OpQsihpCEiT4hIcbsr7Dcisk5EbnV1cEpFVghmzhNtubNxBb5cuIfOnyxhzb6TuS+4egd4eLk1Q+CCN2HsrXB8V+7LVaqAc/RKY7A9XtStQAhwH/COy6JSKpMSgX6837shE4c050J6Br1HruDfM2I4e/46hlfPLCAE7hoDvcbCiT3WneRL/gvpuSxXqQLM0aQh9r+dgYnGmC2Z1imVJ9rWDGXek+0Y3Dqc71bt57aPFudu+JGLIu+CR1ZB7U7w52vWqLkH1+a+XKUKIEeTxloRmY+VNOaJSBCQy76QSuVc0SI+vNy1Lj8Nb0XRIj4M+XYNR86cz33BQeXg7gnQZxIknYAxHWHei3DhXO7LVqoAcTRpDAGeA5oZY5IAX2CQy6JS6hqaVA5hzIAo0jIM363c77yCI7pYVx1NBsCKz+HLlnpfh1KZOJo0bgB2GGNOi0h/4CUgwXVhKXVtVUoVpWNEWSatOpD7XlWZ+QdD149h4Bzw9rPu65j9jF51KIXjSeMrIElEGgJPA3uACS6LSikHDW4dzslzF5ix3gWDIVdtDQ8thZYPw5rRMLItxK5x/usolY84mjTSjDVIVXfgc2PMF0CQ68JSyjEtq5Ukonxxxi7bi0vGUfMNgE5vw4BfIf2C1TX3f2/okOuq0HI0aZwVkeexutrOFhEvrHYNpdxKRBjcuio7jySybPcJ171QeDsYvgwa3gOL37eGXD+6zXWvp5SHcjRp9AFSsO7XiMeaHOl9l0WlVA50axRG6WJ+fLP0L9e+kH8w9PjS6mF15pDVNXfjD659TaU8jENJw04Uk4BgEekCnDfGaJuG8ghFfLzp37IKC3YcY8+xRNe/YEQXeHgFVIiC6cOsrrk6DIkqJBwdRuRuYDXQG7gbWCUivVwZmFI5cW+LKvh5ezF+2b68ecFiZeD+GdD8Qatr7nd3QpIThjdRysM5Wj31ItY9GgOMMfcDzYF/uy4spXImNKgI3RqFMW1tHAlJWQ8DMn9LPK3e/pM5m500g7C3L3R+D7p/AQdWWKPmxsc4p2ylPJSjScPLGHM00/MTOThWqTwxuHU4yanpfL/mwGXr0zMM7/22nWET1xJ/5jyv/rKFcylOrE5q3B8GzbXGrPrmFoj52XllK+VhHP3i/01E5onIQBEZCMzGms9bKY9RN6w4N1QrxbfL912a8e9EYgoDxq7my4V7uKd5JSYNbcnRsyl8tXCPc1+8YhQMWwhlI2HaIBh9kzUv+fkzzn0dpdzM0YbwEcAooIH9GGWM+b/cvriIPC0iRkRK289FRD4Vkd0isklEmuT2NVThMrhNOIcTzjNvSzwbYk/T9bOlrN53kvd6NeDtOxtwQ/VS9GxcgVFL/iL2pJNn7gsqBwNnwW1vW7MCznoS/lsbZjwMB1aCK+4jUSqPiUtuiHLkhUUqAWOAOkBTY8xxEekMPIY1MGIL4BNjTItrlRUVFWWio6NdGq/KH9IzDDf9dyGpaRkcT7xAmeJFGNm/KZEVgi/tE59wng4fLKR97VC+6t/UNYEYY42Uu+5bq7rqQiKUrgWtHrfu9fD2cc3rKpUDIrLWGBOVk2OueqUhImdF5EwWj7Miktvr7o+AZ4HMWas7MMFYVgIlRKR8Ll9HFSLeXsLg1uEcSjhPqxqlmPVYm8sSBkC5YH8ebl+duTHxrNjjohsCRawqq26fwdM7oNvn4BsIvzwKX7WCbb/qlYfKl66aNIwxQcaY4lk8gowxxa/3RUWkO3DQGLPxik0VgNhMz+PsdVmVMUxEokUk+tgxJ8ypoAqM+1pWYeqDNzB2QDNKBPpluc8D7apRoUQAr83aSnqGi7+8ixSDJvdZbR53TwSTAT/0txrN9y117Wsr5WQu6wElIn+ISEwWj+7AC8DLuSnfGDPKGBNljIkKDQ11TtCqQPDyEpqHl8TLK/t5wvx9vXmhcwTbDp/hhzWx2e7nVCJQtxs8vNK6Akk4COPvgO/ugiNb8yYGpXLJZUnDGNPRGBN55QP4CwgHNorIPqwhSdaJSDngIFApUzEV7XVKOV3n+uVoHl6SD+bvICE5D6d49faBJvfD4+vgltchLhq+bgcL39WpZpXHy/N7LYwxm40xZYwxVY0xVbGqoJrYQ5X8Atxv96JqCSQYY5x0J5ZSlxMRXu5Sl1NJF/j0z115H4BvALR+HB5fD/V6wMK3YHQHOLwp72NRykGedoPeHKwrkd3AaOBh94ajCrrICsH0bVaJb5fvy5txq7ISWBLuGmMNhHj2iJU4Frytw68rj+T2pGFfcRy3l40x5hFjTHVjTH1jjPajVS739K21CfD15v3fdrg3kItTzUbeBYvesZLHwbXujUmpK7g9aSjlbqWLFWFg66r8tiWeXUfOujeYwJJw5yjo+z2cO2bdWT6+C2ybBRlOnNJWqeukSUMpYFDrcAJ8vflqkZOHF7ledTrDI6uh43/g5F744V74tDEs/xyST7s7OlWIadJQCihZ1I9+LSozc8Mh5w8vcr0CSkCbJ+GJjXD3BCheAea/CB/WhTkjIPHotctQysk0aShle6BtNbwEvl7sIVcbF3n7QN3uMHguPLjY6mkVPRY+bQLLPoG0FHdHqAoRTRpK2coF+9OraUWmRsdx9Mx5d4eTtfINrSlnH14FVVvD7y/DFy1g+2wdlkTlCU0aSmXyYLvqpKVn8M3Sve4O5epK14B+P0D/n8GnCEzpBxO6653lyuU0aSiVSdXSRenaMIzvVu7ndFI+uE+ixs3w0FK4/X04vBFGtoYfB8Gh9e6OTBVQmjSUusLw9tU5dyGd8cv3uTsUx3j7Qoth1p3lrR6D3X/AqPZWV91dv2u1lXIqTRpKXaFOueJ0jCjLuGX7SHTmtLCuFlgSbnkNnoqxxrQ6sQcm9bKGYt8wGVKT3R2hKgA0aSiVhUc6VCchOZXvVx249s6exj/YGtPqiY3QY6S1bsZweKcKfNsNlnwIB9fpzYLqurht5j5n0pn7lCvcO2Ylu44ksvjZDvj7egOQlp7BziOJbIg9zeGEZMoHB1CpZACVQgIJKxGAn48H/g4zBvYusqqq/loIR2Ks9QEhEN4Owm+Eqm2hdE1r+HZVaFzPzH0656RS2XikfQ36jVnF23O24e/rzfrY02yOSyA5Netf6CJQrrg/tcsF8e5dDShb3D+PI86GCFRrbz3AGhRx72Irgfy1ALbOtNYXKwtV21gJpGpbKFVdk4j6B73SUCobxhju/Go56w+cxs/bi4iw4jSuVIJG9qNiSABHzqYQezLJepxKJu5UErM3HebWeuX47J7G7j6FazMGTv4F+5ZYswjuXQKJ8da20DrW6Lvl6rs3RuUy13OloUlDqas4kZhC3Klk6pQPooiPt0PHfPj7Tj79cxc/DGtJi2qlXByhkxljNaDvXQSL34ekk3D7u9B0oF51FEDXkzQ8sAJWKc9RqlgRGlYq4XDCABh+Y3XCgv159dc8mH/c2USsGwebDYEHl1h3nc96En5+AFLcPAKw8giaNJRysgA/b164w5p/fMqaq/e+Op+azqOT1/GZO2YOvJZioXDvT3DTSxDzk3XvR3yMu6NSbqZJQykXuKN+eVqEl+SDeTtISMp63u/0DMMTU9Yza9NhPvxjJ2v3n8zjKB3g5QXtRsD9v1hXGmNuhjVjdHj2QkyThlIuICK80rUeCcmpfPTHzn9sN8bw0ozNzNtyhBG31SYsOID/+2kzKWkeeu9EeFtruJJKLWD20/BuVWugxJmPwroJcHQbZGS4O0qVB7TLrVIuUjesOP1aVGbiyv3c07wytcsFXdr2wfwdfL86lkc71OCRDjWoG1acQePW8OWCPTx1Sy03Rn0VxcrAfdOtnlaxayBuNWyfBesnWtuLBEOFxhDWBCo0tR7Fy7s3ZuV0buk9JSKvAg8Ax+xVLxhj5tjbngeGAOnA48aYedcqT3tPKU916twF2n+wkHphxZk0tAUiwjdL9/L6rK3c07wyb/WMROxeSU9OWc/szYeZ/XhbapUNukbJHuJib6u41RC7Gg6tgyNbIMMefiWovJU8mg2F6h3cG6v6h3zT5dZOGonGmA+uWF8X+B5oDoQBfwC1jDFXvWbXpKE82YQV+3h55hZG9m9Ccmo6T/2wkdsjy/F5vyZ4e/3djfVEYgodP1xElVJF+Wl4q8u25SupyRC/2Rqq5OBa2L8MzhyCDi9A22esdhLlEQpCl9vuwBRjTIoxZi+wGyuBKJVv9WtemTrlgnhpRgwjftxEq+ql+Lhvo38khVLFivBK13psiD3NxBX73BKrU/gGQKXm0PIhuGs0PBoNDe6GBW/ClHu0ET2fc2fSeFRENonIWBEJsddVAGIz7RNnr/sHERkmItEiEn3s2LGsdlHKI/h4e/FK13ocT7xAnfJBfH1f02zv++jeKIwba4Xy3rwdxJ3ykLnKc8svEHp+DZ0/gN1/2l13N7s7KnWdXJY0ROQPEYnJ4tEd+AqoDjQCDgP/zWn5xphRxpgoY0xUaGiok6NXyrluqF6KqQ/ewKShLQny9812PxHhzZ6RALw0I4aCMGIDYN002PwBGDQH0s7DmFtg45S/txtj3X1+dDv8tQjitLrZU7ms95QxpqMj+4nIaGCW/fQgUCnT5or2OqXyvebhJR3ar2JIICNuq81/ft3KtLVx9Gpa8VJjeb5XqTk8uBimDYbpD8KyT+B8AiQehYwr7mep1Qk6vQ0lq7knVpUldzWElzfGHLaXnwJaGGP6ikg9YDJ/N4T/CdTUhnBV2KRnGHqNtAZLrFAigBuql6J1jVK0rl6aMp4yem5upKfBkg+sK4piZexHWSgaav17aB0seg/SL0Crx6Htv8CvqLujLnDyU++piVhVUwbYBzyYKYm8CAwG0oAnjTFzr1WeJg1VECUkpfLLpkMs332cFX+d4LR9Z3mNMsXoVK8cT91SK//2sHLEmcPw+8uweSoUrwi3vQl1u+vAiU6Ub5KGs2nSUAVdRoZh6+EzLNt9nMW7jrFs9wne6lmffi0quzs019u/HOaMsCaPqtoWGt0LNW+BoqXdHVm+p0lDqULAGEOfr1ey51giC0a0p/hVGtYLjPQ0WDsOFn9gz/chUDEKat4GtW6Fcg30CuQ6aNJQqpCIOZhA18+X8kDbarzQOcLd4eSdjAw4vAF2zYed86y2D7DuPK/VCWp3tqaw9S0A7T55QJOGUoXIs9M2Mn39QeY/dSPhpQtpI/HZI7D7d9j5G+z+H6SeA9+iUOMmqH0H1LwViuazibDykCYNpQqRo2fP0+H9hbSqUZrR9+fo/33BlHreGkxxxxzYMRfOHgbxsuY9r98bIrpBQAl3R+lRNGkoVch8uXA37/22g0lDW9C6hjYMX3KxGmv7bNjyszUPurefdeVRv5dVleUb4O4o3U6ThlKFzPnUdG75aBGBvj7MfrwNPt6eNpycBzDGavvYPM2agTDxCPgFWcO4G2M/0sFkQEY6+AdDk/uhThfwLtizRxSEAQuVUjng7+vNC7dHsOPIWaasib32AYWRiDU8e6e34V/b4P6ZUK87pKVYSQLA29e68vAPhhO74ccB8GljWPEFnD/j3vg9jF5pKJXPGWPoO2olu44msuCZ9gQH/N0F93TSBf7YdpQFO47So1EFbqlb1o2R5hMZ6VabyIov4MBy66qkyX3Q4kEIqeru6JxKq6eUKqQudsEd0jqcYTdWY/6WI8zbEs+KPSdIyzD4+XiRkWEY2b8pHTVxOO7QeljxpdUukpEGASEQXAlKVLb/tZdDI6wxsvLZXCGaNJQqxJ77aRNTo2MxWNX04aWL0imyHJ3qlSM8tCj3fbOabYfOMGZAFO1q6cjQOXLmkNUmcmovnI6FhFjr39Rzf+/jFwTlG0D5hlC+kfVv6ZrglfUw+J5Ak4ZShdjxxBRemh5DRPni3F6/HDXLFLtsdNyEpFTuGW3dST5uUDNaVdfeVrliDCSfgtP7IT4GDm+0HvGbIS3Z2qdkNWj/PETe5ZHJQ5OGUuqqTp67QN9RK4g9mcyEIc1pVtWx4dpVDqSnwYld1gi+q0ZaY2aF1rGSR0Q3j6rC0t5TSqmrKlnUj0lDW1K+hD+Dxq1hQ+zlU68aYzh65jxLdx1nwfajJKakuSnSfMzbB8pEWI3nDy6B3uOtq5IfB8DX7WD7HOt5PqVXGkoVQvEJ5+kzagWnzl1gePsaHDiZxK4jZ9l1NJGE5L8nQ/LxEppUCaFdzdK0qxVKZFgwXgV5OHZXyUi32kQWvWPdaFi6ljVGVuUboEorKB7mlrC0ekop5bCDp5Pp8/UK4k4lUyLQl1plgqhRthi1yhSjVtkgAJbsPs7incfYcsi6VyEk0JeOEWV5tVs9ihYp2De+uUR6Gmz83rrJMHb13w3pJapYyaNySwhrYl2peLt+9GJNGkqpHElJS+dMchqli/lddUrZ44kpLN1lJZAZGw7StWEYH/dpVHCmoXWH9DSI3wQHVlhzhhxYCUnHrW3eRaBcpNULK6yx1SvLP9gaCsXbz0oo3kWs5Vy0kWjSUEq53Gd/7uK/v+/kjR6R9G9Zxd3hFBzGWFVXh9Zb42Ydsh8Xzl79uNZPwi3/ua6XvJ6kodeXSqkceaRDDaL3n+K1X7fSsGIJ6lcMdndIBYMIlKpuPer3stZlZFiJ5EgMpCZZQ5+kp1pzp6dfsJYrNc/bMPVKQymVUyfPXeCOT5fg4y3MerQtwYGFYPbAAihfdbkVkcdEZLuIbBGR9zKtf15EdovIDhG5zV3xKaWyV7KoH5/3a8Lh0+d5ZtpGCsKPT+UYtyQNEekAdAcaGmPqAR/Y6+sCfYF6QCfgSxHxvNsolVI0rRLC850j+H3rEUYv+cvd4ag84q4rjeHAO8aYFABjzFF7fXdgijEmxRizF9gN5G2FnVLKYYNbV+X2yHK8+9sO1uw76e5wVB5wV9KoBbQVkVUiskhEmtnrKwCZJwWIs9f9g4gME5FoEYk+duyYi8NVSmVFRHi3VwMqhQTw6OR17DpyjZ4+Kt9zWdIQkT9EJCaLR3esXlslgZbACGCq5LDDtzFmlDEmyhgTFRqqI3Yq5S7F/X354t4mnEtJ55aPFjNsQvQ/hie50uGEZCau2MeC7Uevup/yPC7rcmuM6ZjdNhEZDvxsrNaz1SKSAZQGDgKVMu1a0V6nlPJg9cKCWfxsB8Yv38e3y/cxf+sybqhWioc7VKdNjdKICHuPn+O3mHjmbYm/lFQCfL1ZNKI9ZYr7u/kMlKPc0uVWRB4CwowxL4tILeBPoDJQF5iM1Y4RZq+vaYxJv1p52uVWKc+RmJLGlNUHGL3kL46cSaFeWHHS0g077KqrBhWDua1eOepXCGbIt2vo1bQSb99Z381RF0756ea+scBYEYkBLgAD7KuOLSIyFdgKpAGPXCthKKU8S7EiPgxtW437bqjCjPUH+Xb5fkoE+vJK17rcWq8cFUoEXNr33hZVmLBiH0PaVKVGmSD3Ba0cpjf3KaXc5kRiCu3fX0jL6qUYfX+OfvAqJ8hXN/cppVSpYkV4qH11ft96hNV7tctufqBJQynlVoNbh1OuuD9vzdl23XeWp6Zn6F3peUSThlLKrQL8vPnXrbXYEHuauTHxDh93IS2D32LiGfptNBH//o3bPl7MFwt2E3syyYXRKm3TUEq5XXqGofMnS0hJS2f+Uzfi55P171ljDFsOnWHa2jhmbjjIqaRUygQVoVNkObYeOkP0/lMARFUJoXvjCtxRvzwli/rl5ankKzqfhlIq31qw/SiDxq/hP93qMaBV1cu2nTmfyvR1B/l+9QG2x5/Fz9uLW+qVpVfTirStURofbyvJxJ5M4peNh5i54SA7jyTi4yU8dlNNnuhY0w1n5Pk0aSil8i1jDP1Gr2LnkbMsHNGeIH9fth46w3er9jNj/UGSLqRTv0IwdzerRLcGYVcdjt0Yw/b4s3z+v93M3nyYz/s1pksD98zD7cny030aSil1GRHh+c516Pb5Mp6dtoljZ1OI3n+KIj5edGsYRv+WVWhYqYTDZUWUL85HfRoRf+Y8z07bRM0yQdQup/eC5JY2hCulPEaDiiXo1jCMuTHxHE9M4aU7Ilj1ws2837uhwwkjMz8fL766twnFivjw4MRoEpJTXRB14aLVU0opj3IuJY0dR87SqGIJvLxyNI5pttbuP0nfUStpU6M03wxo5rRy8zu9uU8ple8VLeJDk8ohTv1ib1qlJC93rceCHcf4+M9dTiu3MNKkoZQqFPq3qEzvphX59M9d/L71iLvDybc0aSilCgUR4fUekTSoGMxTP2xgz7FEd4eUL2nSUEoVGv6+3nzVvyl+Pl4M/TaaY2dT3B1SvqNJQylVqFQoEcCo+5oSn3Ce+75ZxemkC+4OKV/RpKGUKnSiqpZk9P1R/HXsHAPGrSExJc3dIeUbmjSUUoVSm5ql+eLeJsQcTGDw+DUkX3DvfG9Hzpxne/wZt8bgCL0jXClVaN1Stywf9WnEE1PW89B3axl1f1OK+HjnyWufS0lj1d4TLNl1nKW7jrPrqNUw//jNNXmqY01EPPNeEk0aSqlCrVvDMJIvpPF/P23mie838Hm/xpcGQHSF/20/wshFf7H+wClS0w1+Pl40r1qSu5pWZOeRs3z65y7Onk/l33fU9cibEDVpKKUKvT7NKnMuJZ3XZm1lxLRNvN+rgUsSx/erD/Di9M1UKVWUwW3CaVsjlKiqIfj7Wlc3GRmGEgF+jF22l8TzabxzVwO8PSxxaNJQSilgcJtwklPTeX/eDpIupPFJ38aXvsxzyxjDlwv38P68HdxYK5Sv+jch0O+fX79eXsK/u0QQ5O/DJ3/u4tyFND7u0zjb+UXcwS2RiMgPIrLBfuwTkQ2Ztj0vIrtFZIeI3OaO+JRShdMjHWrwSte6zNtyhIHjVnP2fO4HOMzIMLw2ayvvz9tBj0ZhjBkQlWXCuEhEeOqWWrx0RwRzNsfzwIToyxrpjTEcO5vCij0nmLhyP2v25e3c6m650jDG9Lm4LCL/BRLs5bpAX6AeEAb8ISK1jDHu7daglCo0BrUOp2RRP56eupG+o1YyflBzQoOKZLnv2fOpzN9yhJLF/GhaJYTi/pfP8XEhLYMR0zYyc8MhBrcO56U7IhxupxjathrFivjw/PTN9Buzklplgth9LJHdRxMvG613SJtwmlUtef0nnENurZ4Sq3vA3cBN9qruwBRjTAqwV0R2A82BFW4KUSlVCHVvVIHgAF+Gf7eO3iOXM3FICyqVDLy0fffRs0xYsZ+f1sZxzr4K8BKoG1ac5lVL0Ty8JJEVivPi9BgW7TzGs51qM/zG6jnuEdW3eWWKFvHh/37axIETSVQvU4w7GpSnRmgxapSxHuWD/Z167tfi1qHRRaQd8OHFoXlF5HNgpTHmO/v5N8BcY8y0LI4dBgwDqFy5ctP9+/fnXeBKqUJh3YFTDB6/Bl9vL8YNbEbcqWQmrNjH8j0n8PP2okvD8tzbogopqems2nuS1XtPsu7AKVLSMgArkbzVsz59m1fOVRzpGcYlDeIeNXOfiPwBlMti04vGmJn28j3A99dTvjFmFDAKrPk0ritIpZS6iiaVQ/jxwRu475vVdPlsKQBhwf4826k2faIqUarY39VWrWqUBqwqqc0HTxO97xT1KwbTqnrpXMfhST2oXJY0jDEdr7ZdRHyAO4GmmVYfBCplel7RXqeUUm5Rs2wQPz3cii8W7ObGWqHcXKfMVbvj+vl40bRKSZpWybt2hrzkzjaNjsB2Y0xcpnW/AJNF5EOshvCawGp3BKeUUhdVKBHAWz3ruzsMj+DOpNGXK6qmjDFbRGQqsBVIAx7RnlNKKeU53JY0jDEDs1n/JvBm3kajlFLKEZ5zm6FSSimPp0lDKaWUwzRpKKWUcpgmDaWUUg7TpKGUUsphmjSUUko5zK1jTzmLiBwDrnfwqdLAcSeGk58U1nPX8y5c9LyzV8UYE5qTQgtE0sgNEYnO6YBdBUVhPXc978JFz9u5tHpKKaWUwzRpKKWUcpgmDXt49UKqsJ67nnfhouftRIW+TUMppZTj9EpDKaWUwzRpKKWUclihThoi0klEdojIbhF5zt3x5JaIVBKRBSKyVUS2iMgT9vqSIvK7iOyy/w2x14uIfGqf/yYRaZKprAH2/rtEZIC7ziknRMRbRNaLyCz7ebiIrLLP7wcR8bPXF7Gf77a3V81UxvP2+h0icpt7zsRxIlJCRKaJyHYR2SYiNxSGz1tEnrL/xmNE5HsR8S+In7eIjBWRoyISk2md0z5fEWkqIpvtYz4VkWvPK2uMKZQPwBvYA1QD/ICNQF13x5XLcyoPNLGXg4CdQF3gPeA5e/1zwLv2cmdgLiBAS2CVvb4k8Jf9b4i9HOLu83Pg/P8FTAZm2c+nAn3t5ZHAcHv5YWCkvdwX+MFermv/HRQBwu2/D293n9c1zvlbYKi97AeUKOifN1AB2AsEZPqcBxbEzxtoBzQBYjKtc9rnizUzakv7mLnA7deMyd1vihs/jBuAeZmePw887+64nHyOM4FbgB1AeXtdeWCHvfw1cE+m/XfY2+8Bvs60/rL9PPGBNZ/8n8BNwCz7P8FxwOfKzxuYB9xgL/vY+8mVfwOZ9/PEBxBsf3nKFesL9OdtJ41Y+0vQx/68byuonzdQ9Yqk4ZTP1962PdP6y/bL7lGYq6cu/uFdFGevKxDsS/DGwCqgrDHmsL0pHihrL2f3HuTH9+Zj4Fkgw35eCjhtjEmzn2c+h0vnZ29PsPfPb+cdDhwDxtnVcmNEpCgFcGJgdgAABGtJREFU/PM2xhwEPoD/b+9uQ6Sq4jiOf3+0ZZZg9vDCMtiEraAgDQUhAyFZQqQiBKPAyKAHqOhFhOWr3glCEBRBEASxGJQmvsrowTLD2lZWjSxSjFrLByo0DWKxfy/Of9zbMNrVpmZ39veBYeeec++de+6Znf/ce86cw/fAT5T6G6L767uhXfV7VT5vTj+jyRw0upakacB64MmIOFbNi/KVoqv6WUtaChyOiKFOH8v/rIdy6+LliJgLnKDcrjilS+t7BnAnJWheCVwM3N7Rg+qQTtTvZA4aB4CrK8uzMm1Ck3Q+JWAMRMSGTD4kaWbmzwQOZ/rpzsFEOze3AHdI+g54g3KL6gXgEkk9uU61DKfKl/nTgZ+ZeOUeAUYi4rNcfosSRLq9vhcD+yPiSESMAhso74Fur++GdtXvgXzenH5GkzloDAJ92ePiAkoD2aYOH9O/kj0fXgX2RMTzlaxNQKPHxP2Uto5G+orsdbEAOJqXvZuBfkkz8ltdf6aNSxHxTETMioheSj1+EBH3AR8Cy3K15nI3zseyXD8y/Z7sbXMN0EdpKByXIuIg8IOk6zLpNuArury+KbelFki6KN/zjXJ3dX1XtKV+M++YpAV5HldU9nV6nW7k6XAD0xJKD6N9wOpOH08byrOQcqm6CxjOxxLK/dv3gW+B94BLc30BL2X5dwPzKvtaCezNxwOdLttZnINFjPWemk35ENgLvAlMyfQLc3lv5s+ubL86z8c31OhJ0ukHMAf4Iut8I6V3TNfXN/Ac8DXwJfA6pQdU19U3sI7SbjNKubJ8sJ31C8zLc7gPeJGmThWtHh5GxMzMapvMt6fMzOwsOWiYmVltDhpmZlabg4aZmdXmoGFmZrU5aJhVSPo0//ZKurfN+3621WuZTSTucmvWgqRFwFMRsfQstumJsbGPWuUfj4hp7Tg+s07xlYZZhaTj+XQNcKuk4Zy74TxJayUN5lwFD+f6iyRtlbSJ8qtkJG2UNJTzPTyUaWuAqbm/gepr5S9416rMDbFb0vLKvrdobL6MgVrzHZj9h3r+eRWzSWkVlSuN/PA/GhHzJU0Btkl6N9e9GbgxIvbn8sqI+EXSVGBQ0vqIWCXpsYiY0+K17qb8svsm4PLc5uPMmwvcAPwIbKOMsfRJ+4trVo+vNMzq6aeM6zNMGW7+MspYRQCfVwIGwBOSdgLbKQPF9XFmC4F1EXEyIg4BHwHzK/seiYg/KcPC9LalNGbnyFcaZvUIeDwi/jaQX7Z9nGhaXkyZzOd3SVsoYx+dqz8qz0/i/1nrMF9pmLX2G2XK3IbNwKM59DySrs0Jj5pNB37NgHE9ZSrNhtHG9k22Asuz3eQKyhSfE2G0VZuE/K3FrLVdwMm8zfQaZX6OXmBHNkYfAe5qsd07wCOS9lBGTt1eyXsF2CVpR5Sh2xvepkxPupMySvHTEXEwg47ZuOIut2ZmVptvT5mZWW0OGmZmVpuDhpmZ1eagYWZmtTlomJlZbQ4aZmZWm4OGmZnV9hdB+FtC95UIHAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6UjCTMQ_N5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b80cefbf-5b30-4966-af53-b602d1a2fa48"
      },
      "source": [
        "# evaluate on test set\n",
        "model.eval()\n",
        "test_edge_index = test_edge_index.to(device)\n",
        "test_sparse_edge_index = test_sparse_edge_index.to(device)\n",
        "\n",
        "test_loss, test_recall, test_precision, test_ndcg = evaluation(\n",
        "            model, test_edge_index, test_sparse_edge_index, [train_edge_index, val_edge_index], K, LAMBDA)\n",
        "\n",
        "print(f\"[test_loss: {round(test_loss, 5)}, test_recall@{K}: {round(test_recall, 5)}, test_precision@{K}: {round(test_precision, 5)}, test_ndcg@{K}: {round(test_ndcg, 5)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test_loss: -52.53061, test_recall@20: 0.12583, test_precision@20: 0.04638, test_ndcg@20: 0.10166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At4zWPfaVW6q"
      },
      "source": [
        "# Make New Recommendatios for a Given User"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzuMPxFVZlQn"
      },
      "source": [
        "model.eval()\n",
        "df = pd.read_csv(movie_path)\n",
        "movieid_title = pd.Series(df.title.values,index=df.movieId).to_dict()\n",
        "movieid_genres = pd.Series(df.genres.values,index=df.movieId).to_dict()\n",
        "\n",
        "user_pos_items = get_user_positive_items(edge_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(user_id, num_recs):\n",
        "    user = user_mapping[user_id]\n",
        "    e_u = model.users_emb.weight[user]\n",
        "    scores = model.items_emb.weight @ e_u\n",
        "\n",
        "    values, indices = torch.topk(scores, k=len(user_pos_items[user]) + num_recs)\n",
        "\n",
        "    movies = [index.cpu().item() for index in indices if index in user_pos_items[user]][:num_recs]\n",
        "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
        "    titles = [movieid_title[id] for id in movie_ids]\n",
        "    genres = [movieid_genres[id] for id in movie_ids]\n",
        "\n",
        "    print(f\"Here are some movies that user {user_id} rated highly\")\n",
        "    for i in range(num_recs):\n",
        "        print(f\"title: {titles[i]}, genres: {genres[i]} \")\n",
        "\n",
        "    print()\n",
        "\n",
        "    movies = [index.cpu().item() for index in indices if index not in user_pos_items[user]][:num_recs]\n",
        "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
        "    titles = [movieid_title[id] for id in movie_ids]\n",
        "    genres = [movieid_genres[id] for id in movie_ids]\n",
        "\n",
        "    print(f\"Here are some suggested movies for user {user_id}\")\n",
        "    for i in range(num_recs):\n",
        "        print(f\"title: {titles[i]}, genres: {genres[i]} \")"
      ],
      "metadata": {
        "id": "oWR-LQUDaqgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USER_ID = 1\n",
        "NUM_RECS = 10\n",
        "\n",
        "make_predictions(USER_ID, NUM_RECS)"
      ],
      "metadata": {
        "id": "Cvc-P1a6rZhD",
        "outputId": "e16cffc7-e2a0-4383-8917-3ca37c7ea027",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some movies that user 1 rated highly\n",
            "title: Forrest Gump (1994), genres: Comedy|Drama|Romance|War \n",
            "title: Matrix, The (1999), genres: Action|Sci-Fi|Thriller \n",
            "title: Silence of the Lambs, The (1991), genres: Crime|Horror|Thriller \n",
            "title: Star Wars: Episode IV - A New Hope (1977), genres: Action|Adventure|Sci-Fi \n",
            "title: Fight Club (1999), genres: Action|Crime|Drama|Thriller \n",
            "title: Schindler's List (1993), genres: Drama|War \n",
            "title: Star Wars: Episode V - The Empire Strikes Back (1980), genres: Action|Adventure|Sci-Fi \n",
            "title: Braveheart (1995), genres: Action|Drama|War \n",
            "title: American Beauty (1999), genres: Drama|Romance \n",
            "title: Usual Suspects, The (1995), genres: Crime|Mystery|Thriller \n",
            "\n",
            "Here are some suggested movies for user 1\n",
            "title: Shawshank Redemption, The (1994), genres: Crime|Drama \n",
            "title: Pulp Fiction (1994), genres: Comedy|Crime|Drama|Thriller \n",
            "title: Godfather, The (1972), genres: Crime|Drama \n",
            "title: Terminator 2: Judgment Day (1991), genres: Action|Sci-Fi \n",
            "title: Lord of the Rings: The Return of the King, The (2003), genres: Action|Adventure|Drama|Fantasy \n",
            "title: Lord of the Rings: The Fellowship of the Ring, The (2001), genres: Adventure|Fantasy \n",
            "title: Apollo 13 (1995), genres: Adventure|Drama|IMAX \n",
            "title: Lord of the Rings: The Two Towers, The (2002), genres: Adventure|Fantasy \n",
            "title: Sixth Sense, The (1999), genres: Drama|Horror|Mystery \n",
            "title: Lion King, The (1994), genres: Adventure|Animation|Children|Drama|Musical|IMAX \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSFgwnaecWBw",
        "outputId": "828828ac-78f5-47b2-9c72-ff8deff7b58f"
      },
      "source": [
        "USER_ID = 1\n",
        "NUM_RECS = 10\n",
        "\n",
        "make_predictions(USER_ID, NUM_RECS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some movies that user 1 rated highly\n",
            "title: Forrest Gump (1994), genres: Comedy|Drama|Romance|War \n",
            "title: Matrix, The (1999), genres: Action|Sci-Fi|Thriller \n",
            "title: Silence of the Lambs, The (1991), genres: Crime|Horror|Thriller \n",
            "title: Star Wars: Episode IV - A New Hope (1977), genres: Action|Adventure|Sci-Fi \n",
            "title: Fight Club (1999), genres: Action|Crime|Drama|Thriller \n",
            "title: Schindler's List (1993), genres: Drama|War \n",
            "title: Star Wars: Episode V - The Empire Strikes Back (1980), genres: Action|Adventure|Sci-Fi \n",
            "title: Braveheart (1995), genres: Action|Drama|War \n",
            "title: Usual Suspects, The (1995), genres: Crime|Mystery|Thriller \n",
            "title: Star Wars: Episode VI - Return of the Jedi (1983), genres: Action|Adventure|Sci-Fi \n",
            "\n",
            "Here are some suggested movies for user 1\n",
            "title: Shawshank Redemption, The (1994), genres: Crime|Drama \n",
            "title: Pulp Fiction (1994), genres: Comedy|Crime|Drama|Thriller \n",
            "title: Godfather, The (1972), genres: Crime|Drama \n",
            "title: Terminator 2: Judgment Day (1991), genres: Action|Sci-Fi \n",
            "title: Lord of the Rings: The Return of the King, The (2003), genres: Action|Adventure|Drama|Fantasy \n",
            "title: Lord of the Rings: The Fellowship of the Ring, The (2001), genres: Adventure|Fantasy \n",
            "title: Sixth Sense, The (1999), genres: Drama|Horror|Mystery \n",
            "title: Lord of the Rings: The Two Towers, The (2002), genres: Adventure|Fantasy \n",
            "title: Apollo 13 (1995), genres: Adventure|Drama|IMAX \n",
            "title: Aladdin (1992), genres: Adventure|Animation|Children|Comedy|Musical \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLkRpNldrSQe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}